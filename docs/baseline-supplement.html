<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Baseline analysis supplement</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Visualising baseline characteristics</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">About</a>
</li>
<li>
  <a href="manuscript/baseline-manuscript.pdf">Manuscript</a>
</li>
<li>
  <a href="baseline-supplement.html">Descriptives</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Baseline analysis supplement</h1>

</div>


<p>Welcome to the LMI baseline supplement! This supplement will walk you through the paper and provides additional graphs.</p>
<div id="measures-used-in-the-study" class="section level1">
<h1>Measures used in the study</h1>
<p>Clicking the “Code”-buttons on the right shows code for each chunk.</p>
<p>To start data analysis, we set up the basics to enable compiling the document:</p>
<pre class="r"><code>source(&quot;baseline-datasetup.R&quot;)</code></pre>
</div>
<div id="means-with-cis-taking-clustering-into-account" class="section level1 tabset">
<h1>Means with CIs taking clustering into account</h1>
<div id="description" class="section level2">
<h2>Description</h2>
<p>The code chunks create linear models for all variables. The results are used to estimate confidence intervals and intra-class correlations (ICC).</p>
<p>Browse throught the tabs above to see different information.</p>
<p>Code chunk below shows how the values are calculated.</p>
<pre class="r"><code># Create a vector with all names of the variables we want. Exclude T3 variables.
names &lt;- df %&gt;% select(-id, -intervention, -group, -school, -girl, -track, -trackSchool, -contains(&quot;_T3&quot;), -contains(&quot;_diff&quot;)) %&gt;% names(.)

# Create empty soon-to-be-filled objects
m &lt;- NA
mean &lt;- NA
m_p &lt;- NA
ci_low &lt;- NA
ci_high &lt;- NA
ICC_group &lt;- NA
ICC_School &lt;- NA
nonmissings &lt;- NA

## Use this to test a single variable:
# dftest &lt;- df #%&gt;% na.omit()
# m &lt;- lme4::lmer(sitLieAccelerometer_diff ~ (1|school) + (1|group), data=dftest)
# mean &lt;- lme4::fixef(m)
# m_p &lt;- profile(m, which = &quot;beta_&quot;)
# ci_low &lt;- confint(m_p)[, 1]
# ci_high &lt;- confint(m_p)[, 2]
# ICC_group &lt;- icc(m)[1]
# ICC_School &lt;- icc(m)[2]
# nonmissings &lt;- length(m@resp$y)


# Loop over each variable name, extract statistics: 

# all participants
for (i in names){
m &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group)&quot;), data=df)
mean[i] &lt;- lme4::fixef(m)
m_p &lt;- profile(m, which = &quot;beta_&quot;)
ci_low[i] &lt;- confint(m_p)[, 1]
ci_high[i] &lt;- confint(m_p)[, 2]
ICC_group[i] &lt;- sjstats::icc(m)[1]
ICC_School[i] &lt;- sjstats::icc(m)[2]
nonmissings[i] &lt;- length(m@resp$y)
}
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation


vardatatable &lt;- data_frame(
  Variable = stringr::str_sub(names(mean), end = -4), #remove &quot;_T1&quot; from names
  &quot;Mean&quot; = round(mean, 2),
  &quot;CI95&quot; = paste(round(ci_low, 2), &quot; - &quot;, round(ci_high, 2)), 
  &quot;ICC class&quot; =ifelse(round(ICC_group, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_group, 3)), 
  &quot;ICC school&quot; = ifelse(round(ICC_School, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_School, 3)),
  n = nonmissings) %&gt;% 
  dplyr::arrange(Variable) %&gt;% 
  filter(Variable != &quot;&quot;) %&gt;% #remove first row, which is empty
  mutate(`ICC class` = as.numeric(`ICC class`)) %&gt;% 
  as.data.frame()
## Warning in evalq(as.numeric(`ICC class`), &lt;environment&gt;): NAs introduced by
## coercion</code></pre>
</div>
<div id="primary-outcome-variables" class="section level2">
<h2>Primary outcome variables</h2>
<pre class="r"><code>options(tibble.print_max = 1000)

vardatatable2 &lt;- vardatatable
vardatatable2$Variable &lt;- gsub(&quot;paAccelerometer&quot;, &quot;PA minutes&quot;, vardatatable2$Variable)
vardatatable2$Variable &lt;- gsub(&quot;padaysLastweek&quot;, &quot;Number of MVPA days last week (self-report)&quot;, vardatatable2$Variable)
vardatatable2$Variable &lt;- gsub(&quot;sitLieAccelerometer&quot;, &quot;Minutes spent sitting or lying down&quot;, vardatatable2$Variable)
vardatatable2$Variable &lt;- gsub(&quot;sitBreaks&quot;, &quot;Number of times sitting was interrupted&quot;, vardatatable2$Variable)

vardatatable2 %&gt;% 
  filter(Variable == &quot;PA minutes&quot; | 
           Variable == &quot;Number of MVPA days last week (self-report)&quot; | 
           Variable == &quot;Minutes spent sitting or lying down&quot; | 
           Variable == &quot;Number of times sitting was interrupted&quot; ) %&gt;% 
    papaja::apa_table(
        caption = &quot;Primary outcome variables with their class and school ICCs&quot;,
        escape = T,
        format.args = list(digits = c(2, 3, 0), margin = 2))</code></pre>
<caption>
(#tab:selected-total)
</caption>
<caption>
<em>Primary outcome variables with their class and school ICCs</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Mean</th>
<th align="left">CI95</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA minutes</td>
<td align="left">183.13</td>
<td align="left">165.99  -  200.45</td>
<td align="left">0.072</td>
<td align="left">0.096</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">Number of MVPA days last week (self-report)</td>
<td align="left">2.79</td>
<td align="left">2.63  -  2.95</td>
<td align="left">0.047</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">Number of times sitting was interrupted</td>
<td align="left">28.02</td>
<td align="left">24.69  -  31.37</td>
<td align="left">0.058</td>
<td align="left">0.085</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">Minutes spent sitting or lying down</td>
<td align="left">573.94</td>
<td align="left">535.48  -  611.8</td>
<td align="left">0.086</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
</tbody>
</table>
</div>
<div id="all-main-variables-their-means-cis-and-iccs." class="section level2">
<h2>All main variables, their means, CIs and ICCs.</h2>
<pre class="r"><code>options(tibble.print_max = 1000)
 
vardatatable %&gt;%
    papaja::apa_table(
        caption = &quot;All variables with their class and school ICCs&quot;,
        escape = T,
        format.args = list(digits = c(2, 3, 0), margin = 2))</code></pre>
<caption>
(#tab:allvars-total)
</caption>
<caption>
<em>All variables with their class and school ICCs</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Mean</th>
<th align="left">CI95</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b5agr</td>
<td align="left">5.34</td>
<td align="left">5.18 - 5.5</td>
<td align="left">0.033</td>
<td align="left">0.012</td>
<td align="left">1,068</td>
</tr>
<tr class="even">
<td align="left">b5agr_01</td>
<td align="left">5.51</td>
<td align="left">5.38 - 5.66</td>
<td align="left">0.045</td>
<td align="left">0.002</td>
<td align="left">1,061</td>
</tr>
<tr class="odd">
<td align="left">b5agrReverseCoded_02</td>
<td align="left">5.16</td>
<td align="left">4.95 - 5.37</td>
<td align="left">0.005</td>
<td align="left">0.01</td>
<td align="left">1,064</td>
</tr>
<tr class="even">
<td align="left">b5cons</td>
<td align="left">5.03</td>
<td align="left">4.91 - 5.17</td>
<td align="left">NA</td>
<td align="left">0.007</td>
<td align="left">1,067</td>
</tr>
<tr class="odd">
<td align="left">b5cons_01</td>
<td align="left">5.44</td>
<td align="left">5.25 - 5.65</td>
<td align="left">0.014</td>
<td align="left">0.015</td>
<td align="left">1,059</td>
</tr>
<tr class="even">
<td align="left">b5consReverseCoded_02</td>
<td align="left">4.63</td>
<td align="left">4.49 - 4.78</td>
<td align="left">NA</td>
<td align="left">0.002</td>
<td align="left">1,065</td>
</tr>
<tr class="odd">
<td align="left">b5ext</td>
<td align="left">4.53</td>
<td align="left">4.3 - 4.77</td>
<td align="left">0.020</td>
<td align="left">0.022</td>
<td align="left">1,068</td>
</tr>
<tr class="even">
<td align="left">b5ext_01</td>
<td align="left">4.97</td>
<td align="left">4.73 - 5.24</td>
<td align="left">0.048</td>
<td align="left">0.013</td>
<td align="left">1,063</td>
</tr>
<tr class="odd">
<td align="left">b5extReverseCoded_02</td>
<td align="left">4.07</td>
<td align="left">3.84 - 4.32</td>
<td align="left">0.002</td>
<td align="left">0.012</td>
<td align="left">1,062</td>
</tr>
<tr class="even">
<td align="left">b5neur</td>
<td align="left">3.82</td>
<td align="left">3.64 - 4</td>
<td align="left">0.014</td>
<td align="left">0.012</td>
<td align="left">1,068</td>
</tr>
<tr class="odd">
<td align="left">b5neur_01</td>
<td align="left">4.11</td>
<td align="left">3.85 - 4.39</td>
<td align="left">0.017</td>
<td align="left">0.014</td>
<td align="left">1,064</td>
</tr>
<tr class="even">
<td align="left">b5neurReverseCoded_02</td>
<td align="left">3.53</td>
<td align="left">3.39 - 3.67</td>
<td align="left">0.011</td>
<td align="left">0.002</td>
<td align="left">1,061</td>
</tr>
<tr class="odd">
<td align="left">b5open</td>
<td align="left">4.89</td>
<td align="left">4.67 - 5.12</td>
<td align="left">0.010</td>
<td align="left">0.03</td>
<td align="left">1,068</td>
</tr>
<tr class="even">
<td align="left">b5open_01</td>
<td align="left">5.35</td>
<td align="left">5.13 - 5.59</td>
<td align="left">0.025</td>
<td align="left">0.016</td>
<td align="left">1,062</td>
</tr>
<tr class="odd">
<td align="left">b5openReverseCoded_02</td>
<td align="left">4.42</td>
<td align="left">4.19 - 4.67</td>
<td align="left">NA</td>
<td align="left">0.016</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">fatpct</td>
<td align="left">25.52</td>
<td align="left">22.38 - 28.67</td>
<td align="left">0.003</td>
<td align="left">0.123</td>
<td align="left">942</td>
</tr>
<tr class="odd">
<td align="left">PA_actCop</td>
<td align="left">2.63</td>
<td align="left">2.56 - 2.69</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actionplan</td>
<td align="left">2.76</td>
<td align="left">2.69 - 2.83</td>
<td align="left">0.038</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_01</td>
<td align="left">2.60</td>
<td align="left">2.52 - 2.68</td>
<td align="left">0.032</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_02</td>
<td align="left">2.80</td>
<td align="left">2.73 - 2.88</td>
<td align="left">0.028</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_03</td>
<td align="left">2.85</td>
<td align="left">2.78 - 2.93</td>
<td align="left">0.037</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_04</td>
<td align="left">2.78</td>
<td align="left">2.7 - 2.86</td>
<td align="left">0.038</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct</td>
<td align="left">3.11</td>
<td align="left">3 - 3.23</td>
<td align="left">0.052</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_01</td>
<td align="left">3.67</td>
<td align="left">3.51 - 3.85</td>
<td align="left">0.061</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_02</td>
<td align="left">3.19</td>
<td align="left">3.05 - 3.33</td>
<td align="left">0.025</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_03</td>
<td align="left">2.44</td>
<td align="left">2.31 - 2.57</td>
<td align="left">0.009</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_04</td>
<td align="left">2.52</td>
<td align="left">2.38 - 2.67</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_05</td>
<td align="left">2.63</td>
<td align="left">2.49 - 2.78</td>
<td align="left">0.055</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_06</td>
<td align="left">3.22</td>
<td align="left">3.08 - 3.38</td>
<td align="left">0.028</td>
<td align="left">0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_07</td>
<td align="left">3.03</td>
<td align="left">2.91 - 3.16</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_08</td>
<td align="left">3.10</td>
<td align="left">2.97 - 3.25</td>
<td align="left">0.023</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_09</td>
<td align="left">3.67</td>
<td align="left">3.52 - 3.85</td>
<td align="left">0.032</td>
<td align="left">0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_10</td>
<td align="left">3.63</td>
<td align="left">3.48 - 3.79</td>
<td align="left">0.044</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_amotivation</td>
<td align="left">1.54</td>
<td align="left">1.45 - 1.61</td>
<td align="left">0.035</td>
<td align="left">0.002</td>
<td align="left">1,072</td>
</tr>
<tr class="odd">
<td align="left">PA_amotivation_01</td>
<td align="left">1.51</td>
<td align="left">1.44 - 1.59</td>
<td align="left">0.031</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,062</td>
</tr>
<tr class="even">
<td align="left">PA_amotivation_02</td>
<td align="left">1.53</td>
<td align="left">1.42 - 1.63</td>
<td align="left">0.026</td>
<td align="left">0.005</td>
<td align="left">1,057</td>
</tr>
<tr class="odd">
<td align="left">PA_amotivation_03</td>
<td align="left">1.60</td>
<td align="left">1.51 - 1.69</td>
<td align="left">0.032</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,067</td>
</tr>
<tr class="even">
<td align="left">PA_amotivation_04</td>
<td align="left">1.47</td>
<td align="left">1.39 - 1.55</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous</td>
<td align="left">3.41</td>
<td align="left">3.31 - 3.52</td>
<td align="left">0.073</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,078</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_01</td>
<td align="left">3.12</td>
<td align="left">2.96 - 3.29</td>
<td align="left">0.002</td>
<td align="left">0.012</td>
<td align="left">1,063</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_02</td>
<td align="left">3.76</td>
<td align="left">3.66 - 3.86</td>
<td align="left">0.031</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,063</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_03</td>
<td align="left">3.36</td>
<td align="left">3.24 - 3.51</td>
<td align="left">0.058</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_04</td>
<td align="left">3.30</td>
<td align="left">3.17 - 3.47</td>
<td align="left">0.059</td>
<td align="left">0.004</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_05</td>
<td align="left">3.26</td>
<td align="left">3.15 - 3.39</td>
<td align="left">0.048</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,062</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_06</td>
<td align="left">3.09</td>
<td align="left">2.96 - 3.22</td>
<td align="left">0.072</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_07</td>
<td align="left">3.72</td>
<td align="left">3.58 - 3.88</td>
<td align="left">0.072</td>
<td align="left">0.005</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_08</td>
<td align="left">3.63</td>
<td align="left">3.53 - 3.76</td>
<td align="left">0.057</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_09</td>
<td align="left">3.50</td>
<td align="left">3.39 - 3.62</td>
<td align="left">0.055</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,057</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled</td>
<td align="left">1.84</td>
<td align="left">1.78 - 1.9</td>
<td align="left">0.005</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_controlled_01</td>
<td align="left">1.66</td>
<td align="left">1.59 - 1.73</td>
<td align="left">0.010</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,068</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled_02</td>
<td align="left">1.48</td>
<td align="left">1.41 - 1.55</td>
<td align="left">0.024</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069</td>
</tr>
<tr class="even">
<td align="left">PA_controlled_03</td>
<td align="left">1.55</td>
<td align="left">1.49 - 1.61</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled_04</td>
<td align="left">2.18</td>
<td align="left">2.08 - 2.28</td>
<td align="left">NA</td>
<td align="left">0.001</td>
<td align="left">1,068</td>
</tr>
<tr class="even">
<td align="left">PA_controlled_05</td>
<td align="left">2.31</td>
<td align="left">2.22 - 2.4</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="odd">
<td align="left">PA_copingplan</td>
<td align="left">2.50</td>
<td align="left">2.44 - 2.56</td>
<td align="left">0.023</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_01</td>
<td align="left">2.41</td>
<td align="left">2.34 - 2.47</td>
<td align="left">0.007</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_02</td>
<td align="left">2.43</td>
<td align="left">2.37 - 2.5</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_03</td>
<td align="left">2.46</td>
<td align="left">2.39 - 2.54</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_04</td>
<td align="left">2.69</td>
<td align="left">2.62 - 2.77</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm</td>
<td align="left">4.40</td>
<td align="left">4.24 - 4.58</td>
<td align="left">0.050</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">4.50</td>
<td align="left">4.3 - 4.71</td>
<td align="left">0.050</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm_02</td>
<td align="left">4.31</td>
<td align="left">4.11 - 4.52</td>
<td align="left">0.027</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_extrinsic</td>
<td align="left">1.56</td>
<td align="left">1.5 - 1.62</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069</td>
</tr>
<tr class="even">
<td align="left">PA_extrinsic_01</td>
<td align="left">1.66</td>
<td align="left">1.59 - 1.73</td>
<td align="left">0.010</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,068</td>
</tr>
<tr class="odd">
<td align="left">PA_extrinsic_02</td>
<td align="left">1.48</td>
<td align="left">1.41 - 1.55</td>
<td align="left">0.024</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069</td>
</tr>
<tr class="even">
<td align="left">PA_extrinsic_03</td>
<td align="left">1.55</td>
<td align="left">1.49 - 1.61</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct</td>
<td align="left">2.53</td>
<td align="left">2.45 - 2.62</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_01</td>
<td align="left">3.73</td>
<td align="left">3.63 - 3.84</td>
<td align="left">0.014</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_02</td>
<td align="left">1.87</td>
<td align="left">1.76 - 1.98</td>
<td align="left">0.024</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_03</td>
<td align="left">2.03</td>
<td align="left">1.93 - 2.13</td>
<td align="left">0.007</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_04</td>
<td align="left">1.90</td>
<td align="left">1.78 - 2.02</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_05</td>
<td align="left">2.50</td>
<td align="left">2.36 - 2.64</td>
<td align="left">0.033</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_06</td>
<td align="left">3.41</td>
<td align="left">3.29 - 3.54</td>
<td align="left">0.016</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_07</td>
<td align="left">2.20</td>
<td align="left">2.1 - 2.3</td>
<td align="left">0.003</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_08</td>
<td align="left">2.39</td>
<td align="left">2.28 - 2.5</td>
<td align="left">0.014</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_09</td>
<td align="left">2.79</td>
<td align="left">2.67 - 2.9</td>
<td align="left">0.007</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_goal</td>
<td align="left">0.55</td>
<td align="left">0.51 - 0.59</td>
<td align="left">0.046</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,061</td>
</tr>
<tr class="even">
<td align="left">PA_goal_01</td>
<td align="left">0.55</td>
<td align="left">0.51 - 0.59</td>
<td align="left">0.046</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,061</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">3.41</td>
<td align="left">3.3 - 3.54</td>
<td align="left">0.040</td>
<td align="left">0.004</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_identified_01</td>
<td align="left">3.12</td>
<td align="left">2.96 - 3.29</td>
<td align="left">0.002</td>
<td align="left">0.012</td>
<td align="left">1,063</td>
</tr>
<tr class="odd">
<td align="left">PA_identified_02</td>
<td align="left">3.76</td>
<td align="left">3.66 - 3.86</td>
<td align="left">0.031</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,063</td>
</tr>
<tr class="even">
<td align="left">PA_identified_03</td>
<td align="left">3.36</td>
<td align="left">3.24 - 3.51</td>
<td align="left">0.058</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm</td>
<td align="left">4.66</td>
<td align="left">4.48 - 4.84</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_inorm_01</td>
<td align="left">4.66</td>
<td align="left">4.48 - 4.84</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated</td>
<td align="left">3.21</td>
<td align="left">3.11 - 3.34</td>
<td align="left">0.071</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_integrated_01</td>
<td align="left">3.30</td>
<td align="left">3.17 - 3.47</td>
<td align="left">0.059</td>
<td align="left">0.004</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated_02</td>
<td align="left">3.26</td>
<td align="left">3.15 - 3.39</td>
<td align="left">0.048</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,062</td>
</tr>
<tr class="even">
<td align="left">PA_integrated_03</td>
<td align="left">3.09</td>
<td align="left">2.96 - 3.22</td>
<td align="left">0.072</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="odd">
<td align="left">PA_intention</td>
<td align="left">5.38</td>
<td align="left">5.19 - 5.57</td>
<td align="left">0.105</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention_01</td>
<td align="left">5.35</td>
<td align="left">5.16 - 5.55</td>
<td align="left">0.088</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">5.41</td>
<td align="left">5.21 - 5.61</td>
<td align="left">0.111</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intrinsic</td>
<td align="left">3.61</td>
<td align="left">3.51 - 3.74</td>
<td align="left">0.074</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic_01</td>
<td align="left">3.72</td>
<td align="left">3.58 - 3.88</td>
<td align="left">0.072</td>
<td align="left">0.005</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_intrinsic_02</td>
<td align="left">3.63</td>
<td align="left">3.53 - 3.76</td>
<td align="left">0.057</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic_03</td>
<td align="left">3.50</td>
<td align="left">3.39 - 3.62</td>
<td align="left">0.055</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,057</td>
</tr>
<tr class="even">
<td align="left">PA_introjected</td>
<td align="left">2.24</td>
<td align="left">2.16 - 2.33</td>
<td align="left">NA</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected_01</td>
<td align="left">2.18</td>
<td align="left">2.08 - 2.28</td>
<td align="left">NA</td>
<td align="left">0.001</td>
<td align="left">1,068</td>
</tr>
<tr class="even">
<td align="left">PA_introjected_02</td>
<td align="left">2.31</td>
<td align="left">2.22 - 2.4</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities</td>
<td align="left">5.12</td>
<td align="left">5.05 - 5.19</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities_01</td>
<td align="left">4.65</td>
<td align="left">4.32 - 4.98</td>
<td align="left">0.037</td>
<td align="left">0.02</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities_02</td>
<td align="left">5.50</td>
<td align="left">5.38 - 5.62</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,067</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities_04</td>
<td align="left">5.55</td>
<td align="left">5.37 - 5.75</td>
<td align="left">0.021</td>
<td align="left">0.008</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities_05</td>
<td align="left">5.32</td>
<td align="left">5.21 - 5.43</td>
<td align="left">NA</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities_07</td>
<td align="left">4.63</td>
<td align="left">4.49 - 4.77</td>
<td align="left">0.009</td>
<td align="left">0.001</td>
<td align="left">1,068</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunitiesReverseCoded_03</td>
<td align="left">5.11</td>
<td align="left">5 - 5.23</td>
<td align="left">NA</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,065</td>
</tr>
<tr class="even">
<td align="left">PA_opportunitiesReverseCoded_06</td>
<td align="left">3.63</td>
<td align="left">3.31 - 3.95</td>
<td align="left">NA</td>
<td align="left">0.024</td>
<td align="left">1,059</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunitiesReverseCoded_08</td>
<td align="left">6.58</td>
<td align="left">6.49 - 6.68</td>
<td align="left">0.020</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations</td>
<td align="left">4.61</td>
<td align="left">4.48 - 4.74</td>
<td align="left">0.034</td>
<td align="left">0.013</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_01</td>
<td align="left">5.48</td>
<td align="left">5.27 - 5.7</td>
<td align="left">0.042</td>
<td align="left">0.011</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_03</td>
<td align="left">5.20</td>
<td align="left">4.94 - 5.47</td>
<td align="left">0.008</td>
<td align="left">0.018</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_04</td>
<td align="left">5.47</td>
<td align="left">5.3 - 5.65</td>
<td align="left">0.009</td>
<td align="left">0.007</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_05</td>
<td align="left">5.19</td>
<td align="left">5 - 5.39</td>
<td align="left">0.023</td>
<td align="left">0.011</td>
<td align="left">1,067</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_06</td>
<td align="left">5.40</td>
<td align="left">5.18 - 5.63</td>
<td align="left">0.030</td>
<td align="left">0.016</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_07</td>
<td align="left">4.92</td>
<td align="left">4.73 - 5.13</td>
<td align="left">0.039</td>
<td align="left">0.008</td>
<td align="left">1,062</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_10</td>
<td align="left">5.35</td>
<td align="left">5.18 - 5.54</td>
<td align="left">0.019</td>
<td align="left">0.006</td>
<td align="left">1,069</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_11</td>
<td align="left">5.13</td>
<td align="left">4.91 - 5.38</td>
<td align="left">0.055</td>
<td align="left">0.011</td>
<td align="left">1,063</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_12</td>
<td align="left">5.19</td>
<td align="left">4.95 - 5.45</td>
<td align="left">0.042</td>
<td align="left">0.014</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectationsNegative_02</td>
<td align="left">2.87</td>
<td align="left">2.73 - 3.02</td>
<td align="left">0.046</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectationsNegative_08</td>
<td align="left">2.53</td>
<td align="left">2.34 - 2.69</td>
<td align="left">0.038</td>
<td align="left">0.004</td>
<td align="left">1,063</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectationsNegative_09</td>
<td align="left">2.57</td>
<td align="left">2.45 - 2.68</td>
<td align="left">0.023</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">PA_pbc</td>
<td align="left">5.32</td>
<td align="left">5.19 - 5.45</td>
<td align="left">0.028</td>
<td align="left">0.004</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_pbc_01</td>
<td align="left">5.86</td>
<td align="left">5.74 - 5.98</td>
<td align="left">0.032</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069</td>
</tr>
<tr class="odd">
<td align="left">PA_pbc_03</td>
<td align="left">5.19</td>
<td align="left">4.97 - 5.4</td>
<td align="left">0.014</td>
<td align="left">0.01</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_pbcReverseCoded_02</td>
<td align="left">4.92</td>
<td align="left">4.7 - 5.11</td>
<td align="left">0.005</td>
<td align="left">0.005</td>
<td align="left">1,063</td>
</tr>
<tr class="odd">
<td align="left">PA_selfefficacy</td>
<td align="left">5.22</td>
<td align="left">5.1 - 5.35</td>
<td align="left">0.007</td>
<td align="left">0.005</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_selfefficacy_01</td>
<td align="left">5.85</td>
<td align="left">5.75 - 5.96</td>
<td align="left">0.009</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_selfefficacyReverseCoded_02</td>
<td align="left">4.59</td>
<td align="left">4.41 - 4.77</td>
<td align="left">0.002</td>
<td align="left">0.005</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_sePbc</td>
<td align="left">5.27</td>
<td align="left">5.15 - 5.4</td>
<td align="left">0.028</td>
<td align="left">0.007</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">paAccelerometer</td>
<td align="left">183.13</td>
<td align="left">165.99 - 200.45</td>
<td align="left">0.072</td>
<td align="left">0.096</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">padaysLastweek</td>
<td align="left">2.79</td>
<td align="left">2.63 - 2.95</td>
<td align="left">0.047</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">pafreqUsually</td>
<td align="left">2.56</td>
<td align="left">2.4 - 2.73</td>
<td align="left">0.094</td>
<td align="left">0.003</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">5.44</td>
<td align="left">4.7 - 6.16</td>
<td align="left">0.024</td>
<td align="left">0.007</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">pahrsUsually</td>
<td align="left">3.11</td>
<td align="left">2.88 - 3.36</td>
<td align="left">0.085</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">paLastweek</td>
<td align="left">339.67</td>
<td align="left">295.99 - 382.07</td>
<td align="left">0.024</td>
<td align="left">0.006</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">paminLastweek</td>
<td align="left">1.44</td>
<td align="left">1.38 - 1.5</td>
<td align="left">NA</td>
<td align="left">0.01</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">SB_dnorm</td>
<td align="left">3.25</td>
<td align="left">3.1 - 3.41</td>
<td align="left">0.003</td>
<td align="left">0.007</td>
<td align="left">1,062</td>
</tr>
<tr class="odd">
<td align="left">SB_dnorm_01</td>
<td align="left">3.07</td>
<td align="left">2.94 - 3.22</td>
<td align="left">NA</td>
<td align="left">0.004</td>
<td align="left">1,059</td>
</tr>
<tr class="even">
<td align="left">SB_dnorm_02</td>
<td align="left">3.41</td>
<td align="left">3.24 - 3.59</td>
<td align="left">0.010</td>
<td align="left">0.007</td>
<td align="left">1,060</td>
</tr>
<tr class="odd">
<td align="left">SB_inorm</td>
<td align="left">4.01</td>
<td align="left">3.9 - 4.14</td>
<td align="left">0.012</td>
<td align="left">0.004</td>
<td align="left">1,064</td>
</tr>
<tr class="even">
<td align="left">SB_inorm_01</td>
<td align="left">3.93</td>
<td align="left">3.76 - 4.11</td>
<td align="left">NA</td>
<td align="left">0.008</td>
<td align="left">1,056</td>
</tr>
<tr class="odd">
<td align="left">SB_inorm_02</td>
<td align="left">4.10</td>
<td align="left">3.95 - 4.28</td>
<td align="left">0.030</td>
<td align="left">0.005</td>
<td align="left">1,053</td>
</tr>
<tr class="even">
<td align="left">SB_intention</td>
<td align="left">3.74</td>
<td align="left">3.42 - 4.06</td>
<td align="left">0.014</td>
<td align="left">0.035</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_01</td>
<td align="left">3.33</td>
<td align="left">3.03 - 3.64</td>
<td align="left">NA</td>
<td align="left">0.025</td>
<td align="left">1,059</td>
</tr>
<tr class="even">
<td align="left">SB_intention_02</td>
<td align="left">3.49</td>
<td align="left">3.17 - 3.81</td>
<td align="left">NA</td>
<td align="left">0.034</td>
<td align="left">1,056</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_03</td>
<td align="left">4.02</td>
<td align="left">3.68 - 4.37</td>
<td align="left">0.023</td>
<td align="left">0.027</td>
<td align="left">1,054</td>
</tr>
<tr class="even">
<td align="left">SB_intention_04</td>
<td align="left">4.09</td>
<td align="left">3.77 - 4.43</td>
<td align="left">0.028</td>
<td align="left">0.027</td>
<td align="left">1,055</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectations</td>
<td align="left">4.41</td>
<td align="left">4.3 - 4.53</td>
<td align="left">0.029</td>
<td align="left">0.005</td>
<td align="left">1,064</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectations_02</td>
<td align="left">4.84</td>
<td align="left">4.63 - 5.06</td>
<td align="left">0.017</td>
<td align="left">0.014</td>
<td align="left">1,056</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectations_03</td>
<td align="left">4.64</td>
<td align="left">4.41 - 4.88</td>
<td align="left">0.024</td>
<td align="left">0.014</td>
<td align="left">1,058</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectations_04</td>
<td align="left">4.92</td>
<td align="left">4.74 - 5.12</td>
<td align="left">0.038</td>
<td align="left">0.005</td>
<td align="left">1,063</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectations_05</td>
<td align="left">4.91</td>
<td align="left">4.73 - 5.09</td>
<td align="left">0.040</td>
<td align="left">0.004</td>
<td align="left">1,060</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectations_06</td>
<td align="left">4.87</td>
<td align="left">4.65 - 5.11</td>
<td align="left">0.047</td>
<td align="left">0.011</td>
<td align="left">1,058</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectationsNegative_01</td>
<td align="left">3.40</td>
<td align="left">3.28 - 3.51</td>
<td align="left">0.008</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,063</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectationsNegative_07</td>
<td align="left">3.35</td>
<td align="left">3.18 - 3.51</td>
<td align="left">0.012</td>
<td align="left">0.003</td>
<td align="left">1,057</td>
</tr>
<tr class="odd">
<td align="left">SB_sePbc</td>
<td align="left">4.97</td>
<td align="left">4.82 - 5.14</td>
<td align="left">0.015</td>
<td align="left">0.011</td>
<td align="left">1,064</td>
</tr>
<tr class="even">
<td align="left">SB_sePbc_01</td>
<td align="left">4.36</td>
<td align="left">4.14 - 4.6</td>
<td align="left">0.010</td>
<td align="left">0.014</td>
<td align="left">1,062</td>
</tr>
<tr class="odd">
<td align="left">SB_sePbc_02</td>
<td align="left">4.30</td>
<td align="left">4.07 - 4.54</td>
<td align="left">0.003</td>
<td align="left">0.015</td>
<td align="left">1,061</td>
</tr>
<tr class="even">
<td align="left">SB_sePbc_03</td>
<td align="left">5.74</td>
<td align="left">5.63 - 5.87</td>
<td align="left">0.026</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,060</td>
</tr>
<tr class="odd">
<td align="left">SB_sePbc_04</td>
<td align="left">5.74</td>
<td align="left">5.62 - 5.88</td>
<td align="left">0.034</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,060</td>
</tr>
<tr class="even">
<td align="left">SB_sePbc_05</td>
<td align="left">4.68</td>
<td align="left">4.46 - 4.91</td>
<td align="left">0.005</td>
<td align="left">0.012</td>
<td align="left">1,054</td>
</tr>
<tr class="odd">
<td align="left">sitBreaks</td>
<td align="left">28.02</td>
<td align="left">24.69 - 31.37</td>
<td align="left">0.058</td>
<td align="left">0.085</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">sitLieAccelerometer</td>
<td align="left">573.94</td>
<td align="left">535.48 - 611.8</td>
<td align="left">0.086</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
<tr class="odd">
<td align="left">symptom</td>
<td align="left">1.97</td>
<td align="left">1.83 - 2.11</td>
<td align="left">0.023</td>
<td align="left">0.039</td>
<td align="left">1,084</td>
</tr>
<tr class="even">
<td align="left">symptom_headAche</td>
<td align="left">1.99</td>
<td align="left">1.83 - 2.16</td>
<td align="left">0.007</td>
<td align="left">0.027</td>
<td align="left">1,055</td>
</tr>
<tr class="odd">
<td align="left">symptom_irritabilityAngerbursts</td>
<td align="left">1.91</td>
<td align="left">1.8 - 2.04</td>
<td align="left">0.026</td>
<td align="left">0.01</td>
<td align="left">1,039</td>
</tr>
<tr class="even">
<td align="left">symptom_lowerBackPain</td>
<td align="left">1.76</td>
<td align="left">1.68 - 1.85</td>
<td align="left">0.004</td>
<td align="left">0.005</td>
<td align="left">1,053</td>
</tr>
<tr class="odd">
<td align="left">symptom_neckShoulderPain</td>
<td align="left">1.97</td>
<td align="left">1.78 - 2.17</td>
<td align="left">0.011</td>
<td align="left">0.033</td>
<td align="left">1,047</td>
</tr>
<tr class="even">
<td align="left">symptom_sleepDifficulty</td>
<td align="left">2.09</td>
<td align="left">1.92 - 2.27</td>
<td align="left">0.010</td>
<td align="left">0.023</td>
<td align="left">1,052</td>
</tr>
<tr class="odd">
<td align="left">symptom_stomachAche</td>
<td align="left">1.73</td>
<td align="left">1.61 - 1.86</td>
<td align="left">0.015</td>
<td align="left">0.023</td>
<td align="left">1,026</td>
</tr>
<tr class="even">
<td align="left">symptom_tensionNervousness</td>
<td align="left">1.92</td>
<td align="left">1.77 - 2.08</td>
<td align="left">0.007</td>
<td align="left">0.024</td>
<td align="left">1,051</td>
</tr>
<tr class="odd">
<td align="left">symptom_tirednessFaintness</td>
<td align="left">2.28</td>
<td align="left">2.15 - 2.4</td>
<td align="left">0.025</td>
<td align="left">0.009</td>
<td align="left">1,058</td>
</tr>
</tbody>
</table>
</div>
<div id="icc-top-20-items-sorted-by-classroom-icc" class="section level2">
<h2>ICC top 20 items, sorted by classroom ICC</h2>
<pre class="r"><code>
vardatatable %&gt;% 
  select(Variable, `ICC class`, `ICC school`, n) %&gt;% 
  arrange(desc(`ICC class`)) %&gt;% slice(1:20) %&gt;% 
  as.tbl() %&gt;% 
  papaja::apa_table(caption = &quot;Intra-class correlations sorted by classroom ICC&quot;,
        format.args = list(digits = c(3, 0), margin = 2))</code></pre>
<caption>
(#tab:icc-school-class-sortbyclass)
</caption>
<caption>
<em>Intra-class correlations sorted by classroom ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">0.111</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.105</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">pafreqUsually</td>
<td align="left">0.094</td>
<td align="left">0.003</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">PA_intention_01</td>
<td align="left">0.088</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">sitLieAccelerometer</td>
<td align="left">0.086</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">pahrsUsually</td>
<td align="left">0.085</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.074</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_06</td>
<td align="left">0.072</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_07</td>
<td align="left">0.072</td>
<td align="left">0.005</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated_03</td>
<td align="left">0.072</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_intrinsic_01</td>
<td align="left">0.072</td>
<td align="left">0.005</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">paAccelerometer</td>
<td align="left">0.072</td>
<td align="left">0.096</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">PA_integrated</td>
<td align="left">0.071</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_01</td>
<td align="left">0.061</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_04</td>
<td align="left">0.059</td>
<td align="left">0.004</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated_01</td>
<td align="left">0.059</td>
<td align="left">0.004</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_03</td>
<td align="left">0.058</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_identified_03</td>
<td align="left">0.058</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">sitBreaks</td>
<td align="left">0.058</td>
<td align="left">0.085</td>
<td align="left">706</td>
</tr>
</tbody>
</table>
</div>
<div id="icc-top-20-items-sorted-by-school-icc" class="section level2">
<h2>ICC top 20 items, sorted by school ICC</h2>
<pre class="r"><code>
vardatatable %&gt;% select(Variable, `ICC class`, `ICC school`, n) %&gt;% 
  arrange(desc(`ICC school`)) %&gt;% 
  slice(1:20) %&gt;% 
  papaja::apa_table(caption = &quot;Intra-class correlations sorted by school ICC&quot;,
        format.args = list(digits = c(3, 0), margin = 2))</code></pre>
<caption>
(#tab:icc-school-class-sortbyschool)
</caption>
<caption>
<em>Intra-class correlations sorted by school ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">sitLieAccelerometer</td>
<td align="left">0.086</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">fatpct</td>
<td align="left">0.003</td>
<td align="left">0.123</td>
<td align="left">942</td>
</tr>
<tr class="odd">
<td align="left">paAccelerometer</td>
<td align="left">0.072</td>
<td align="left">0.096</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">sitBreaks</td>
<td align="left">0.058</td>
<td align="left">0.085</td>
<td align="left">706</td>
</tr>
<tr class="odd">
<td align="left">symptom</td>
<td align="left">0.023</td>
<td align="left">0.039</td>
<td align="left">1,084</td>
</tr>
<tr class="even">
<td align="left">SB_intention</td>
<td align="left">0.014</td>
<td align="left">0.035</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_02</td>
<td align="left">NA</td>
<td align="left">0.034</td>
<td align="left">1,056</td>
</tr>
<tr class="even">
<td align="left">symptom_neckShoulderPain</td>
<td align="left">0.011</td>
<td align="left">0.033</td>
<td align="left">1,047</td>
</tr>
<tr class="odd">
<td align="left">b5open</td>
<td align="left">0.010</td>
<td align="left">0.03</td>
<td align="left">1,068</td>
</tr>
<tr class="even">
<td align="left">SB_intention_03</td>
<td align="left">0.023</td>
<td align="left">0.027</td>
<td align="left">1,054</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_04</td>
<td align="left">0.028</td>
<td align="left">0.027</td>
<td align="left">1,055</td>
</tr>
<tr class="even">
<td align="left">symptom_headAche</td>
<td align="left">0.007</td>
<td align="left">0.027</td>
<td align="left">1,055</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_01</td>
<td align="left">NA</td>
<td align="left">0.025</td>
<td align="left">1,059</td>
</tr>
<tr class="even">
<td align="left">PA_opportunitiesReverseCoded_06</td>
<td align="left">NA</td>
<td align="left">0.024</td>
<td align="left">1,059</td>
</tr>
<tr class="odd">
<td align="left">symptom_tensionNervousness</td>
<td align="left">0.007</td>
<td align="left">0.024</td>
<td align="left">1,051</td>
</tr>
<tr class="even">
<td align="left">symptom_sleepDifficulty</td>
<td align="left">0.010</td>
<td align="left">0.023</td>
<td align="left">1,052</td>
</tr>
<tr class="odd">
<td align="left">symptom_stomachAche</td>
<td align="left">0.015</td>
<td align="left">0.023</td>
<td align="left">1,026</td>
</tr>
<tr class="even">
<td align="left">b5ext</td>
<td align="left">0.020</td>
<td align="left">0.022</td>
<td align="left">1,068</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities_01</td>
<td align="left">0.037</td>
<td align="left">0.02</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_03</td>
<td align="left">0.008</td>
<td align="left">0.018</td>
<td align="left">1,064</td>
</tr>
</tbody>
</table>
</div>
<div id="model-with-educational-track" class="section level2">
<h2>Model with educational track</h2>
<p>The model below is the same as the one above, except it adds educational track.</p>
<p>As before, we create a table with all variables, their means, CIs and ICCs.</p>
<pre class="r"><code>#library(sjstats)
#library(lme4)

names &lt;- df %&gt;% select(-id, -intervention, -group, -school, -girl, -track, -trackSchool, -contains(&quot;_T3&quot;), -contains(&quot;_diff&quot;)) %&gt;% names(.)

# Create empty soon-to-be-filled objects
m &lt;- NA
mean &lt;- NA
m_p &lt;- NA
ci_low &lt;- NA
ci_high &lt;- NA
ICC_group &lt;- NA
ICC_School &lt;- NA
nonmissings &lt;- NA
ICC_track &lt;- NA


## To test the code with a single variable:
# dftest &lt;- df #%&gt;% na.omit()
# m &lt;- lmer(sitLieAccelerometer_T1 ~ (1|school) + (1|group) + (1|track), data=df)
# mean &lt;- fixef(m)
# m_p &lt;- profile(m)
# ci_low &lt;- confint(m_p)[5]
# ci_high &lt;- confint(m_p)[10]
# ICC_group &lt;- icc(m)[1]
# ICC_School &lt;- icc(m)[2]
# nonmissings &lt;- length(m@resp$y)

# Loop over each variable name, extract statistics: 

# all participants  
for (i in names){
m &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + (1|track)&quot;), data=df)
mean[i] &lt;- lme4::fixef(m)
m_p &lt;- profile(m, which = &quot;beta_&quot;)
ci_low[i] &lt;- confint(m_p)[5]
ci_high[i] &lt;- confint(m_p)[10]
ICC_group[i] &lt;- sjstats::icc(m)[1]
ICC_School[i] &lt;- sjstats::icc(m)[3]
ICC_track[i] &lt;- sjstats::icc(m)[2]
nonmissings[i] &lt;- length(m@resp$y)
}
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

vardatatable_containing_edutrack &lt;- data_frame(
  Variable = stringr::str_sub(names(mean), end = -4), #remove &quot;_T1&quot; from names
  Mean = round(mean, 2), 
  CI95 = paste(round(ci_low, 2), &quot;-&quot;, round(ci_high, 2)), 
  &quot;ICC class&quot; =ifelse(round(ICC_group, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_group, 3)), 
  &quot;ICC school&quot; = ifelse(round(ICC_School, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_School, 3)),
  &quot;ICC educational track&quot; = ifelse(round(ICC_track, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_track, 3)),
  n = nonmissings) %&gt;% 
  dplyr::arrange(Variable) %&gt;% 
  filter(Variable != &quot;&quot;) #remove first row, which is empty

options(tibble.print_max = 15)</code></pre>
<div id="top-20-items-sorted-by-school" class="section level3">
<h3>Top 20 items, sorted by school</h3>
<pre class="r"><code>
vardatatable_containing_edutrack %&gt;% 
  select(Variable, `ICC educational track`, `ICC class`, `ICC school`, n) %&gt;% 
  arrange(desc(`ICC school`)) %&gt;% 
  top_n(20) %&gt;% 
  papaja::apa_table(caption = &quot;Intra-class correlations sorted by school ICC&quot;,
        format.args = list(digits = c(0), margin = 2))
## Selecting by n</code></pre>
<caption>
(#tab:icc-school-class-track-sortbyschool)
</caption>
<caption>
<em>Intra-class correlations sorted by school ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC educational track</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">0.054</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.012</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paminLastweek</td>
<td align="left">0.005</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.011</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated</td>
<td align="left">0.082</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.008</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">0.005</td>
<td align="left">0.006</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.071</td>
<td align="left">0.009</td>
<td align="left">0.006</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">pafreqUsually</td>
<td align="left">0.069</td>
<td align="left">0.023</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm</td>
<td align="left">0.052</td>
<td align="left">0.005</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsUsually</td>
<td align="left">0.051</td>
<td align="left">0.033</td>
<td align="left">0.004</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_inorm_01</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations</td>
<td align="left">0.024</td>
<td align="left">0.029</td>
<td align="left">0.003</td>
<td align="left">1,078</td>
</tr>
<tr class="even">
<td align="left">PA_actCop</td>
<td align="left">0.036</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actionplan</td>
<td align="left">0.031</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_01</td>
<td align="left">0.033</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_02</td>
<td align="left">0.018</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_03</td>
<td align="left">0.02</td>
<td align="left">0.021</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_04</td>
<td align="left">0.038</td>
<td align="left">0.008</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_controlled</td>
<td align="left">0.051</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copingplan</td>
<td align="left">0.034</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_01</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_02</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_03</td>
<td align="left">0.034</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_04</td>
<td align="left">0.033</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm_02</td>
<td align="left">0.023</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">0.044</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.064</td>
<td align="left">0.039</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_01</td>
<td align="left">0.061</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention_02</td>
<td align="left">0.064</td>
<td align="left">0.044</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected</td>
<td align="left">0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
<tr class="odd">
<td align="left">padaysLastweek</td>
<td align="left">0.04</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">0.036</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">paLastweek</td>
<td align="left">0.037</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">symptom</td>
<td align="left">0.066</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,084</td>
</tr>
</tbody>
</table>
</div>
<div id="top-20-items-sorted-by-classroom" class="section level3">
<h3>Top 20 items, sorted by classroom</h3>
<pre class="r"><code>
vardatatable_containing_edutrack %&gt;% select(Variable, `ICC educational track`, `ICC class`, `ICC school`, n) %&gt;% arrange(desc(`ICC class`)) %&gt;% top_n(20) %&gt;% papaja::apa_table(caption = &quot;Intra-class correlations sorted by classroom ICC&quot;,
        format.args = list(digits = c(0), margin = 2))
## Selecting by n</code></pre>
<caption>
(#tab:icc-school-class-track-sortbyclass)
</caption>
<caption>
<em>Intra-class correlations sorted by classroom ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC educational track</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">0.064</td>
<td align="left">0.044</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.064</td>
<td align="left">0.039</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">pahrsUsually</td>
<td align="left">0.051</td>
<td align="left">0.033</td>
<td align="left">0.004</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations</td>
<td align="left">0.024</td>
<td align="left">0.029</td>
<td align="left">0.003</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_01</td>
<td align="left">0.061</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pafreqUsually</td>
<td align="left">0.069</td>
<td align="left">0.023</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_03</td>
<td align="left">0.02</td>
<td align="left">0.021</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_02</td>
<td align="left">0.018</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actionplan</td>
<td align="left">0.031</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_02</td>
<td align="left">0.023</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">symptom</td>
<td align="left">0.066</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,084</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_03</td>
<td align="left">0.034</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_04</td>
<td align="left">0.033</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.071</td>
<td align="left">0.009</td>
<td align="left">0.006</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_04</td>
<td align="left">0.038</td>
<td align="left">0.008</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actCop</td>
<td align="left">0.036</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_01</td>
<td align="left">0.033</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">0.044</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_inorm</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm_01</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">padaysLastweek</td>
<td align="left">0.04</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">0.005</td>
<td align="left">0.006</td>
<td align="left">1,078</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm</td>
<td align="left">0.052</td>
<td align="left">0.005</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled</td>
<td align="left">0.051</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">0.036</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">paLastweek</td>
<td align="left">0.037</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">PA_copingplan</td>
<td align="left">0.034</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_01</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_02</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">0.054</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.012</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_integrated</td>
<td align="left">0.082</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.008</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected</td>
<td align="left">0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paminLastweek</td>
<td align="left">0.005</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.011</td>
<td align="left">1,082</td>
</tr>
</tbody>
</table>
</div>
<div id="top-20-items-sorted-by-educational-track" class="section level3">
<h3>Top 20 items, sorted by educational track</h3>
<pre class="r"><code>
vardatatable_containing_edutrack %&gt;% select(Variable, `ICC educational track`, `ICC class`, `ICC school`, n) %&gt;% arrange(desc(`ICC educational track`)) %&gt;% top_n(20) %&gt;% papaja::apa_table(caption = &quot;Intra-class correlations sorted by educational track ICC&quot;,
        format.args = list(digits = c(0), margin = 2))
## Selecting by n</code></pre>
<caption>
(#tab:icc-school-class-track-sortbytrack)
</caption>
<caption>
<em>Intra-class correlations sorted by educational track ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC educational track</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_integrated</td>
<td align="left">0.082</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.008</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">0.005</td>
<td align="left">0.006</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.071</td>
<td align="left">0.009</td>
<td align="left">0.006</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">pafreqUsually</td>
<td align="left">0.069</td>
<td align="left">0.023</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">symptom</td>
<td align="left">0.066</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,084</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.064</td>
<td align="left">0.039</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">0.064</td>
<td align="left">0.044</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention_01</td>
<td align="left">0.061</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">0.054</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.012</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm</td>
<td align="left">0.052</td>
<td align="left">0.005</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled</td>
<td align="left">0.051</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsUsually</td>
<td align="left">0.051</td>
<td align="left">0.033</td>
<td align="left">0.004</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">0.044</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">padaysLastweek</td>
<td align="left">0.04</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_04</td>
<td align="left">0.038</td>
<td align="left">0.008</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paLastweek</td>
<td align="left">0.037</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actCop</td>
<td align="left">0.036</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">0.036</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_copingplan</td>
<td align="left">0.034</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_03</td>
<td align="left">0.034</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_01</td>
<td align="left">0.033</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_04</td>
<td align="left">0.033</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actionplan</td>
<td align="left">0.031</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations</td>
<td align="left">0.024</td>
<td align="left">0.029</td>
<td align="left">0.003</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_02</td>
<td align="left">0.023</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_01</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_03</td>
<td align="left">0.02</td>
<td align="left">0.021</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_02</td>
<td align="left">0.018</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_02</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paminLastweek</td>
<td align="left">0.005</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.011</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected</td>
<td align="left">0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_inorm</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm_01</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
</tbody>
</table>
</div>
<div id="model-with-educational-track-only" class="section level3">
<h3>Model with educational track only</h3>
<pre class="r"><code>#library(sjstats)
#library(lme4)

names &lt;- df %&gt;% select(-id, -intervention, -group, -school, -girl, -track, -trackSchool, -contains(&quot;_T3&quot;), -contains(&quot;_diff&quot;)) %&gt;% names(.)

# Create empty soon-to-be-filled objects
m &lt;- NA
mean &lt;- NA
m_p &lt;- NA
ci_low &lt;- NA
ci_high &lt;- NA
ICC_group &lt;- NA
ICC_School &lt;- NA
nonmissings &lt;- NA
ICC_track &lt;- NA


## To test the code with a single variable:
# dftest &lt;- df #%&gt;% na.omit()
# m &lt;- lmer(sitLieAccelerometer_T1 ~ (1|school) + (1|group) + (1|track), data=df)
# mean &lt;- fixef(m)
# m_p &lt;- profile(m)
# ci_low &lt;- confint(m_p)[5]
# ci_high &lt;- confint(m_p)[10]
# ICC_group &lt;- icc(m)[1]
# ICC_School &lt;- icc(m)[2]
# nonmissings &lt;- length(m@resp$y)

# Loop over each variable name, extract statistics: 

# all participants  
for (i in names){
m &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + (1|track)&quot;), data=df)
mean[i] &lt;- lme4::fixef(m)
m_p &lt;- profile(m, which = &quot;beta_&quot;)
ci_low[i] &lt;- confint(m_p)[5]
ci_high[i] &lt;- confint(m_p)[10]
ICC_group[i] &lt;- sjstats::icc(m)[1]
ICC_School[i] &lt;- sjstats::icc(m)[3]
ICC_track[i] &lt;- sjstats::icc(m)[2]
nonmissings[i] &lt;- length(m@resp$y)
}
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

vardatatable_containing_edutrack &lt;- data_frame(
  Variable = stringr::str_sub(names(mean), end = -4), #remove &quot;_T1&quot; from names
  Mean = round(mean, 2), 
  CI95 = paste(round(ci_low, 2), &quot;-&quot;, round(ci_high, 2)), 
  &quot;ICC class&quot; =ifelse(round(ICC_group, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_group, 3)), 
  &quot;ICC school&quot; = ifelse(round(ICC_School, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_School, 3)),
  &quot;ICC educational track&quot; = ifelse(round(ICC_track, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_track, 3)),
  n = nonmissings) %&gt;% 
  dplyr::arrange(Variable) %&gt;% 
  filter(Variable != &quot;&quot;) #remove first row, which is empty

options(tibble.print_max = 15)</code></pre>
<p>Top 20 items, sorted by ICC educational track</p>
<pre class="r"><code>
vardatatable_containing_edutrack %&gt;% 
  select(Variable, `ICC educational track`, n) %&gt;% 
  arrange(desc(`ICC educational track`)) %&gt;% 
  top_n(20) %&gt;% 
  papaja::apa_table(caption = &quot;Intra-class correlations sorted by educational track ICC&quot;,
        format.args = list(digits = c(0), margin = 2))
## Selecting by n</code></pre>
<caption>
(#tab:icc-edu-track-only)
</caption>
<caption>
<em>Intra-class correlations sorted by educational track ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC educational track</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_integrated</td>
<td align="left">0.082</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.071</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">pafreqUsually</td>
<td align="left">0.069</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">symptom</td>
<td align="left">0.066</td>
<td align="left">1,084</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.064</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">0.064</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention_01</td>
<td align="left">0.061</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">0.054</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm</td>
<td align="left">0.052</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled</td>
<td align="left">0.051</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsUsually</td>
<td align="left">0.051</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">0.044</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">padaysLastweek</td>
<td align="left">0.04</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_04</td>
<td align="left">0.038</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paLastweek</td>
<td align="left">0.037</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actCop</td>
<td align="left">0.036</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">0.036</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_copingplan</td>
<td align="left">0.034</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_03</td>
<td align="left">0.034</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_01</td>
<td align="left">0.033</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_04</td>
<td align="left">0.033</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actionplan</td>
<td align="left">0.031</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations</td>
<td align="left">0.024</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_02</td>
<td align="left">0.023</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_01</td>
<td align="left">0.022</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_03</td>
<td align="left">0.02</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_02</td>
<td align="left">0.018</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_02</td>
<td align="left">0.015</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paminLastweek</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected</td>
<td align="left">0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_inorm</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm_01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="create-confidence-bounds-for-all-items-by-gender-and-intervention-allocation" class="section level2">
<h2>Create confidence bounds for all items by gender and intervention allocation</h2>
<p>These numbers are visualised with diamond plots later.</p>
<pre class="r"><code>names &lt;- df %&gt;% select(-id, -intervention, -group, -school, -girl, -track, -trackSchool, -contains(&quot;_T3&quot;), -contains(&quot;_diff&quot;)) %&gt;% names(.)

# Intercepts for boys; when boy is 1, girl is 0, but boy is a factor, so intercept is for boys even though boy is 1 for boys and 0 for girls.
m.boys &lt;- NA
mean.boys &lt;- NA
m_p.boys &lt;- NA
ci_low.boys &lt;- NA
ci_high.boys &lt;- NA
ICC_group.boys &lt;- NA
ICC_School.boys &lt;- NA
nonmissings.boys &lt;- NA

df.boys &lt;- df %&gt;% mutate(boy = factor(ifelse(girl == 1, 0, 1), levels = c(1, 0)))

for (i in names){
m.boys &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + boy&quot;), data=df.boys)
mean.boys[i] &lt;- lme4::fixef(m.boys)[1]
m_p.boys &lt;- profile(m.boys, which = &quot;beta_&quot;)
ci_low.boys[i] &lt;- confint(m_p.boys)[1, 1]
ci_high.boys[i] &lt;- confint(m_p.boys)[1, 2]
ICC_group.boys[i] &lt;- sjstats::icc(m.boys)[1]
ICC_School.boys[i] &lt;- sjstats::icc(m.boys)[2]
nonmissings.boys[i] &lt;- length(m.boys@resp$y)
}
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.boys, which = &quot;beta_&quot;): non-monotonic profile
## for (Intercept)
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in confint.thpr(m_p.boys): bad spline fit for (Intercept): falling
## back to linear interpolation

## Warning in confint.thpr(m_p.boys): bad spline fit for (Intercept): falling
## back to linear interpolation
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower =
## fitted@lower): convergence code 1 from bobyqa: bobyqa -- maximum number of
## function evaluations exceeded
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

cat(&quot;The labels are arranged such that intercept is not for girls:&quot;, labels(lme4::fixef(m.boys))[2] == &quot;boy0&quot;)
## The labels are arranged such that intercept is not for girls: TRUE

ci_boys &lt;- data.frame(ciLo = ci_low.boys, mean = mean.boys, ciHi = ci_high.boys)
diamondlabels &lt;- labels(ci_boys)[[1]]
ci_boys &lt;- data.frame(ci_boys, diamondlabels)

# Intercepts for girls; when boy is 1, girl is 0, but boy is a factor, so intercept is for girls even though girl is 1 for girls and 0 for boys.
m.girls &lt;- NA
mean.girls &lt;- NA
m_p.girls &lt;- NA
ci_low.girls &lt;- NA
ci_high.girls &lt;- NA
ICC_group.girls &lt;- NA
ICC_School.girls &lt;- NA
nonmissings.girls &lt;- NA

for (i in names){
m.girls &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + girl&quot;), data=df)
mean.girls[i] &lt;- lme4::fixef(m.girls)[1]
m_p.girls &lt;- profile(m.girls, which = &quot;beta_&quot;)
ci_low.girls[i] &lt;- confint(m_p.girls)[1, 1]
ci_high.girls[i] &lt;- confint(m_p.girls)[1, 2]
ICC_group.girls[i] &lt;- sjstats::icc(m.girls)[1]
ICC_School.girls[i] &lt;- sjstats::icc(m.girls)[2]
nonmissings.girls[i] &lt;- length(m.girls@resp$y)
}
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in optwrap(optimizer, devfun, x@theta, lower = x@lower, calc.derivs
## = TRUE, : convergence code 3 from bobyqa: bobyqa -- a trust region step
## failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.girls, which = &quot;beta_&quot;): non-monotonic profile
## for (Intercept)
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation

## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in optwrap(optimizer, devfun, x@theta, lower = x@lower, calc.derivs
## = TRUE, : convergence code 3 from bobyqa: bobyqa -- a trust region step
## failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.girls, which = &quot;beta_&quot;): non-monotonic profile
## for (Intercept)
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation

## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation

cat(&quot;The labels are arranged such that intercept is not for boys:&quot;, labels(lme4::fixef(m.girls))[2] == &quot;girl0&quot;)
## The labels are arranged such that intercept is not for boys: TRUE

ci_girls &lt;- data.frame(ciLo = ci_low.girls, mean = mean.girls, ciHi = ci_high.girls)
diamondlabels &lt;- labels(ci_girls)[[1]]
ci_girls &lt;- data.frame(ci_girls, diamondlabels)


# Intercepts for intervention
m.intervention &lt;- NA
mean.intervention &lt;- NA
m_p.intervention &lt;- NA
ci_low.intervention &lt;- NA
ci_high.intervention &lt;- NA
ICC_group.intervention &lt;- NA
ICC_School.intervention &lt;- NA
nonmissings.intervention &lt;- NA

## change &quot;intervention&quot; to be consistent regarding level order with &quot;girl&quot;.
df.intervention &lt;- df %&gt;% mutate(intervention = factor(intervention, levels = c(1, 0)))

for (i in names){
m.intervention &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + intervention&quot;), data=df.intervention)
mean.intervention[i] &lt;- lme4::fixef(m.intervention)[1]
m_p.intervention &lt;- profile(m.intervention, which = &quot;beta_&quot;)
ci_low.intervention[i] &lt;- confint(m_p.intervention)[1, 1]
ci_high.intervention[i] &lt;- confint(m_p.intervention)[1, 2]
ICC_group.intervention[i] &lt;- sjstats::icc(m.intervention)[1]
ICC_School.intervention[i] &lt;- sjstats::icc(m.intervention)[2]
nonmissings.intervention[i] &lt;- length(m.intervention@resp$y)
}
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in optwrap(optimizer, devfun, x@theta, lower = x@lower, calc.derivs
## = TRUE, : convergence code 3 from bobyqa: bobyqa -- a trust region step
## failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for intervention0
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for intervention0
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for intervention0
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation

cat(&quot;The labels are arranged such that intercept is not for control:&quot;, labels(lme4::fixef(m.intervention))[2] == &quot;intervention0&quot;)
## The labels are arranged such that intercept is not for control: TRUE

ci_intervention &lt;- data.frame(ciLo = ci_low.intervention, mean = mean.intervention, ciHi = ci_high.intervention)
diamondlabels &lt;- labels(ci_intervention)[[1]]
ci_intervention &lt;- data.frame(ci_intervention, diamondlabels)

# Intercepts for control

m.control &lt;- NA
mean.control &lt;- NA
m_p.control &lt;- NA
ci_low.control &lt;- NA
ci_high.control &lt;- NA
ICC_group.control &lt;- NA
ICC_School.control &lt;- NA
nonmissings.control &lt;- NA

df.control &lt;- df %&gt;% mutate(control = factor(ifelse(intervention == 1, 0, 1), levels = c(1, 0)))

for (i in names){
m.control &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + control&quot;), data=df.control)
mean.control[i] &lt;- lme4::fixef(m.control)[1]
m_p.control &lt;- profile(m.control, which = &quot;beta_&quot;)
ci_low.control[i] &lt;- confint(m_p.control)[1, 1]
ci_high.control[i] &lt;- confint(m_p.control)[1, 2]
ICC_group.control[i] &lt;- sjstats::icc(m.control)[1]
ICC_School.control[i] &lt;- sjstats::icc(m.control)[2]
nonmissings.control[i] &lt;- length(m.control@resp$y)
}
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for control0
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for control0
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for control0
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation

cat(&quot;The labels are arranged such that intercept is not for intervention:&quot;, labels(lme4::fixef(m.control))[2] == &quot;control0&quot;)
## The labels are arranged such that intercept is not for intervention: TRUE

ci_control &lt;- data.frame(ciLo = ci_low.control, mean = mean.control, ciHi = ci_high.control)
diamondlabels &lt;- labels(ci_control)[[1]]
ci_control &lt;- data.frame(ci_control, diamondlabels)

# Same ICC results you&#39;d get with e.g.:
# m1 &lt;- as.data.frame(VarCorr(m))
# m1$vcov[1] / (m1$vcov[1] + m1$vcov[3])

# Or from broom:
# tidy(m)$estimate[2]^2 / (tidy(m)$estimate[2]^2 + tidy(m)$estimate[4]^2)

# Or from sjstats:
# sum(get_re_var(m)) / (sum(get_re_var(m)) + get_re_var(m, &quot;sigma_2&quot;))
</code></pre>
</div>
</div>
<div id="descriptive-tables" class="section level1">
<h1>Descriptive tables</h1>
<div id="prepare-data" class="section level2">
<h2>prepare data</h2>
<pre class="r"><code>
demographics &lt;- lmi %&gt;% dplyr::select(id = ID,
birthYear = Kys0004.1,
intervention = ryhma,
school = Aineisto.1,
girl = Kys0013.1,
ethnicity = Kys0005.1,
studyYear = Kys0014.1) %&gt;% 
  mutate(age = 2016 - birthYear,
         intervention = ifelse(intervention == 1, 1, 0),
         intervention = as.numeric(intervention),
         girl = ifelse(girl == 2, 1, 0),
          girl = as.numeric(girl, levels = c(&quot;1&quot;, &quot;0&quot;)),
         school = factor(school, levels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;)),
         bornInFinland = as.numeric(ifelse(ethnicity == 1, 1, 0)),
         studyYear = ifelse(studyYear == 0, NA, studyYear)) # Remove &quot;other&quot; from study year

# Insert track variable with those who answered &quot;other&quot; with one of the actual category labels given the appropriate category:
Track &lt;- lmi %&gt;% select(Kys0016.1, Kys0017.1) %&gt;% mutate(
  Kys0016.1 = ifelse(Kys0017.1 == &quot;Merkonomi&quot; | Kys0017.1 == &quot;merkonomi&quot;, 3,
                  ifelse(Kys0017.1 == &quot;Datanomi&quot; | Kys0017.1 == &quot;datanomi&quot;, 2, Kys0016.1)),
  Track = factor(Kys0016.1, # Fix track labels first
                     levels = c(0, 1, 2, 3, 4),
                     labels = c(&quot;Other&quot;, &quot;Business IT&quot;, &quot;Business Admin&quot;, &quot;HRC&quot;, &quot;Nursing&quot;))) %&gt;% 
  select(-Kys0016.1, -Kys0017.1)

demographics &lt;- bind_cols(demographics, Track)</code></pre>
</div>
<div id="create-demographic-tables" class="section level2">
<h2>Create demographic tables</h2>
<div id="by-educational-track" class="section level3">
<h3>By educational track</h3>
<pre class="r"><code>demotable &lt;- demographics %&gt;% 
  group_by(Track) %&gt;% 
  summarise(&quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(Track)) 
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf

demotable_total &lt;- demographics %&gt;% 
  summarise(&quot;Track&quot; = &quot;Full sample&quot;,
            &quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n())

demotable &lt;- bind_rows(demotable, demotable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

demotable &lt;- demotable %&gt;% tidyr::gather(Variable, val, 2:ncol(demotable)) %&gt;% tidyr::spread(Track, val)

# For some reason, sum of n&#39;s of all tracks is 1084.

papaja::apa_table(demotable, caption = &quot;Baseline demographics of educational tracks&quot;, digits = c(0, 1, 1, 1, 1, 1, 0))</code></pre>
<caption>
(#tab:demographics-table-track)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Business Admin</th>
<th align="left">Business IT</th>
<th align="left">Full sample</th>
<th align="left">HRC</th>
<th align="left">Nursing</th>
<th align="left">Other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">% born in Finland</td>
<td align="left">87.1</td>
<td align="left">87.9</td>
<td align="left">83.1</td>
<td align="left">88.2</td>
<td align="left">80</td>
<td align="left">54.2</td>
</tr>
<tr class="even">
<td align="left">% girl</td>
<td align="left">39</td>
<td align="left">16</td>
<td align="left">56.5</td>
<td align="left">60.6</td>
<td align="left">82.3</td>
<td align="left">70.8</td>
</tr>
<tr class="odd">
<td align="left">% intervention</td>
<td align="left">53.5</td>
<td align="left">46.6</td>
<td align="left">53.6</td>
<td align="left">31.5</td>
<td align="left">68.9</td>
<td align="left">41.7</td>
</tr>
<tr class="even">
<td align="left">Mean age (range)</td>
<td align="left">19 (17-36)</td>
<td align="left">19.5 (18-44)</td>
<td align="left">19.3 (17-50)</td>
<td align="left">18.5 (17-27)</td>
<td align="left">19.8 (17-50)</td>
<td align="left">21 (17-45)</td>
</tr>
<tr class="odd">
<td align="left">Mean study year (sd)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.9 (0.7)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">2 (1.4)</td>
</tr>
<tr class="even">
<td align="left">n</td>
<td align="left">282</td>
<td align="left">163</td>
<td align="left">1165</td>
<td align="left">213</td>
<td align="left">402</td>
<td align="left">24</td>
</tr>
</tbody>
</table>
</div>
<div id="by-gender" class="section level3">
<h3>By gender</h3>
<pre class="r"><code>demographics$Girl &lt;- factor(demographics$girl)

demotable &lt;- demographics %&gt;% 
  group_by(Girl) %&gt;% 
  summarise(&quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(Girl)) 
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf

demotable_total &lt;- demographics %&gt;% 
  summarise(&quot;Girl&quot; = &quot;Full sample&quot;,
            &quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n())

demotable &lt;- bind_rows(demotable, demotable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

demotable &lt;- demotable %&gt;% tidyr::gather(Variable, val, 2:ncol(demotable)) %&gt;% tidyr::spread(Girl, val)

names(demotable) &lt;- c(&quot;&quot;, &quot;Boy&quot;, &quot;Girl&quot;, &quot;Full sample&quot;)

# For some reason, sum of n&#39;s of all tracks is 1084.

papaja::apa_table(demotable, caption = &quot;Baseline demographics of educational tracks&quot;, digits = c(0, 1, 1, 1, 1, 0))</code></pre>
<caption>
(#tab:demographics-table-gender)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">Boy</th>
<th align="left">Girl</th>
<th align="left">Full sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>% born in Finland</td>
<td align="left">88.2</td>
<td align="left">80.1</td>
<td align="left">83.1</td>
</tr>
<tr class="even">
<td>% intervention</td>
<td align="left">50.5</td>
<td align="left">56</td>
<td align="left">53.6</td>
</tr>
<tr class="odd">
<td>Mean age (range)</td>
<td align="left">19.1 (17-36)</td>
<td align="left">19.5 (17-50)</td>
<td align="left">19.3 (17-50)</td>
</tr>
<tr class="even">
<td>Mean study year (sd)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.8)</td>
<td align="left">1.7 (0.9)</td>
</tr>
<tr class="odd">
<td>n</td>
<td align="left">471</td>
<td align="left">613</td>
<td align="left">1165</td>
</tr>
</tbody>
</table>
</div>
<div id="by-intervention-participation" class="section level3">
<h3>By intervention participation</h3>
<pre class="r"><code>demographics$intervention &lt;- factor(demographics$intervention)
demographics$girl &lt;- as.numeric(demographics$girl)

demotable &lt;- demographics %&gt;% 
  group_by(intervention) %&gt;% 
  summarise(&quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(intervention)) 
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf

demotable_total &lt;- demographics %&gt;% 
  summarise(&quot;intervention&quot; = &quot;Full sample&quot;,
            &quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n())

demotable &lt;- bind_rows(demotable, demotable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

demotable &lt;- demotable %&gt;% tidyr::gather(Variable, val, 2:ncol(demotable)) %&gt;% tidyr::spread(intervention, val)

names(demotable) &lt;- c(&quot;&quot;, &quot;Control&quot;, &quot;Intervention&quot;, &quot;Full sample&quot;)

# For some reason, sum of n&#39;s of all tracks is 1084.

papaja::apa_table(demotable, caption = &quot;Baseline demographics of educational tracks&quot;, digits = c(0, 1, 1, 1, 1, 0))</code></pre>
<caption>
(#tab:demographics-table-intervention)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">Control</th>
<th align="left">Intervention</th>
<th align="left">Full sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>% born in Finland</td>
<td align="left">87.5</td>
<td align="left">79.6</td>
<td align="left">83.1</td>
</tr>
<tr class="even">
<td>% girl</td>
<td align="left">53.7</td>
<td align="left">59</td>
<td align="left">56.5</td>
</tr>
<tr class="odd">
<td>Mean age (range)</td>
<td align="left">19 (17-39)</td>
<td align="left">19.6 (17-50)</td>
<td align="left">19.3 (17-50)</td>
</tr>
<tr class="even">
<td>Mean study year (sd)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
</tr>
<tr class="odd">
<td>n</td>
<td align="left">503</td>
<td align="left">581</td>
<td align="left">1165</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="create-outcome-tables" class="section level2">
<h2>Create outcome tables</h2>
<pre class="r"><code>
outtable_track &lt;- df %&gt;%
  select(paAccelerometer_T1, sitLieAccelerometer_T1, sitBreaks_T1, # Main outcomes 
          PA_actionplan_T1,
          PA_copingplan_T1,
          PA_agrbct_T1,
          PA_frqbct_T1,
          PA_amotivation_T1,
          PA_autonomous_T1,
          PA_controlled_T1,
          PA_goal_T1,
          PA_inorm_T1,
          PA_dnorm_T1,
          PA_intention_T1,
          PA_outcomeExpectations_T1,
          PA_opportunities_T1,
          PA_pbc_T1,
          PA_selfefficacy_T1,
          SB_dnorm_T1,
          SB_inorm_T1,
          SB_intention_T1,
          SB_outcomeExpectations_T1,
          SB_sePbc_T1,
         track, girl, intervention) %&gt;% 
  group_by(track) %&gt;% 
  summarise(
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(track)) %&gt;% 
  filter(track != &quot;Other&quot;)

outtable_intervention &lt;- df %&gt;%
  select(paAccelerometer_T1, sitLieAccelerometer_T1, sitBreaks_T1, # Main outcomes 
          PA_actionplan_T1,
          PA_copingplan_T1,
          PA_agrbct_T1,
          PA_frqbct_T1,
          PA_amotivation_T1,
          PA_autonomous_T1,
          PA_controlled_T1,
          PA_goal_T1,
          PA_inorm_T1,
          PA_dnorm_T1,
          PA_intention_T1,
          PA_outcomeExpectations_T1,
          PA_opportunities_T1,
          PA_pbc_T1,
          PA_selfefficacy_T1,
          SB_dnorm_T1,
          SB_inorm_T1,
          SB_intention_T1,
          SB_outcomeExpectations_T1,
          SB_sePbc_T1,
         track, girl, intervention) %&gt;% 
  group_by(intervention) %&gt;% 
  summarise(
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n()) %&gt;% 
  filter(complete.cases(.))

outtable_girl &lt;- df %&gt;%
  select(paAccelerometer_T1, sitLieAccelerometer_T1, sitBreaks_T1, # Main outcomes 
          PA_actionplan_T1,
          PA_copingplan_T1,
          PA_agrbct_T1,
          PA_frqbct_T1,
          PA_amotivation_T1,
          PA_autonomous_T1,
          PA_controlled_T1,
          PA_goal_T1,
          PA_inorm_T1,
          PA_dnorm_T1,
          PA_intention_T1,
          PA_outcomeExpectations_T1,
          PA_opportunities_T1,
          PA_pbc_T1,
          PA_selfefficacy_T1,
          SB_dnorm_T1,
          SB_inorm_T1,
          SB_intention_T1,
          SB_outcomeExpectations_T1,
          SB_sePbc_T1,
         track, girl, intervention) %&gt;% 
  group_by(girl) %&gt;% 
  summarise(
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n()) %&gt;% 
  filter(complete.cases(.))

outtable_total &lt;- df %&gt;% 
  summarise(&#39;girl&#39; = &quot;Full sample&quot;,
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n())



# Transpose each table
outtable_track &lt;- outtable_track %&gt;% tidyr::gather(Variable, val, 2:ncol(.)) %&gt;% tidyr::spread(track, val)

outtable_intervention &lt;- outtable_intervention %&gt;% tidyr::gather(Variable, val, 2:ncol(.)) %&gt;% tidyr::spread(intervention, val)
names(outtable_intervention) &lt;- c(&quot;Variable&quot;, &quot;Control&quot;, &quot;Intervention&quot;)

## In the last table, have a column for total before transposing
outtable_girl &lt;- bind_rows(outtable_girl, outtable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector
outtable_girl &lt;- outtable_girl %&gt;% tidyr::gather(Variable, val, 2:ncol(.)) %&gt;% tidyr::spread(girl, val)
names(outtable_girl) &lt;- c(&quot;Variable&quot;, &quot;Boy&quot;, &quot;Girl&quot;, &quot;Full sample&quot;)

# Are all variables the same?
identical(outtable_track$Variable, outtable_girl$Variable)</code></pre>
<p>[1] TRUE</p>
<pre class="r"><code>identical(outtable_track$Variable, outtable_intervention$Variable)</code></pre>
<p>[1] TRUE</p>
<pre class="r"><code>
# Create large table with all variables
outtable_mega &lt;- bind_cols(outtable_track, outtable_intervention, outtable_girl) %&gt;% 
  select(-Variable1, -Variable2) 

# Move n to be the first row
out1 &lt;- outtable_mega %&gt;% filter(Variable == &quot;n&quot;)
out2 &lt;- outtable_mega %&gt;% filter(Variable != &quot;n&quot;)
outtable_mega &lt;- bind_rows(out1, out2)

# Fix names: leave first blank, have the rest as they were
names(outtable_mega) &lt;- c(&quot;&quot;, names(outtable_mega)[2:(length(names(outtable_mega)))])

papaja::apa_table(outtable_mega, caption = &quot;Baseline demographics of educational tracks&quot;)</code></pre>
<caption>
(#tab:outcome-table)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">Business IT</th>
<th align="left">Business Admin</th>
<th align="left">HRC</th>
<th align="left">Nursing</th>
<th align="left">Control</th>
<th align="left">Intervention</th>
<th align="left">Boy</th>
<th align="left">Girl</th>
<th align="left">Full sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n</td>
<td align="left">163</td>
<td align="left">282</td>
<td align="left">213</td>
<td align="left">402</td>
<td align="left">503</td>
<td align="left">581</td>
<td align="left">471</td>
<td align="left">613</td>
<td align="left">1165</td>
</tr>
<tr class="even">
<td>Mean daily breaks in sitting</td>
<td align="left">20 (9)</td>
<td align="left">27.5 (10)</td>
<td align="left">27.5 (9.6)</td>
<td align="left">31.7 (11.3)</td>
<td align="left">27.2 (10.4)</td>
<td align="left">29 (11.6)</td>
<td align="left">23.4 (9.5)</td>
<td align="left">31.3 (11)</td>
<td align="left">28.2 (11.1)</td>
</tr>
<tr class="odd">
<td>Mean daily minutes spent sitting or lying down</td>
<td align="left">652.8 (86.3)</td>
<td align="left">586.8 (93)</td>
<td align="left">557.8 (101.2)</td>
<td align="left">554.4 (82.1)</td>
<td align="left">568.5 (100.9)</td>
<td align="left">585.9 (92.7)</td>
<td align="left">612.5 (95.6)</td>
<td align="left">554.9 (90.9)</td>
<td align="left">578.2 (97.2)</td>
</tr>
<tr class="even">
<td>Mean daily MVPA minutes</td>
<td align="left">141.3 (51.6)</td>
<td align="left">179.6 (48.4)</td>
<td align="left">183.1 (52.2)</td>
<td align="left">201.2 (49.2)</td>
<td align="left">179.5 (52)</td>
<td align="left">187.3 (55.1)</td>
<td align="left">173.5 (59.4)</td>
<td align="left">190.4 (48.6)</td>
<td align="left">183.8 (53.8)</td>
</tr>
<tr class="odd">
<td>PA action planning</td>
<td align="left">2.4 (1.1)</td>
<td align="left">2.9 (0.9)</td>
<td align="left">2.8 (0.9)</td>
<td align="left">2.8 (0.9)</td>
<td align="left">2.8 (1)</td>
<td align="left">2.7 (0.9)</td>
<td align="left">2.8 (1)</td>
<td align="left">2.7 (0.9)</td>
<td align="left">2.8 (0.9)</td>
</tr>
<tr class="even">
<td>PA agreement-BCTs</td>
<td align="left">2.6 (1.3)</td>
<td align="left">3.5 (1.2)</td>
<td align="left">3.1 (1.3)</td>
<td align="left">3 (1.3)</td>
<td align="left">3.2 (1.3)</td>
<td align="left">3 (1.3)</td>
<td align="left">3.1 (1.4)</td>
<td align="left">3.1 (1.3)</td>
<td align="left">3.1 (1.3)</td>
</tr>
<tr class="odd">
<td>PA amotivation</td>
<td align="left">1.8 (1)</td>
<td align="left">1.5 (0.8)</td>
<td align="left">1.5 (0.8)</td>
<td align="left">1.4 (0.7)</td>
<td align="left">1.6 (0.8)</td>
<td align="left">1.5 (0.8)</td>
<td align="left">1.6 (0.9)</td>
<td align="left">1.5 (0.7)</td>
<td align="left">1.5 (0.8)</td>
</tr>
<tr class="even">
<td>PA autonomous regulation</td>
<td align="left">2.9 (1.1)</td>
<td align="left">3.6 (1)</td>
<td align="left">3.4 (1.1)</td>
<td align="left">3.5 (1)</td>
<td align="left">3.5 (1)</td>
<td align="left">3.4 (1.1)</td>
<td align="left">3.5 (1.1)</td>
<td align="left">3.4 (1)</td>
<td align="left">3.4 (1.1)</td>
</tr>
<tr class="odd">
<td>PA controlled regulation</td>
<td align="left">1.9 (0.8)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.8 (0.9)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.9 (0.9)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.9 (0.8)</td>
<td align="left">1.8 (0.8)</td>
</tr>
<tr class="even">
<td>PA coping planning</td>
<td align="left">2.2 (0.9)</td>
<td align="left">2.7 (0.8)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.6 (0.9)</td>
<td align="left">2.5 (0.8)</td>
<td align="left">2.5 (0.9)</td>
</tr>
<tr class="odd">
<td>PA descriptive norm</td>
<td align="left">3.8 (1.6)</td>
<td align="left">4.8 (1.5)</td>
<td align="left">4.5 (1.5)</td>
<td align="left">4.2 (1.6)</td>
<td align="left">4.5 (1.6)</td>
<td align="left">4.3 (1.6)</td>
<td align="left">4.5 (1.6)</td>
<td align="left">4.3 (1.6)</td>
<td align="left">4.4 (1.6)</td>
</tr>
<tr class="even">
<td>PA frequency-BCTs</td>
<td align="left">2.2 (1.1)</td>
<td align="left">2.8 (1.2)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.6 (1.1)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.6 (1.2)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.5 (1.1)</td>
</tr>
<tr class="odd">
<td>PA injunctive norm</td>
<td align="left">4.7 (2)</td>
<td align="left">4.8 (2)</td>
<td align="left">4.7 (2)</td>
<td align="left">4.5 (2)</td>
<td align="left">4.8 (2)</td>
<td align="left">4.5 (2)</td>
<td align="left">4.8 (2)</td>
<td align="left">4.6 (2)</td>
<td align="left">4.6 (2)</td>
</tr>
<tr class="even">
<td>PA intention</td>
<td align="left">4.3 (2.1)</td>
<td align="left">5.7 (1.7)</td>
<td align="left">5.5 (1.8)</td>
<td align="left">5.5 (1.7)</td>
<td align="left">5.4 (1.9)</td>
<td align="left">5.4 (1.8)</td>
<td align="left">5.3 (1.9)</td>
<td align="left">5.4 (1.8)</td>
<td align="left">5.4 (1.8)</td>
</tr>
<tr class="odd">
<td>PA opportunities</td>
<td align="left">5.1 (0.9)</td>
<td align="left">5.2 (1)</td>
<td align="left">5.1 (0.9)</td>
<td align="left">5.1 (1)</td>
<td align="left">5.2 (0.9)</td>
<td align="left">5.1 (1)</td>
<td align="left">5.2 (0.9)</td>
<td align="left">5.1 (1)</td>
<td align="left">5.1 (0.9)</td>
</tr>
<tr class="even">
<td>PA outcome expectations</td>
<td align="left">4.3 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.7 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.5 (0.9)</td>
<td align="left">4.7 (0.9)</td>
<td align="left">4.6 (0.9)</td>
</tr>
<tr class="odd">
<td>PA perceived behavioural control</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.5 (1.2)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.5 (1.2)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
</tr>
<tr class="even">
<td>PA self-efficacy</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.4 (1.4)</td>
<td align="left">5.1 (1.2)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.1 (1.3)</td>
<td align="left">5.2 (1.3)</td>
</tr>
<tr class="odd">
<td>SB descriptive norm</td>
<td align="left">2.8 (1.5)</td>
<td align="left">3.2 (1.4)</td>
<td align="left">3.4 (1.4)</td>
<td align="left">3.4 (1.5)</td>
<td align="left">3.3 (1.4)</td>
<td align="left">3.2 (1.5)</td>
<td align="left">3.3 (1.5)</td>
<td align="left">3.2 (1.4)</td>
<td align="left">3.2 (1.5)</td>
</tr>
<tr class="even">
<td>SB injunctive norm</td>
<td align="left">4 (1.1)</td>
<td align="left">3.8 (1.3)</td>
<td align="left">4 (1.2)</td>
<td align="left">4.1 (1.3)</td>
<td align="left">4.1 (1.2)</td>
<td align="left">3.9 (1.3)</td>
<td align="left">4 (1.2)</td>
<td align="left">4 (1.3)</td>
<td align="left">4 (1.3)</td>
</tr>
<tr class="odd">
<td>SB intention</td>
<td align="left">3 (1.6)</td>
<td align="left">3.6 (1.5)</td>
<td align="left">3.7 (1.6)</td>
<td align="left">4 (1.6)</td>
<td align="left">3.7 (1.6)</td>
<td align="left">3.7 (1.6)</td>
<td align="left">3.5 (1.7)</td>
<td align="left">3.9 (1.6)</td>
<td align="left">3.7 (1.6)</td>
</tr>
<tr class="even">
<td>SB outcome expectations</td>
<td align="left">4.1 (1.1)</td>
<td align="left">4.4 (1)</td>
<td align="left">4.4 (1)</td>
<td align="left">4.5 (1)</td>
<td align="left">4.4 (1)</td>
<td align="left">4.4 (1.1)</td>
<td align="left">4.3 (1.1)</td>
<td align="left">4.5 (1)</td>
<td align="left">4.4 (1)</td>
</tr>
<tr class="odd">
<td>SB self-efficacy &amp; perceived behavioural control</td>
<td align="left">5 (1.3)</td>
<td align="left">4.9 (1.2)</td>
<td align="left">5.1 (1.2)</td>
<td align="left">4.9 (1.3)</td>
<td align="left">5.1 (1.2)</td>
<td align="left">4.9 (1.3)</td>
<td align="left">5 (1.3)</td>
<td align="left">4.9 (1.2)</td>
<td align="left">4.9 (1.3)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="pa-psychosocial-determinants-self-report-scales-t1" class="section level1">
<h1>PA psychosocial determinants: self report scales T1</h1>
<pre class="r"><code>PA_ci_girls &lt;- ci_girls %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

PA_ci_boys &lt;- ci_boys %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

PA_ci_intervention &lt;- ci_intervention %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

PA_ci_control &lt;- ci_control %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

ICClabels &lt;- vardatatable_containing_edutrack %&gt;% filter(Variable %in% PA_ci_control$diamondlabels)

library(ggplot2)
plot1 &lt;- userfriendlyscience::diamondPlot(PA_ci_girls, color = &#39;green&#39;, alpha=.3, yLabels = PA_ci_girls$diamondlabels, fixedSize = 0.3, xlab = NULL) +
  userfriendlyscience::diamondPlot(PA_ci_boys, returnLayerOnly = TRUE, color=&#39;blue&#39;, alpha=.3, fixedSize = 0.3) +
  scale_x_continuous(limits = c(1, 7), breaks = 1:7)

plot2 &lt;- userfriendlyscience::diamondPlot(PA_ci_intervention, color = &#39;red&#39;, alpha=.3, yLabels = c(rep(&quot;&quot;, length(PA_ci_girls$diamondlabels))), fixedSize = 0.3, xlab = NULL, ylab = NULL) +
  userfriendlyscience::diamondPlot(PA_ci_control, returnLayerOnly = TRUE, color=&#39;black&#39;, alpha=.3, fixedSize = 0.3) +
  scale_x_continuous(limits = c(1, 7), breaks = 1:7)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-6-1.png" width="2100" /></p>
<pre class="r"><code>
# dat2 &lt;- data.frame(ciLo = c(3, 2), mean = c(4, 2.5), ciHi = c(6, 3));
# userfriendlyscience::diamondPlot(dat1, color = &#39;blue&#39;, alpha=.3, yLabels = dat1$diamondlabels) +
# userfriendlyscience::diamondPlot(dat2, returnLayerOnly = TRUE, color=&#39;red&#39;, alpha=.3)
 </code></pre>
<p>Note: action and coping planning on a scale from 1 to 4.</p>
</div>
<div id="visualising-random-effects-using-full-posterior-under-construction" class="section level1">
<h1>Visualising random effects using full posterior (UNDER CONSTRUCTION)</h1>
<div id="using-rstanarm" class="section level2">
<h2>Using rstanarm</h2>
<p>Plot below shows credible intervals deviations</p>
<pre class="r"><code>library(rstanarm)
# grep(&quot;PA_&quot;, names(df), value = TRUE)

# Centre the variable:
df &lt;- df %&gt;% mutate(paAccelerometer_T1_centred = paAccelerometer_T1 - mean(paAccelerometer_T1, na.rm = TRUE))

m_1 &lt;- stan_glmer(paAccelerometer_T1_centred ~ (1 | group), data = df, chains = 2, iter = 2000) 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1).
## 
## Gradient evaluation took 0 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 2.011 seconds (Warm-up)
##                1.311 seconds (Sampling)
##                3.322 seconds (Total)
## 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2).
## 
## Gradient evaluation took 0 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 1.581 seconds (Warm-up)
##                1.019 seconds (Sampling)
##                2.6 seconds (Total)
pt &lt;- ranef(m_1) 
posteriors &lt;- data.frame(posterior_interval(m_1, prob = 0.90)) 
school_int &lt;- posteriors[-c(1, nrow(posteriors)-1, nrow(posteriors)),] #remove intercept and sigma parameters, leaving only class intervals 

# This not needed any more:
# groupmeans &lt;- df %&gt;% select(paAccelerometer_T1, group) %&gt;% group_by(group) %&gt;% 
#   summarise(mean = mean(paAccelerometer_T1, na.rm = T)) %&gt;% filter(complete.cases(.))

dat_plt &lt;- data.frame(pt$group, school_int) 
colnames(dat_plt) &lt;- c(&quot;pt&quot;, &quot;low&quot;, &quot;up&quot;) 
dat_plt &lt;- dat_plt %&gt;% arrange(pt) 
dat_plt$index &lt;- 1:nrow(dat_plt) 
dat_plt %&gt;% ggplot(aes(x = index, y = pt)) + geom_errorbar(aes(ymin = low, ymax = up)) + geom_point(size = 4, shape = 18) + geom_point(size = 2.5, shape = 18, color = &quot;white&quot;) + theme_bw()</code></pre>
<p><img src="baseline-supplement_files/figure-html/randeff-plot-rstanarm-1.png" width="2100" /></p>
</div>
<div id="using-brms-and-diamondplot" class="section level2">
<h2>Using brms and diamondPlot</h2>
<p>Set Rtools folder, if not in C:/Rtools/:</p>
<pre class="r"><code># For some reason, having BINPREF in .Renviron doesn&#39;t work and I keep needing this:
Sys.setenv(&quot;BINPREF&quot; = &quot;C:/HYApp/Rtools3.4/mingw_$(WIN)/bin/&quot;)</code></pre>
<pre class="r"><code>
library(brms)

# Centre the variable:
df &lt;- df %&gt;% mutate(paAccelerometer_T1_centred = 
                      paAccelerometer_T1 - mean(paAccelerometer_T1, na.rm = TRUE))

m_1 &lt;- brms::bf(paAccelerometer_T1_centred ~ (1 | group)) 
get_prior(m_1, data = df)

fit_1 &lt;- brms::brm(m_1, df)

pt &lt;- brms::ranef(fit_1, robust = TRUE) %&gt;% 
  data.frame %&gt;% 
  select(credintLow = group.2.5.ile.Intercept,
         intercept = group.Estimate.Intercept, 
         credintHigh = group.97.5.ile.Intercept) %&gt;% 
  arrange(intercept)


plot1 &lt;- userfriendlyscience::diamondPlot(pt, color = &#39;green&#39;, alpha=.3, yLabels = 1:58, fixedSize = 0.3, xlab = NULL) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average MVPA&quot;, y = &quot;Group&quot;)


df %&gt;% ggplot(aes(x = group, y = paAccelerometer_T1_centred)) +
  userfriendlyscience::diamondPlot(pt, color = &#39;green&#39;, alpha=.3, yLabels = 1:58, fixedSize = 0.3, xlab = NULL, returnLayerOnly = TRUE) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average MVPA&quot;, y = &quot;Group&quot;)
   
forest(fit_1)</code></pre>
</div>
<div id="random-effects-in-autonomous-motivation" class="section level2">
<h2>Random effects in autonomous motivation</h2>
<pre class="r"><code>
# Centre the variable:
df &lt;- df %&gt;% mutate(PA_autonomous_T1_centred = PA_autonomous_T1 - mean(PA_autonomous_T1, na.rm = TRUE))

m_1 &lt;- brms::bf(PA_autonomous_T1_centred ~ (1 | group)) 
get_prior(m_1, data = df)
## Warning: Rows containing NAs were excluded from the model
##                    prior     class      coef group resp dpar nlpar bound
## 1 student_t(3, 0.03, 10) Intercept                                      
## 2    student_t(3, 0, 10)        sd                                      
## 3                               sd           group                      
## 4                               sd Intercept group                      
## 5    student_t(3, 0, 10)     sigma

fit_1 &lt;- brms::brm(m_1, df)
## Warning: Rows containing NAs were excluded from the model
## Compiling the C++ model
## Warning: running command &#39;C:/PROGRA~1/R/R-34~1.3/bin/x64/R CMD SHLIB
## file2f5446917dd0.cpp 2&gt; file2f5446917dd0.cpp.err.txt&#39; had status 1
## Error in compileCode(f, code, language = language, verbose = verbose): Compilation ERROR, function(s)/method(s) not created! C:/Rtools/mingw_64/bin/g++: not found
## make: *** [file2f5446917dd0.o] Error 127
## Warning message:
## running command &#39;make -f &quot;C:/PROGRA~1/R/R-34~1.3/etc/x64/Makeconf&quot; -f &quot;C:/PROGRA~1/R/R-34~1.3/share/make/winshlib.mk&quot; -f &quot;//ATKK/home/h/hema/Documents/.R/Makevars&quot; SHLIB_LDFLAGS=&#39;$(SHLIB_CXXLDFLAGS)&#39; SHLIB_LD=&#39;$(SHLIB_CXXLD)&#39; SHLIB=&quot;file2f5446917dd0.dll&quot; WIN=64 TCLBIN=64 OBJECTS=&quot;file2f5446917dd0.o&quot;&#39; had status 2

pt &lt;- brms::ranef(fit_1, robust = TRUE) %&gt;% 
  data.frame %&gt;% 
  select(credintLow = group.2.5.ile.Intercept,
         intercept = group.Estimate.Intercept, 
         credintHigh = group.97.5.ile.Intercept) %&gt;% 
  arrange(intercept)
## Error in brms::ranef(fit_1, robust = TRUE): object &#39;fit_1&#39; not found


plot1 &lt;- userfriendlyscience::diamondPlot(pt, color = &#39;blue&#39;, alpha=.3, yLabels = 1:59, fixedSize = 0.3, xlab = NULL) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average motivation&quot;, y = &quot;Group&quot;)
## Error in 1:nrow(data): argument of length 0


df %&gt;% ggplot(aes(x = group, y = PA_autonomous_T1_centred)) +
  userfriendlyscience::diamondPlot(pt, color = &#39;blue&#39;, alpha=.3, yLabels = 1:59, fixedSize = 0.3, xlab = NULL, returnLayerOnly = TRUE) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average motivation&quot;, y = &quot;Group&quot;)
## Error in 1:nrow(data): argument of length 0</code></pre>
</div>
</div>
<div id="ridge-plots" class="section level1">
<h1>Ridge plots</h1>
<div id="pa-motivation" class="section level2">
<h2>PA motivation</h2>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;PA autonomous \nmotivation&#39; = PA_autonomous_T1,
&#39;PA controlled \nmotivation&#39; = PA_controlled_T1,
&#39;PA amotivation&#39; = PA_amotivation_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA amotivation 0&quot;, &quot;PA amotivation 1&quot;),
                      labels = c( &#39;PA amotivation 0&#39; = &quot;Boy&quot;, &#39;PA amotivation 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;PA autonomous motivation&#39; = PA_autonomous_T1,
&#39;PA controlled motivation&#39; = PA_controlled_T1,
&#39;PA amotivation&#39; = PA_amotivation_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA amotivation 1&quot;, &quot;PA amotivation 0&quot;),
                      labels = c(&#39;PA amotivation 1&#39; = &quot;Intervention&quot;, &#39;PA amotivation 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

# grid.arrange(plot1, plot2, ncol = 2)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.216
## Warning: Removed 272 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.216
## Warning: Removed 272 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-8-1.png" width="2100" /></p>
</div>
<div id="big-5-personality-traits" class="section level2">
<h2>Big 5 personality traits</h2>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Agreeableness&#39; = big5_agreeableness_T1,
&#39;Conscientiousness&#39; = big5_conscientiousness_T1,
&#39;Extraversion&#39; = big5_extraversion_T1,
&#39;Neuroticism&#39; = big5_neuroticism_T1,
&#39;Openness&#39; = big5_openness_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreeableness 0&quot;, &quot;Agreeableness 1&quot;),
                      labels = c( &#39;Agreeableness 0&#39; = &quot;Boy&quot;, &#39;Agreeableness 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)
## Error in overscope_eval_next(overscope, expr): object &#39;big5_agreeableness_T1&#39; not found

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Agreeableness&#39; = big5_agreeableness_T1,
&#39;Conscientiousness&#39; = big5_conscientiousness_T1,
&#39;Extraversion&#39; = big5_extraversion_T1,
&#39;Neuroticism&#39; = big5_neuroticism_T1,
&#39;Openness&#39; = big5_openness_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreeableness 1&quot;, &quot;Agreeableness 0&quot;),
                      labels = c(&#39;Agreeableness 1&#39; = &quot;Intervention&quot;, &#39;Agreeableness 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)
## Error in overscope_eval_next(overscope, expr): object &#39;big5_agreeableness_T1&#39; not found

# grid.arrange(plot1, plot2, ncol = 2)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.216
## Warning: Removed 272 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.216
## Warning: Removed 272 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-9-1.png" width="2100" /></p>
</div>
<div id="bct-use" class="section level2">
<h2>BCT use</h2>
<div id="ridge-plots-for-means" class="section level3">
<h3>Ridge plots for means</h3>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Frequency-\nrelated BCTs&#39; = PA_frqbct_T1,
&#39;Agreement-\nrelated BCTs&#39; = PA_agrbct_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreement-\nrelated BCTs 0&quot;, &quot;Agreement-\nrelated BCTs 1&quot;),
                      labels = c( &#39;Agreement-\nrelated BCTs 0&#39; = &quot;Boy&quot;, &#39;Agreement-\nrelated BCTs 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Frequency-\nrelated BCTs&#39; = PA_frqbct_T1,
&#39;Agreement-\nrelated BCTs&#39; = PA_agrbct_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreement-\nrelated BCTs 1&quot;, &quot;Agreement-\nrelated BCTs 0&quot;),
                      labels = c(&#39;Agreement-\nrelated BCTs 1&#39; = &quot;Intervention&quot;, &#39;Agreement-\nrelated BCTs 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.319
## Warning: Removed 189 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.318
## Warning: Removed 189 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-10-1.png" width="2100" /></p>
<pre class="r"><code>


# grid.arrange(plot1, plot2, ncol = 2)</code></pre>
</div>
<div id="sm-kernel-density-plots-for-means" class="section level3">
<h3>sm kernel density plots for means</h3>
<div id="frequency-measured-bcts" class="section level4">
<h4>Frequency-measured BCTs</h4>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- df
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_frqbct_T1, intervention) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_frqbct_T1_1 &lt;- sm.density.compare2(as.numeric(dens$PA_frqbct_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.31
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_frqbct_T1, girl) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_frqbct_T1_2 &lt;- sm.density.compare2(as.numeric(dens$PA_frqbct_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.11
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_frqbct_T1, school) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_frqbct_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$PA_frqbct_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-11-1.png" width="2100" /></p>
</div>
<div id="agreement-measured-bcts" class="section level4">
<h4>Agreement-measured BCTs</h4>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- df
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_agrbct_T1, intervention) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_agrbct_T1_1 &lt;- sm.density.compare2(as.numeric(dens$PA_agrbct_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_agrbct_T1, girl) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_agrbct_T1_2 &lt;- sm.density.compare2(as.numeric(dens$PA_agrbct_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.27
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_agrbct_T1, school) %&gt;% 
  na.omit(.)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_agrbct_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$PA_agrbct_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-12-1.png" width="2100" /></p>
</div>
</div>
<div id="histograms-for-individual-items" class="section level3">
<h3>Histograms for individual items</h3>
<div id="frequency-measured-bcts-1" class="section level4">
<h4>Frequency-measured BCTs</h4>
<p>These questions were asked with the lead “Have you done the following during the last three weeks?”.</p>
<p>The answer scale was as follows:</p>
<p>0 = not once 1 = once 2 = twice 3 = weekly 4 = about every second day 5 = daily</p>
<p>Items are as follows:</p>
<ol style="list-style-type: decimal">
<li>I have reminded myself even in my spare time, what kind of positive consequences frequent PA would have in my life.</li>
<li>I have monitored my PA by marking the PA occasions on an exercise log on paper.</li>
<li>I have monitored my PA by using a smart phone, e.g. the Moves-app.</li>
<li>I use mnemonic cues with which I remember to implement my PA intention.</li>
<li>I have compared my actualized PA with the PA goal I have set.</li>
<li>I have thought about which reasons to do PA are important to me personally.</li>
<li>I have made changes in my home (e.g. my room or my computer), so that starting PA would be easier.</li>
<li>I have asked my friends or family for support to reach my PA goals.</li>
<li>If I haven’t reached my PA goal, I have evaluated, what went wrong.</li>
</ol>
<pre class="r"><code>
bctGirls &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Girls&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctBoys &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Boys&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctInt &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Intervention&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctCont &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Control&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(bctInt, bctGirls, bctCont, bctBoys, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;))
## Warning: Removed 54 rows containing non-finite values (stat_binline).
## Warning: Removed 72 rows containing non-finite values (stat_binline).
## Warning: Removed 54 rows containing non-finite values (stat_binline).
## Warning: Removed 72 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-13-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
# grid.newpage()
# grid.draw(rbind(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), size = &quot;last&quot;), cbind(ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;)))</code></pre>
</div>
<div id="agreement-measured-bcts-1" class="section level4">
<h4>Agreement-measured BCTs</h4>
<p>These questions were asked with the lead “Have you done the following during the last three weeks?”.</p>
<p>The answer scale was as follows:</p>
<p>0 = not at all true 1 … 4 [unlabeled] 5 = completely true</p>
<p>Items are as follows:</p>
<ol style="list-style-type: decimal">
<li>I have set PA goals for myself.</li>
<li>I have personally made a specific plan (“what, where, how”) to implement my PA.</li>
<li>I have a PA plan, which has been made by someone else, e.g. my sports club (e.g. a workout schedule).</li>
<li>I have a way by which I remind myself of my PA plan, e.g. I write it down in the calendar.</li>
<li>I have cut larger PA goals to smaller subgoals.</li>
<li>I have tried out new ways for me to be physically active.</li>
<li>I have pondered, what kind of difficult situations or barriers prevent me from implementing my PA plan.</li>
<li>I have planned for ways to overcome barriers to doing PA.</li>
<li>I have thought about how PA fits my identity (self concept).</li>
<li>I have attempted to find ways to exercise so, that it won’t obstruct but instead helps actualise my other life values.</li>
</ol>
<pre class="r"><code>
bctGirls &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Girls&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctBoys &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Boys&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctInt &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Intervention&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctCont &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Control&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(bctInt, bctGirls, bctCont, bctBoys, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;))
## Warning: Removed 60 rows containing non-finite values (stat_binline).
## Warning: Removed 70 rows containing non-finite values (stat_binline).
## Warning: Removed 60 rows containing non-finite values (stat_binline).
## Warning: Removed 70 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-14-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
# grid.newpage()
# grid.draw(rbind(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), size = &quot;last&quot;), cbind(ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;)))

# bctBoys &lt;- df %&gt;% dplyr::select(id,
#   intervention,
#   group,
#   school,
#   girl,
#   &#39;Has set goals&#39; = PA_agrbct_01_T1,
#   &#39;Has made plan&#39; = PA_agrbct_02_T1,
#   &#39;Plan made by other&#39; = PA_agrbct_03_T1,
#   &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
#   &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
#   &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
#   &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
#   &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
#   &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
#   &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1)
# 
# mean(bctBoys$`Has set goals`, na.rm = T)
# mean(bctBoys$`Has made plan`, na.rm = T)
# mean(bctBoys$`Plan made by other`, na.rm = T)
# mean(bctBoys$`Has reminder of plan`, na.rm = T)
# mean(bctBoys$`Has cut goals to subgoals`, na.rm = T)
# mean(bctBoys$`Has tried new PA options`, na.rm = T)
# mean(bctBoys$`Has thought of barriers`, na.rm = T)
# mean(bctBoys$`Has planned for barriers`, na.rm = T)
# mean(bctBoys$`Has thought of PA identity`, na.rm = T)
# mean(bctBoys$`Has fitted PA to life values`, na.rm = T)</code></pre>
</div>
</div>
</div>
<div id="pa-determinants" class="section level2">
<h2>PA determinants</h2>
<div id="plot-without-fill" class="section level3">
<h3>Plot without fill</h3>
<pre class="r"><code>plot1 &lt;- df %&gt;% dplyr::select(id,
                              intervention,
                              group,
                              school,
                              girl,
                              &#39;PA intention&#39; = PA_intention_T1,
                              &#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
                              &#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
                              &#39;PA self efficacy&#39; = PA_selfefficacy_T1,
                              &#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
                              &#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
                              &#39;PA injunctive\nnorm&#39; = PA_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;%
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, colour = paste(Variable, girl), 
                                    fill = paste(Variable, girl)), 
                                    alpha = 0, size = 0.75, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 0&quot;, &quot;PA injunctive\nnorm 1&quot;),
                                labels = c( &#39;PA injunctive\nnorm 0&#39; = &quot;Boy&quot;, &#39;PA injunctive\nnorm 1&#39; = &quot;Girl&quot;),
                                values = viridis::viridis(4, end = 0.8)[c(1, 3)], #c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                                name = &quot;&quot;, guide = guide_legend(override.aes = list(alpha = 1))) +
  ggridges::scale_colour_cyclical(values = viridis::viridis(4, end = 0.8, alpha = 0.9)[c(1, 3)]) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10)) +
  geom_hline(yintercept = 1:7)
## Warning: attributes are not identical across measure variables;
## they will be dropped

target = c(
&quot;PA_intention_T1&quot;,
&quot;PA_outcomeExpectations_T1&quot;,
&quot;PA_pbc_T1&quot;,
&quot;PA_selfefficacy_T1&quot;,
&quot;PA_opportunities_T1&quot;,
&quot;PA_dnorm_T1&quot;,
&quot;PA_inorm_T1&quot;)

PA_ci_girls &lt;- ci_girls %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_girls &lt;- PA_ci_girls[match(target, PA_ci_girls$diamondlabels), ]

PA_ci_boys &lt;- ci_boys %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_boys &lt;- PA_ci_boys[match(target, PA_ci_boys$diamondlabels), ]

plot1 &lt;- plot1 + userfriendlyscience::diamondPlot(PA_ci_girls, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[c(3)], 
                alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_boys, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[c(1)],  
                alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

plot2 &lt;- df %&gt;% dplyr::select(id,
                              intervention,
                              group,
                              school,
                              girl,
                              &#39;PA intention&#39; = PA_intention_T1,
                              &#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
                              &#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
                              &#39;PA self efficacy&#39; = PA_selfefficacy_T1,
                              &#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
                              &#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
                              &#39;PA injunctive\nnorm&#39; = PA_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;%
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, colour = paste(Variable, intervention), 
                                    fill = paste(Variable, intervention)), 
                                    alpha = 0, size = 0.75, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 0&quot;, &quot;PA injunctive\nnorm 1&quot;),
                                labels = c( &#39;PA injunctive\nnorm 0&#39; = &quot;Control&quot;, &#39;PA injunctive\nnorm 1&#39; = &quot;Intervention&quot;),
                                values = c(viridis::viridis(4, end = 0.8)[c(2, 4)], viridis::viridis(8, end = 0.8)[c(4, 8)]), # get 2 x 2 colors, close to each other MUUTTAAKO MITÄÄN?
                                name = &quot;&quot;, guide = guide_legend(override.aes = list(alpha = 1))) +
  ggridges::scale_colour_cyclical(values = viridis::viridis(4, end = 0.8, alpha = 0.9)[c(2, 4)]) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10)) +
  geom_hline(yintercept = 1:7)
## Warning: attributes are not identical across measure variables;
## they will be dropped

PA_ci_intervention &lt;- ci_intervention %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_intervention &lt;- PA_ci_intervention[match(target, PA_ci_intervention$diamondlabels), ]

PA_ci_control &lt;- ci_control %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_control &lt;- PA_ci_control[match(target, PA_ci_control$diamondlabels), ]

plot2 &lt;- plot2 + 
  userfriendlyscience::diamondPlot(PA_ci_intervention, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[c(4)],
              alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_control, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[c(2)], 
              alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

# grid.arrange(plot1, plot2, ncol = 2)
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.355
## Warning: Removed 641 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.359
## Warning: Removed 641 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-15-1.png" width="2100" /></p>
</div>
<div id="pretty-plot-with-fill" class="section level3">
<h3>Pretty plot with fill</h3>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
                              intervention,
                              group,
                              school,
                              girl,
                              &#39;PA intention&#39; = PA_intention_T1,
                              &#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
                              &#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
                              &#39;PA self efficacy&#39; = PA_selfefficacy_T1,
                              &#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
                              &#39;PA descriptive\nnorm&#39; = PA_dnorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;%
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, colour = &quot;black&quot;, 
                                    fill = paste(Variable, girl)), 
                                    alpha = 0.6, size = 0.25, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA descriptive\nnorm 0&quot;, &quot;PA descriptive\nnorm 1&quot;),
                                labels = c( &#39;PA descriptive\nnorm 0&#39; = &quot;Boy&quot;, &#39;PA descriptive\nnorm 1&#39; = &quot;Girl&quot;),
                                values = viridis::viridis(4, end = 0.8)[c(1, 3)],
                                name = &quot;&quot;, guide = guide_legend(override.aes = list(alpha = 1))) +
  ggridges::scale_colour_cyclical(values = &quot;black&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10))

target = c(
&quot;PA_intention_T1&quot;,
&quot;PA_outcomeExpectations_T1&quot;,
&quot;PA_pbc_T1&quot;,
&quot;PA_selfefficacy_T1&quot;,
&quot;PA_opportunities_T1&quot;,
&quot;PA_dnorm_T1&quot;)

PA_ci_girls &lt;- ci_girls %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels))

PA_ci_girls &lt;- PA_ci_girls[match(target, PA_ci_girls$diamondlabels), ]

PA_ci_boys &lt;- ci_boys %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels))

PA_ci_boys &lt;- PA_ci_boys[match(target, PA_ci_boys$diamondlabels), ]

plot1 &lt;- plot1 + userfriendlyscience::diamondPlot(PA_ci_girls, returnLayerOnly = TRUE, lineColor = &quot;black&quot;, color=viridis::viridis(4, end = 0.8)[3], 
                alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_boys, returnLayerOnly = TRUE, lineColor = &quot;black&quot;, linetype = &quot;solid&quot;, color=viridis::viridis(4, end = 0.8)[1],  
                alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

plot2 &lt;- df %&gt;% dplyr::select(id,
                              intervention,
                              group,
                              school,
                              girl,
                              &#39;PA intention&#39; = PA_intention_T1,
                              &#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
                              &#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
                              &#39;PA self efficacy&#39; = PA_selfefficacy_T1,
                              &#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
                              &#39;PA descriptive\nnorm&#39; = PA_dnorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;%
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, colour = &quot;black&quot;, 
                                    fill = paste(Variable, intervention)), 
                                    alpha = 0.75, size = 0.25, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA descriptive\nnorm 0&quot;, &quot;PA descriptive\nnorm 1&quot;),
                                labels = c( &#39;PA descriptive\nnorm 0&#39; = &quot;Control&quot;, &#39;PA descriptive\nnorm 1&#39; = &quot;Intervention&quot;),
                                values = viridis::viridis(4, end = 0.8)[c(2, 4)],
                                name = &quot;&quot;, guide = guide_legend(override.aes = list(alpha = 1))) +
  ggridges::scale_colour_cyclical(values = &quot;black&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10))

PA_ci_intervention &lt;- ci_intervention %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels))

PA_ci_intervention &lt;- PA_ci_intervention[match(target, PA_ci_intervention$diamondlabels), ]

PA_ci_control &lt;- ci_control %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels))

PA_ci_control &lt;- PA_ci_control[match(target, PA_ci_control$diamondlabels), ]

plot2 &lt;- plot2 + 
  userfriendlyscience::diamondPlot(PA_ci_intervention, returnLayerOnly = TRUE, lineColor = &quot;black&quot;, color=viridis::viridis(4, end = 0.8)[4],
              alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_control, returnLayerOnly = TRUE, lineColor = &quot;black&quot;, color=viridis::viridis(4, end = 0.8)[2], 
              alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

# grid.arrange(plot1, plot2, ncol = 2)
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.327
## Warning: Removed 549 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.332
## Warning: Removed 549 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-16-1.png" width="2100" /></p>
<pre class="r"><code>
# Test that the legend is right; descriptive norms are smaller for girls
df %&gt;% group_by(girl) %&gt;% summarise(mean = mean(PA_dnorm_T1, na.rm = T)) %&gt;% filter(girl == &quot;1&quot;) %&gt;% select(mean) &lt; df %&gt;% group_by(girl) %&gt;% summarise(mean = mean(PA_dnorm_T1, na.rm = T)) %&gt;% filter(girl == &quot;0&quot;) %&gt;% select(mean)
##      mean
## [1,] TRUE

# KESKEN: iv/ctrl-legend
df %&gt;% group_by(intervention) %&gt;% summarise(mean = mean(PA_dnorm_T1, na.rm = TRUE)) %&gt;% filter(intervention == &quot;1&quot;) %&gt;% select(mean) &lt; df %&gt;% group_by(intervention) %&gt;% summarise(mean = mean(PA_dnorm_T1, na.rm = T)) %&gt;% filter(intervention == &quot;0&quot;) %&gt;% select(mean)
##      mean
## [1,] TRUE</code></pre>
<pre class="r"><code>library(viridis::viridis)
## Error in library(viridis::viridis): &#39;package&#39; must be of length 1
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;PA action and\ncoping planning&#39; = PA_actCop_T1,
&#39;PA intention&#39; = PA_intention_T1,
&#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
&#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
&#39;PA self efficacy&#39; = PA_selfefficacy_T1,
&#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
&#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
&#39;PA injunctive\nnorm&#39; = PA_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .1, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 0&quot;, &quot;PA injunctive\nnorm 1&quot;),
                      labels = c( &#39;PA injunctive\nnorm 0&#39; = &quot;Boy&quot;, &#39;PA injunctive\nnorm 1&#39; = &quot;Girl&quot;),
                      values = viridis::viridis(4, end = 0.8)[1:2], #c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10))
## Warning: attributes are not identical across measure variables;
## they will be dropped

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;PA action and\ncoping planning&#39; = PA_actCop_T1,
&#39;PA intention&#39; = PA_intention_T1,
&#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
&#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
&#39;PA self efficacy&#39; = PA_selfefficacy_T1,
&#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
&#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
&#39;PA injunctive\nnorm&#39; = PA_inorm_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .9, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 1&quot;, &quot;PA injunctive\nnorm 0&quot;),
                      labels = c(&#39;PA injunctive\nnorm 1&#39; = &quot;Intervention&quot;, &#39;PA injunctive\nnorm 0&#39; = &quot;Control&quot;),
                      values = viridis::viridis(4, end = 0.8)[3:4], #c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10))
## Warning: attributes are not identical across measure variables;
## they will be dropped

target = c(&quot;PA_actCop_T1&quot;,
&quot;PA_intention_T1&quot;,
&quot;PA_outcomeExpectations_T1&quot;,
&quot;PA_pbc_T1&quot;,
&quot;PA_selfefficacy_T1&quot;,
&quot;PA_opportunities_T1&quot;,
&quot;PA_dnorm_T1&quot;,
&quot;PA_inorm_T1&quot;)

PA_ci_girls &lt;- ci_girls %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_girls &lt;- PA_ci_girls[match(target, PA_ci_girls$diamondlabels), ]

PA_ci_boys &lt;- ci_boys %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_boys &lt;- PA_ci_boys[match(target, PA_ci_boys$diamondlabels), ]

plot1 &lt;- plot1 + 
  userfriendlyscience::diamondPlot(PA_ci_girls, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[1],# &#39;blue&#39;, 
                alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_boys, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[2], #&#39;green&#39;, 
                alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

PA_ci_intervention &lt;- ci_intervention %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_intervention &lt;- PA_ci_intervention[match(target, PA_ci_intervention$diamondlabels), ]

PA_ci_control &lt;- ci_control %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_control &lt;- PA_ci_control[match(target, PA_ci_control$diamondlabels), ]

plot2 &lt;- plot2 + 
  userfriendlyscience::diamondPlot(PA_ci_intervention, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[4],# &#39;blue&#39;,
              alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_control, returnLayerOnly = TRUE, color=viridis::viridis(4, end = 0.8)[3], #&#39;red&#39;, 
              alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

# grid.arrange(plot1, plot2, ncol = 2)
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.337
## Warning: Removed 733 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.341
## Warning: Removed 733 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-17-1.png" width="2100" /></p>
<pre class="r"><code>library(visreg)
library(broom)

m_pbcgirl &lt;- lme4::lmer(PA_pbc_T1 ~ girl + (1 | school), data = df)
summary(m_pbcgirl)
## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: PA_pbc_T1 ~ girl + (1 | school)
##    Data: df
## 
## REML criterion at convergence: 3561.2
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2903 -0.6705  0.1155  0.9014  1.4253 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. 
##  school   (Intercept) 1.393e-14 1.180e-07
##  Residual             1.619e+00 1.272e+00
## Number of obs: 1071, groups:  school, 5
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  5.18644    0.05164  100.43
## girl0        0.32578    0.07846    4.15
## 
## Correlation of Fixed Effects:
##       (Intr)
## girl0 -0.658

visreg::visreg(m_pbcgirl, &quot;school&quot;, type = &quot;contrast&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-18-1.png" width="2100" /></p>
<pre class="r"><code>
visreg(m_pbcgirl, &quot;girl&quot;, by=&quot;school&quot;, re.form=~(1|school))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-18-2.png" width="2100" /></p>
<pre class="r"><code>
glance(m_pbcgirl)
##      sigma    logLik      AIC      BIC deviance df.residual
## 1 1.272372 -1780.624 3569.247 3589.153 3553.336        1067</code></pre>
</div>
</div>
<div id="sb-determinants" class="section level2">
<h2>SB determinants</h2>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;SB intention&#39; = SB_intention_T1,
&#39;SB outcome\nexpectations&#39; = SB_outcomeExpectations_T1,
&#39;SB self-efficacy\nand perceived\nbehavioural control&#39; = SB_sePbc_T1,
&#39;SB descriptive\nnorm&#39; = SB_dnorm_T1,
&#39;SB injunctive\nnorm&#39; = SB_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;SB injunctive\nnorm 0&quot;, &quot;SB injunctive\nnorm 1&quot;),
                      labels = c( &#39;SB injunctive\nnorm 0&#39; = &quot;Boy&quot;, &#39;SB injunctive\nnorm 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;SB intention&#39; = SB_intention_T1,
&#39;SB outcome\nexpectations&#39; = SB_outcomeExpectations_T1,
&#39;SB self-efficacy\nand perceived\nbehavioural control&#39; = SB_sePbc_T1,
&#39;SB descriptive\nnorm&#39; = SB_dnorm_T1,
&#39;SB injunctive\nnorm&#39; = SB_inorm_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;SB injunctive\nnorm 1&quot;, &quot;SB injunctive\nnorm 0&quot;),
                      labels = c(&#39;SB injunctive\nnorm 1&#39; = &quot;Intervention&quot;, &#39;SB injunctive\nnorm 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

gridExtra::grid.arrange(plot1, plot2, ncol = 2)
## Picking joint bandwidth of 0.311
## Warning: Removed 507 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.317
## Warning: Removed 507 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-19-1.png" width="2100" /></p>
</div>
</div>
<div id="ciber-not-included-for-now" class="section level1">
<h1>CIBER (not included for now)</h1>
<pre class="r"><code>#p_install(&quot;userfriendlyscience&quot;)

# cat(names(df), sep = &quot;\&quot;,\n\&quot;&quot;)

# Make variables numeric, and d as data frame
d_num &lt;- df %&gt;% mutate_all(as.numeric) 
d_num &lt;- as.data.frame(d_num)

userfriendlyscience::CIBER(data = d_num,
      determinants = c(
        &quot;actCop_T1&quot;,
        &quot;agrbct_T1&quot;,
        &quot;amotivation_T1&quot;,
        &quot;autonomous_T1&quot;,
        &quot;big5_agreeableness_T1.1&quot;,
        &quot;big5_conscientiousness_T1.1&quot;,
        &quot;big5_extraversion_T1.1&quot;,
        &quot;big5_neuroticism_T1.1&quot;,
        &quot;big5_openness_T1.1&quot;,
        &quot;controlled_T1&quot;,
        &quot;dnorm_T1&quot;,
        &quot;frqbct_T1&quot;,
        &quot;goal_T1&quot;,
        &quot;inorm_T1&quot;,
        &quot;intention_T1&quot;,
        &quot;outcomeExpectations_T1&quot;,
        &quot;opportunities_T1&quot;,
        &quot;pbc_T1&quot;,
        &quot;selfefficacy_T1&quot;),
      targets = c(&quot;paT1&quot;, &quot;fatpct_T1&quot;),
      conf.level = list(means = 0.9999,
                        associations = 0.99)
      )

userfriendlyscience::CIBER(data = d_num,
      determinants = c(
        &quot;actCop_T1&quot;,
        &quot;agrbct_T1&quot;,
        &quot;frqbct_T1&quot;,
        &quot;amotivation_T1&quot;,
        &quot;autonomous_T1&quot;,
        &quot;controlled_T1&quot;,
        &quot;dnorm_T1&quot;,
        &quot;intention_T1&quot;,
        &quot;outcomeExpectations_T1&quot;,
        &quot;opportunities_T1&quot;,
        &quot;sePbc_T1&quot;),
      targets = c(&quot;paT1&quot;, &quot;fatpct_T1&quot;),
      conf.level = list(means = 0.9999,
                        associations = 0.99)
      )

# to create variable list for CIBER:
# cat(names(d), sep = &quot;\&quot;,\n\&quot;&quot;)

userfriendlyscience::CIBER(data = d_num,
  determinants = c(
  &quot;agrbct_01_T1&quot;,
  &quot;agrbct_02_T1&quot;,
  &quot;agrbct_03_T1&quot;,
  &quot;agrbct_04_T1&quot;,
  &quot;agrbct_05_T1&quot;,
  &quot;agrbct_06_T1&quot;,
  &quot;agrbct_07_T1&quot;,
  &quot;agrbct_08_T1&quot;,
  &quot;agrbct_09_T1&quot;,
  &quot;agrbct_10_T1&quot;,
  &quot;frqbct_01_T1&quot;,
  &quot;frqbct_02_T1&quot;,
  &quot;frqbct_03_T1&quot;,
  &quot;frqbct_04_T1&quot;,
  &quot;frqbct_05_T1&quot;,
  &quot;frqbct_06_T1&quot;,
  &quot;frqbct_07_T1&quot;,
  &quot;frqbct_08_T1&quot;,
  &quot;frqbct_09_T1&quot;),
   targets = c(&quot;MVPA&quot;, &quot;SB&quot;),
  leftAnchors = rep(&quot;&quot;, 19),
  rightAnchors = rep(&quot;&quot;, 19))

userfriendlyscience::CIBER(data = d_num,
  determinants = c(
  &quot;autonomous_01_T1&quot;,
  &quot;autonomous_02_T1&quot;,
  &quot;autonomous_03_T1&quot;,
  &quot;autonomous_04_T1&quot;,
  &quot;autonomous_05_T1&quot;,
  &quot;autonomous_06_T1&quot;,
  &quot;autonomous_07_T1&quot;,
  &quot;autonomous_08_T1&quot;,
  &quot;autonomous_09_T1&quot;),
   targets = c(&quot;MVPA&quot;, &quot;SB&quot;),
  leftAnchors = rep(&quot;&quot;, 9),
  rightAnchors = rep(&quot;&quot;, 9))

userfriendlyscience::CIBER(data = d_num,
  determinants = c(
  &quot;intention_01_T1&quot;,
  &quot;intention_02_T1&quot;,
  &quot;selfefficacy_01_T1&quot;,
  &quot;selfefficacy_02_T1&quot;,
  &quot;pbc_01_T1&quot;,
  &quot;pbc_02_T1&quot;,
  &quot;pbc_03_T1&quot;,
  &quot;norm_01_T1&quot;,
  &quot;norm_02_T1&quot;,
  &quot;outcomeExpectations_01_T1&quot;,
  &quot;outcomeExpectations_02_T1&quot;,
  &quot;outcomeExpectations_03_T1&quot;,
  &quot;outcomeExpectations_04_T1&quot;,
  &quot;outcomeExpectations_05_T1&quot;,
  &quot;outcomeExpectations_06_T1&quot;,
  &quot;outcomeExpectations_07_T1&quot;,
  &quot;outcomeExpectations_08_T1&quot;,
  &quot;outcomeExpectations_09_T1&quot;,
  &quot;outcomeExpectations_10_T1&quot;,
  &quot;outcomeExpectations_11_T1&quot;,
  &quot;outcomeExpectations_12_T1&quot;),
   targets = c(&quot;MVPA&quot;, &quot;SB&quot;),
  leftAnchors = rep(&quot;&quot;, 21),
  rightAnchors = rep(&quot;&quot;, 21))</code></pre>
</div>
<div id="density-plots" class="section level1">
<h1>Density plots</h1>
<div id="accelerometer-measured-pa" class="section level2">
<h2>Accelerometer-measured PA</h2>
<p>Contrary to some other findings, in our sample girls were more active than boys.</p>
<pre class="r"><code>
MVPAgirl_df &lt;- df %&gt;% group_by(girl) %&gt;% select(girl, paAccelerometer_T1) %&gt;% summarise(mean = mean(paAccelerometer_T1, na.rm = TRUE), median = median(paAccelerometer_T1, na.rm = TRUE))
MVPAgirl_df[1, 2] - MVPAgirl_df[2, 2]
##       mean
## 1 16.81268
MVPAgirl_df[1, 3] - MVPAgirl_df[2, 3]
##     median
## 1 24.52857

userfriendlyscience::meanDiff(df$girl, df$paAccelerometer_T1)
## Input variables:
## 
##   girl (grouping variable)
##   paAccelerometer_T1 (dependent variable)
##   Mean 1 (1) = 190.36, sd = 48.6, n = 425
##   Mean 2 (0)= 173.55, sd = 59.39, n = 281
## 
## Independent samples t-test (tested for equal variances, p &lt; .001, so unequal variances)
##   (standard deviation used of largest sample, 48.6)
## 
## 95% confidence intervals:
##   Absolute mean difference: [8.45, 25.17] (Absolute mean difference: 16.81)
##   Cohen&#39;s d for difference: [0.19, 0.5] (Cohen&#39;s d point estimate: 0.35)
##   Hedges g for difference:  [0.19, 0.5] (Hedges g point estimate:  0.35)
## 
## Achieved power for d=0.35: 0.9957 (for small: 0.756; medium: 1; large: 1)
## 
## (secondary information (NHST): t[516] = 3.95, p &lt; .001)
## 
## 
## NOTE: because the t-test is based on unequal variances, the NHST p-value may be inconsistent with the confidence interval. Although this is not a problem, if you wish to ensure consistency, you can use parameter &quot;var.equal = &#39;yes&#39;&quot; to force equal variances.</code></pre>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- d
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(paAccelerometer_T1, intervention) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.paAccelerometer_T1_1 &lt;- sm.density.compare2(as.numeric(dens$paAccelerometer_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.25
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(paAccelerometer_T1, girl) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.paAccelerometer_T1_2 &lt;- sm.density.compare2(as.numeric(dens$paAccelerometer_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(paAccelerometer_T1, school) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Make plot
sm.paAccelerometer_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$paAccelerometer_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-22-1.png" width="2100" /></p>
</div>
<div id="time-spent-sitting-and-lying-down" class="section level2">
<h2>Time spent sitting and lying down</h2>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- d
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(sitLieAccelerometer_T1, intervention) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.sitLieAccelerometer_T1_1 &lt;- sm.density.compare2(as.numeric(dens$sitLieAccelerometer_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.09
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(sitLieAccelerometer_T1, girl) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.sitLieAccelerometer_T1_2 &lt;- sm.density.compare2(as.numeric(dens$sitLieAccelerometer_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(sitLieAccelerometer_T1, school) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Make plot
sm.sitLieAccelerometer_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$sitLieAccelerometer_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-23-1.png" width="2100" /></p>
</div>
</div>
<div id="symptoms" class="section level1">
<h1>Symptoms</h1>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- df
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(symptom_T1, intervention) %&gt;% na.omit(densplot)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.symptom_T1_1 &lt;- sm.density.compare2(as.numeric(dens$symptom_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.59
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(symptom_T1, girl)  %&gt;% na.omit(densplot)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.symptom_T1_2 &lt;- sm.density.compare2(as.numeric(dens$symptom_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(&quot;Symptom sum score&quot; = symptom_T1, school) %&gt;% na.omit(densplot)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)
linewidths &lt;- c(2,1,1,2,1)

# Make plot
sm.symptom_T1_3 &lt;- sm::sm.density.compare(dens$`Symptom sum score`, dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;equal&quot;, lwd=linewidths)
## Reference band available to compare two groups only.</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-24-1.png" width="2100" /></p>
<pre><code>## 
## Test of equal densities:  p-value =  0
xlab = &quot;&quot;
</code></pre>
<div id="symptom-histograms" class="section level2">
<h2>Symptom histograms</h2>
<div id="intervention-gender" class="section level3">
<h3>intervention / gender</h3>
<pre class="r"><code>
sympGirls &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Girls&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympBoys &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Boys&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympInt &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Intervention&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympCont &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Control&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(sympInt, sympGirls, sympCont, sympBoys, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(sympInt), ggplotGrob(sympCont), ggplotGrob(sympGirls), ggplotGrob(sympBoys), size = &quot;last&quot;))
## Warning: Removed 198 rows containing non-finite values (stat_binline).
## Warning: Removed 93 rows containing non-finite values (stat_binline).
## Warning: Removed 197 rows containing non-finite values (stat_binline).
## Warning: Removed 94 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-25-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
#grid.newpage()
#grid.draw(rbind(cbind(ggplotGrob(sympInt), ggplotGrob(sympCont), size = &quot;last&quot;), cbind(ggplotGrob(sympGirls), ggplotGrob(sympBoys), size = &quot;last&quot;)))
</code></pre>
</div>
<div id="educational-track" class="section level3">
<h3>educational track</h3>
<pre class="r"><code>
sympHRC &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;HRC&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;HRC&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympNursing &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;Nursing&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Nursing&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympIT &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;Business IT&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Business IT&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympBA &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;Business Admin&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Business Admin&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(sympIT, sympHRC, sympBA, sympNursing, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(sympIT), ggplotGrob(sympBA), ggplotGrob(sympHRC), ggplotGrob(sympNursing), size = &quot;last&quot;))
## Warning: Removed 26 rows containing non-finite values (stat_binline).
## Warning: Removed 49 rows containing non-finite values (stat_binline).

## Warning: Removed 49 rows containing non-finite values (stat_binline).
## Warning: Removed 141 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-26-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
#grid.newpage()
#grid.draw(rbind(cbind(ggplotGrob(sympIT), ggplotGrob(sympBA), size = &quot;last&quot;), cbind(ggplotGrob(sympHRC), ggplotGrob(sympNursing), size = &quot;last&quot;)))
</code></pre>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
