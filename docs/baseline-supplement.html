<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Baseline analysis supplement</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}

.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Visualising baseline characteristics</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">About</a>
</li>
<li>
  <a href="manuscript/baseline-manuscript.pdf">Manuscript</a>
</li>
<li>
  <a href="baseline-supplement.html">Supplement</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Baseline analysis supplement</h1>

</div>


<p>Welcome to the LMI baseline supplement! This supplement will walk you through the paper and provides additional graphs.</p>
<div id="measures-used-in-the-study" class="section level1">
<h1>Measures used in the study</h1>
<p>Clicking the “Code”-buttons on the right shows code for each chunk.</p>
<p>To start data analysis, we set up the basics to enable compiling the document:</p>
<pre class="r"><code>## Remember to tell R where your packages are.
# .libPaths(&quot;C:/rlibs/3.4.2&quot;)

# If pacman-package is not installed, install it and then load it.
if (!require(pacman)) install.packages(&quot;pacman&quot;)
#library(pacman)

CRANpacks &lt;- c(&quot;viridis&quot;, &quot;bookdown&quot;, &quot;knitr&quot;, &quot;tidyverse&quot;, &quot;haven&quot;, &quot;lme4&quot;, &quot;userfriendlyscience&quot;, &quot;sm&quot;, &quot;sjstats&quot;, &quot;gridExtra&quot;, &quot;ggridges&quot;, &quot;igraph&quot;, &quot;devtools&quot;,&quot;EstimateGroupNetwork&quot;, &quot;bootnet&quot;, &quot;qgraph&quot;,&quot;rstanarm&quot;, &quot;brms&quot;, &quot;mlmRev&quot;)
instpacks &lt;- setdiff(CRANpacks,pacman::p_library())

# Use pacman to install the needed packages.
if (length(instpacks)&gt;0) pacman::p_install(instpacks)

pacman::p_install_gh(&quot;crsh/papaja&quot;)</code></pre>
<pre><code>## Installation failed: Send failure: Connection was aborted</code></pre>
<pre><code>## Warning in pacman::p_install_gh(&quot;crsh/papaja&quot;): The following may have incorrect capitalization specification:
## 
## papaja</code></pre>
<pre><code>## 
## The following packages were not able to be installed:
## papaja</code></pre>
<pre class="r"><code>pacman::p_install_gh(&quot;sachaepskamp/NetworkComparisonTest&quot;)</code></pre>
<pre><code>## Installation failed: Could not resolve host: raw.githubusercontent.com</code></pre>
<pre><code>## Warning in pacman::p_install_gh(&quot;sachaepskamp/NetworkComparisonTest&quot;): The following may have incorrect capitalization specification:
## 
## NetworkComparisonTest</code></pre>
<pre><code>## 
## The following packages were not able to be installed:
## NetworkComparisonTest</code></pre>
<pre class="r"><code># Packages specifically for network analysis
#pacman::p_install(c(&quot;EstimateGroupNetwork&quot;, &quot;bootnet&quot;, &quot;qgraph&quot;))
#pacman::p_install_gh(&quot;sachaepskamp/NetworkComparisonTest&quot;)

# Packages for the figures which show Bayesian credible intervals of classes
#pacman::p_install(c(&quot;rstanarm&quot;, &quot;brms&quot;, &quot;mlmRev&quot;))

pacman::p_load(knitr, tidyverse)

knitr::opts_chunk$set(echo = TRUE, 
               warning = TRUE,
               error = TRUE,
               cache = TRUE, 
               collapse = TRUE,
               eval = TRUE,
               dpi = 300)
knitr::opts_chunk$set(root.dir = &quot;.&quot;)  # Always set project root as working directory
knitr::opts_knit$set(root.dir = &quot;.&quot;)  # This is needed for some versions of RStudio

ggplot2::theme_set(papaja::theme_apa())</code></pre>
<div id="read-data" class="section level2">
<h2>Read data</h2>
<pre class="r"><code>
# Read data.

#lmi &lt;- haven::read_sav(&quot;data/LMI_data_korjattu_syntaksilla_nimetpoistettu.sav&quot;, user_na = FALSE)

lmi &lt;- haven::read_sav(&quot;data/LMI_data_korjattu_syntaksilla_nimetpoistettu - skandit muutettu MANUAALISESTI.sav&quot;, user_na = FALSE)


# write_csv(lmi, &quot;Z:/Desktop/LMI DATA/LMI_data_korjattu_syntaksilla_CSV.csv&quot;)

# to get rid of DLL warning, these don&#39;t work: 
# Sys.setenv(&quot;R_MAX_NUM_DLLS&quot; = 1000)

# Unloading all packages gives LAPACK error:
# pkgs &lt;- names(sessionInfo()$otherPkgs)
# pkgs &lt;- paste(&#39;package:&#39;, pkgs, sep = &quot;&quot;)
# lapply(pkgs, detach, character.only = TRUE, unload = TRUE)

# What seems to work is create a file .Renviron in the project root, which contains
# </code></pre>
</div>
<div id="package-sm-modifications" class="section level2">
<h2>Package sm modifications</h2>
<p>The package sm has a nice tool for visualising densities and doing a bootstrap test on their equivalence. We modify the function so that we can change the color of the equivalence band.</p>
<pre class="r"><code>
# Changing the sm density compare function to allow different color of the band of equality. Copied from https://web.archive.org/web/20170222214214/https://stat.ethz.ch/pipermail/r-help//2009-March/416920.html.

sm.density.compare2 &lt;- function (x, group, h, model = &quot;none&quot;, bandcol =
                                  &#39;cyan&#39;, lwd = par(&quot;lwd&quot;), usePolyg = NULL, asp=NA, 
                                xlab=opt$xlab, ylab=opt$ylab, ...) 
{
  if (!is.vector(x)) 
    stop(&quot;sm.density.compare can handle only 1-d data&quot;)
  opt &lt;- sm:::sm.options(list(...))
  sm:::replace.na(opt, ngrid, 50)                 
  ## These all changed from replace.na() --&gt; sm:::
  sm:::replace.na(opt, display, &quot;line&quot;)
  sm:::replace.na(opt, xlab, deparse(substitute(x)))
  sm:::replace.na(opt, ylab, &quot;Density&quot;)
  sm:::replace.na(opt, xlim, c(min(x) - diff(range(x))/4, max(x) + 
                                 diff(range(x))/4))
  sm:::replace.na(opt, eval.points, seq(opt$xlim[1], opt$xlim[2], 
                                        length = opt$ngrid))
  if (is.na(opt$band)) {
    if (model == &quot;none&quot;) 
      opt$band &lt;- FALSE
    else opt$band &lt;- TRUE
  }
  if ((model == &quot;none&quot;) &amp;&amp; opt$band) 
    opt$band &lt;- FALSE
  band &lt;- opt$band
  ngrid &lt;- opt$ngrid
  xlim &lt;- opt$xlim
  nboot &lt;- opt$nboot
  y &lt;- x
  if (is.na(opt$test)) {
    if (model == &quot;none&quot;) 
      opt$test &lt;- FALSE
    else opt$test &lt;- TRUE
  }
  if ((model == &quot;none&quot;) &amp;&amp; opt$test) 
    opt$test &lt;- FALSE
  test &lt;- opt$test
  if (opt$display %in% &quot;none&quot;) 
    band &lt;- FALSE
  fact &lt;- factor(group)
  fact.levels &lt;- levels(fact)
  nlev &lt;- length(fact.levels)
  ni &lt;- table(fact)
  if (band &amp; (nlev &gt; 2)) {
    cat(&quot;Reference band available to compare two groups only.&quot;, 
        &quot;\n&quot;)
    band &lt;- FALSE
  }
  if (length(opt$lty) &lt; nlev) 
    opt$lty &lt;- 1:nlev
  if (length(opt$col) &lt; nlev) 
    opt$col &lt;- 2:(nlev + 1)
  if (missing(h)) 
    h &lt;- sm:::h.select(x, y = NA, group = group, ...)
  opt$band &lt;- band
  opt$test &lt;- test
  estimate &lt;- matrix(0, ncol = opt$ngrid, nrow = nlev)
  se &lt;- matrix(0, ncol = opt$ngrid, nrow = nlev)
  for (i in 1:nlev) {
    sm &lt;- sm:::sm.density(y[fact == fact.levels[i]], h = h, display = &quot;none&quot;, 
                     eval.points = opt$eval.points)
    estimate[i, ] &lt;- sm$estimate
    se[i, ] &lt;- sm$se
  }
  eval.points &lt;- sm$eval.points
  if (!(opt$display %in% &quot;none&quot; | band)) {
    plot(xlim, c(0, 1.1 * max(as.vector(estimate))), xlab = opt$xlab, 
         ylab = opt$ylab, type = &quot;n&quot;)
    #for (i in 1:nlev) lines(eval.points, estimate[i, ], lty = opt$lty[i], 
    #    col = opt$col[i])
    for (i in 1:nlev) lines(eval.points, estimate[i, ], lty =
                              opt$lty[i],   ## lwd hacked in
                            col = opt$col[i], lwd = lwd[i])
  }
  est &lt;- NULL
  p &lt;- NULL
  if (model == &quot;equal&quot; &amp; test) {
    if (nlev == 2) {
      ts &lt;- sum((estimate[1, ] - estimate[2, ])^2)
    }
    else {
      sm.mean &lt;- sm:::sm.density(y, h = h, xlim = opt$xlim, 
                            ngrid = opt$ngrid, display = &quot;none&quot;)$estimate
      ts &lt;- 0
      for (i in 1:nlev) ts &lt;- ts + ni[i] * sum((estimate[i, 
                                                         ] - sm.mean)^2)
    }
    p &lt;- 0
    est.star &lt;- matrix(0, ncol = opt$ngrid, nrow = nlev)
    for (iboot in 1:nboot) {
      ind &lt;- (1:length(y))
      for (i in 1:nlev) {
        indi &lt;- sample((1:length(ind)), ni[i])
        est.star[i, ] &lt;- sm:::sm.density(y[ind[indi]], h = h, 
                                    ngrid = opt$ngrid, xlim = opt$xlim, display =
                                      &quot;none&quot;)$estimate
        ind &lt;- ind[-indi]
      }
      if (nlev == 2) {
        ts.star &lt;- sum((est.star[1, ] - est.star[2, ])^2)
      }
      else {
        sm.mean &lt;- sm:::sm.density(y, h = h, xlim = opt$xlim, 
                              ngrid = opt$ngrid, display = &quot;none&quot;)$estimate
        ts.star &lt;- 0
        for (i in 1:nlev) {
          ts.star &lt;- ts.star + ni[i] * sum((est.star[i, 
                                                     ] - sm.mean)^2)
        }
      }
      if (ts.star &gt; ts) 
        p &lt;- p + 1
      if (opt$verbose &gt; 1) {
        cat(iboot)
        cat(&quot; &quot;)
      }
    }
    p &lt;- p/nboot
    cat(&quot;\nTest of equal densities:  p-value = &quot;, round(p, 
                                                        5), &quot;\n&quot;)
    est &lt;- list(p = p, h = h)
  }
  if (model == &quot;equal&quot; &amp; band) {
    av &lt;- (sqrt(estimate[1, ]) + sqrt(estimate[2, ]))/2
    se &lt;- sqrt(se[1, ]^2 + se[2, ]^2)
    upper &lt;- (av + se)^2
    lower &lt;- pmax(av - se, 0)^2
    plot(xlim, c(0, 1.1 * max(as.vector(estimate), upper)), 
         xlab = xlab, ylab = ylab, type = &quot;n&quot;, asp=asp, ...)     
    ## ... and asp added; was opt$xlab and opt$ylab
    polygon(c(eval.points, rev(eval.points)), c(upper, rev(lower)), 
            col = bandcol, border = 0)                                      
    ## was col = &quot;cyan&quot;
    if (is.null(usePolyg)) {
      lines(eval.points, estimate[1, ], lty = opt$lty[1], col =
              opt$col[1], lwd = lwd[1])
      lines(eval.points, estimate[2, ], lty = opt$lty[2], col =
              opt$col[2], lwd = lwd[2])
    }
    else {
      polygon(eval.points, estimate[1, ], lty = opt$lty[1], col =
                opt$col[1], lwd = lwd[1])
      polygon(eval.points, estimate[2, ], lty = opt$lty[2], col =
                opt$col[2], lwd = lwd[2])
    }
    est &lt;- list(p = p, upper = upper, lower = lower, h = h)
  }
  invisible(est)
}</code></pre>
</div>
</div>
<div id="prepare-data-with-variables-of-interest" class="section level1">
<h1>Prepare data with variables of interest</h1>
<p>We do data manipulation and cleaning to come up with a dataaset with our variables of interests.</p>
<pre class="r"><code>#library(userfriendlyscience)
library(dplyr)
d &lt;- lmi %&gt;% dplyr::select(id = ID,
  intervention = ryhma,
  group = ryhmakoodi_korjattu,
  school = Aineisto.1,
  girl = Kys0013.1,
b5agr_01_T1 = Kys0155.1,
b5agrReverseCoded_02_T1 = Kys0150.1,
b5cons_01_T1 = Kys0151.1,
b5consReverseCoded_02_T1 = Kys0156.1,
b5ext_01_T1 = Kys0149.1,
b5extReverseCoded_02_T1 = Kys0154.1,
b5neur_01_T1 = Kys0152.1,
b5neurReverseCoded_02_T1 = Kys0157.1,
b5open_01_T1 = Kys0153.1,
b5openReverseCoded_02_T1 = Kys0158.1,
fatpct_T1 = Rasva,
PA_actCop_01_T1 = Kys0115.1,
PA_actCop_01_T3 = Kys0115.3,
PA_actCop_02_T1 = Kys0116.1,
PA_actCop_02_T3 = Kys0116.3,
PA_actCop_03_T1 = Kys0117.1,
PA_actCop_03_T3 = Kys0117.3,
PA_actCop_04_T1 = Kys0118.1,
PA_actCop_04_T3 = Kys0118.3,
PA_agrbct_01_T1 = Kys0128.1,
PA_agrbct_01_T3 = Kys0128.3,
PA_agrbct_02_T1 = Kys0129.1,
PA_agrbct_02_T3 = Kys0129.3,
PA_agrbct_03_T1 = Kys0130.1,
PA_agrbct_03_T3 = Kys0130.3,
PA_agrbct_04_T1 = Kys0131.1,
PA_agrbct_04_T3 = Kys0131.3,
PA_agrbct_05_T1 = Kys0132.1,
PA_agrbct_05_T3 = Kys0132.3,
PA_agrbct_06_T1 = Kys0133.1,
PA_agrbct_06_T3 = Kys0133.3,
PA_agrbct_07_T1 = Kys0134.1,
PA_agrbct_07_T3 = Kys0134.3,
PA_agrbct_08_T1 = Kys0135.1,
PA_agrbct_08_T3 = Kys0135.3,
PA_agrbct_09_T1 = Kys0136.1,
PA_agrbct_09_T3 = Kys0136.3,
PA_agrbct_10_T1 = Kys0137.1,
PA_agrbct_10_T3 = Kys0137.3,
PA_amotivation_01_T1 = Kys0082.1,
PA_amotivation_01_T3 = Kys0082.3,
PA_amotivation_02_T1 = Kys0086.1,
PA_amotivation_02_T3 = Kys0086.3,
PA_amotivation_03_T1 = Kys0096.1,
PA_amotivation_03_T3 = Kys0096.3,
PA_amotivation_04_T1 = Kys0097.1,
PA_amotivation_04_T3 = Kys0097.3,
PA_actCop_05_T1 = Kys0119.1,
PA_actCop_05_T3 = Kys0119.3,
PA_actCop_06_T1 = Kys0120.1,
PA_actCop_06_T3 = Kys0120.3,
PA_actCop_07_T1 = Kys0121.1,
PA_actCop_07_T3 = Kys0121.3,
PA_actCop_08_T1 = Kys0122.1,
PA_actCop_08_T3 = Kys0122.3,
PA_dnorm_02_T1 = Kys0107.1,
PA_dnormparents_02_T3 = Kys0107.3,
PA_dnorm_01_T1 = Kys0106.1,
PA_dnorm_01_T3 = Kys0106.3,
PA_controlled_01_T1 = Kys0080.1,
PA_controlled_01_T3 = Kys0080.3,
PA_controlled_02_T1 = Kys0081.1,
PA_controlled_02_T3 = Kys0081.3,
PA_controlled_03_T1 = Kys0083.1,
PA_controlled_03_T3 = Kys0083.3,
PA_frqbct_01_T1 = Kys0138.1,
PA_frqbct_01_T3 = Kys0138.3,
PA_frqbct_02_T1 = Kys0139.1,
PA_frqbct_02_T3 = Kys0139.3,
PA_frqbct_03_T1 = Kys0140.1,
PA_frqbct_03_T3 = Kys0140.3,
PA_frqbct_04_T1 = Kys0141.1,
PA_frqbct_04_T3 = Kys0141.3,
PA_frqbct_05_T1 = Kys0142.1,
PA_frqbct_05_T3 = Kys0142.3,
PA_frqbct_06_T1 = Kys0143.1,
PA_frqbct_06_T3 = Kys0143.3,
PA_frqbct_07_T1 = Kys0144.1,
PA_frqbct_07_T3 = Kys0144.3,
PA_frqbct_08_T1 = Kys0145.1,
PA_frqbct_08_T3 = Kys0145.3,
PA_frqbct_09_T1 = Kys0146.1,
PA_frqbct_09_T3 = Kys0146.3,
PA_goal_01_T1 = Kys0147.1,
PA_goal_01_T3 = Kys0147.3,
PA_autonomous_01_T1 = Kys0087.1,
PA_autonomous_01_T3 = Kys0087.3,
PA_autonomous_02_T1 = Kys0088.1,
PA_autonomous_02_T3 = Kys0088.3,
PA_autonomous_03_T1 = Kys0090.1,
PA_autonomous_03_T3 = Kys0090.3,
PA_inorm_01_T1 = Kys0108.1,
PA_inorm_01_T3 = Kys0108.3,
PA_autonomous_04_T1 = Kys0089.1,
PA_autonomous_04_T3 = Kys0089.3,
PA_autonomous_05_T1 = Kys0092.1,
PA_autonomous_05_T3 = Kys0092.3,
PA_autonomous_06_T1 = Kys0094.1,
PA_autonomous_06_T3 = Kys0094.3,
PA_intention_01_T1 = Kys0113.1,
PA_intention_01_T3 = Kys0113.3,
PA_intention_02_T1 = Kys0114.1,
PA_intention_02_T3 = Kys0114.3,
PA_autonomous_07_T1 = Kys0091.1,
PA_autonomous_07_T3 = Kys0091.3,
PA_autonomous_08_T1 = Kys0093.1,
PA_autonomous_08_T3 = Kys0093.3,
PA_autonomous_09_T1 = Kys0095.1,
PA_autonomous_09_T3 = Kys0095.3,
PA_controlled_04_T1 = Kys0084.1,
PA_controlled_04_T3 = Kys0084.3,
PA_controlled_05_T1 = Kys0085.1,
PA_controlled_05_T3 = Kys0085.3,
PA_outcomeExpectations_01_T1 = Kys0068.1,
PA_outcomeExpectations_01_T3 = Kys0068.3,
PA_outcomeExpectations_03_T1 = Kys0070.1,
PA_outcomeExpectations_03_T3 = Kys0070.3,
PA_outcomeExpectations_04_T1 = Kys0071.1,
PA_outcomeExpectations_04_T3 = Kys0071.3,
PA_outcomeExpectations_05_T1 = Kys0072.1,
PA_outcomeExpectations_05_T3 = Kys0072.3,
PA_outcomeExpectations_06_T1 = Kys0073.1,
PA_outcomeExpectations_06_T3 = Kys0073.3,
PA_outcomeExpectations_07_T1 = Kys0074.1,
PA_outcomeExpectations_07_T3 = Kys0074.3,
PA_outcomeExpectations_10_T1 = Kys0077.1,
PA_outcomeExpectations_10_T3 = Kys0077.3,
PA_outcomeExpectations_11_T1 = Kys0078.1,
PA_outcomeExpectations_11_T3 = Kys0078.3,
PA_outcomeExpectations_12_T1 = Kys0079.1,
PA_outcomeExpectations_12_T3 = Kys0079.3,
PA_outcomeExpectationsNegative_02_T1 = Kys0069.1,
PA_outcomeExpectationsNegative_02_T3 = Kys0069.3,
PA_outcomeExpectationsNegative_08_T1 = Kys0075.1,
PA_outcomeExpectationsNegative_08_T3 = Kys0075.3,
PA_outcomeExpectationsNegative_09_T1 = Kys0076.1,
PA_outcomeExpectationsNegative_09_T3 = Kys0076.3,
PA_opportunities_01_T1 = Kys0098.1,
PA_opportunities_01_T3 = Kys0098.3,
PA_opportunities_02_T1 = Kys0099.1,
PA_opportunities_02_T3 = Kys0099.3,
PA_opportunities_04_T1 = Kys0101.1,
PA_opportunities_04_T3 = Kys0101.3,
PA_opportunities_05_T1 = Kys0102.1,
PA_opportunities_05_T3 = Kys0102.3,
PA_opportunities_07_T1 = Kys0104.1,
PA_opportunities_07_T3 = Kys0104.3,
PA_opportunitiesReverseCoded_03_T1 = Kys0100.1,
PA_opportunitiesReverseCoded_03_T3 = Kys0100.3,
PA_opportunitiesReverseCoded_06_T1 = Kys0103.1,
PA_opportunitiesReverseCoded_06_T3 = Kys0103.3,
PA_opportunitiesReverseCoded_08_T1 = Kys0105.1,
# No answers or not asked T3: PA_opportunitiesReverseCoded_08_T3 = Kys0105.3,
PA_pbc_01_T1 = Kys0125.1,
PA_pbc_01_T3 = Kys0125.3,
PA_pbc_03_T1 = Kys0127.1,
PA_pbc_03_T3 = Kys0127.3,
PA_pbcReverseCoded_02_T1 = Kys0126.1,
PA_pbcReverseCoded_02_T3 = Kys0126.3,
PA_selfefficacy_01_T1 = Kys0123.1,
PA_selfefficacy_01_T3 = Kys0123.3,
PA_selfefficacyReverseCoded_02_T1 = Kys0124.1,
PA_selfefficacyReverseCoded_02_T3 = Kys0124.3,
paAccelerometer_T1 = LiikuntaT1_ka,
paAccelerometer_T3 = LiikuntaT3_ka,
padaysLastweek_T1 = Kys0045.1,
padaysLastweek_T3 = Kys0045.3,
pafreqUsually_T1 = Kys0048.1,
pafreqUsually_T3 = Kys0048.3,
pahrsLastweek_T1 = Kys0046.1,
pahrsLastweek_T3 = Kys0046.3,
pahrsUsually_T1 = Kys0049.1,
pahrsUsually_T3 = Kys0049.3,
paminLastweek_T1 = Kys0047.1,
paminLastweek_T3 = Kys0047.3,
SB_dnorm_01_T1 = Kys0178.1,
SB_dnorm_01_T3 = Kys0178.3,
SB_dnorm_02_T1 = Kys0179.1,
SB_dnorm_02_T3 = Kys0179.3,
SB_inorm_01_T1 = Kys0180.1,
SB_inorm_01_T3 = Kys0180.3,
SB_inorm_02_T1 = Kys0181.1,
SB_inorm_02_T3 = Kys0181.3,
SB_intention_01_T1 = Kys0187.1,
SB_intention_01_T3 = Kys0187.3,
SB_intention_02_T1 = Kys0188.1,
SB_intention_02_T3 = Kys0188.3,
SB_intention_03_T1 = Kys0189.1,
SB_intention_03_T3 = Kys0189.3,
SB_intention_04_T1 = Kys0190.1,
SB_intention_04_T3 = Kys0190.3,
SB_outcomeExpectationsNegative_01_T1 = Kys0171.1,
SB_outcomeExpectationsNegative_01_T3 = Kys0171.3,
SB_outcomeExpectations_02_T1 = Kys0172.1,
SB_outcomeExpectations_02_T3 = Kys0172.3,
SB_outcomeExpectations_03_T1 = Kys0173.1,
SB_outcomeExpectations_03_T3 = Kys0173.3,
SB_outcomeExpectations_04_T1 = Kys0174.1,
SB_outcomeExpectations_04_T3 = Kys0174.3,
SB_outcomeExpectations_05_T1 = Kys0175.1,
SB_outcomeExpectations_05_T3 = Kys0175.3,
SB_outcomeExpectations_06_T1 = Kys0176.1,
SB_outcomeExpectations_06_T3 = Kys0176.3,
SB_outcomeExpectationsNegative_07_T1 = Kys0177.1,
SB_outcomeExpectationsNegative_07_T3 = Kys0177.3,
SB_sePbc_01_T1 = Kys0182.1,
SB_sePbc_01_T3 = Kys0182.3,
SB_sePbc_02_T1 = Kys0183.1,
SB_sePbc_02_T3 = Kys0183.3,
SB_sePbc_03_T1 = Kys0184.1,
SB_sePbc_03_T3 = Kys0184.3,
SB_sePbc_04_T1 = Kys0185.1,
SB_sePbc_04_T3 = Kys0185.3,
SB_sePbc_05_T1 = Kys0186.1,
SB_sePbc_05_T3 = Kys0186.3,
sitLieAccelerometer_T1 = MaIsT1_ka,
sitLieAccelerometer_T3 = MaIsT3_ka,
symptom_neckShoulderPain_T1 = Kys0031.1,
symptom_neckShoulderPain_T3 = Kys0031.3,
symptom_lowerBackPain_T1 = Kys0032.1,
symptom_lowerBackPain_T3 = Kys0032.3,
symptom_stomachAche_T1 = Kys0033.1,
symptom_stomachAche_T3 = Kys0033.3,
symptom_tensionNervousness_T1 = Kys0034.1,
symptom_tensionNervousness_T3 = Kys0034.3,
symptom_irritabilityAngerbursts_T1 = Kys0035.1,
symptom_irritabilityAngerbursts_T3 = Kys0035.3,
symptom_sleepDifficulty_T1 = Kys0036.1,
symptom_sleepDifficulty_T3 = Kys0036.3,
symptom_headAche_T1 = Kys0037.1,
symptom_headAche_T3 = Kys0037.3,
symptom_tirednessFaintness_T1 = Kys0038.1,
symptom_tirednessFaintness_T3 = Kys0038.3,
PA_actplan_01_T1 = Kys0115.1,
PA_actplan_02_T1 = Kys0116.1,
PA_actplan_03_T1 = Kys0117.1,
PA_actplan_04_T1 = Kys0118.1,
PA_copplan_01_T1 = Kys0119.1,
PA_copplan_02_T1 = Kys0120.1,
PA_copplan_03_T1 = Kys0121.1,
PA_copplan_04_T1 = Kys0122.1,
PA_actplan_01_T3 = Kys0115.3,
PA_actplan_02_T3 = Kys0116.3,
PA_actplan_03_T3 = Kys0117.3,
PA_actplan_04_T3 = Kys0118.3,
PA_copplan_01_T3 = Kys0119.3,
PA_copplan_02_T3 = Kys0120.3,
PA_copplan_03_T3 = Kys0121.3,
PA_copplan_04_T3 = Kys0122.3,
sitBreaks_T1 = YlosT1_ka
)

# Reverse coded items to normal: 
# Take vars that contain &quot;ReverseCoded_&quot;, substract them from 8 (each scale is 1-7)
d &lt;- d %&gt;% mutate_at(dplyr::vars(contains(&quot;ReverseCoded_&quot;)), funs(8 - .))

# To check:
# d %&gt;% select(contains(&quot;ReverseCoded_&quot;)), contains(&quot;Rev&quot;)) %&gt;% View
identical(as.numeric(8 - lmi$Kys0154.1), as.numeric(d$b5extReverseCoded_02_T1))
## [1] TRUE
identical(as.numeric(8 - lmi$Kys0100.1), as.numeric(d$PA_opportunitiesReverseCoded_03_T1))
## [1] TRUE

# Group variable has empty missings
d &lt;- d %&gt;% dplyr::mutate(group = ifelse(group == &quot;&quot;, NA, group))

# Create grouping variable, which indicates  

# Fix intervention and gender variables
d &lt;- d %&gt;% dplyr::mutate(intervention = ifelse(intervention == 1, 1, 0),
                         intervention = factor(intervention),
            girl = ifelse(girl == 2, 1, 0),
            girl = factor(girl, levels = c(&quot;1&quot;, &quot;0&quot;)),
            school = factor(school, levels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;)))

# Create the self-reported PA time variable
d &lt;- d %&gt;% dplyr::mutate(paLastweek_T1 = (pahrsLastweek_T1 * 60) + ifelse(paminLastweek_T1 == 2, 30, 0))

# Insert track variable with those who answered &quot;other&quot; with one of the actual category labels given the appropriate category:
track &lt;- lmi %&gt;% select(Kys0016.1, Kys0017.1) %&gt;% mutate(
  Kys0016.1 = ifelse(Kys0017.1 == &quot;Merkonomi&quot; | Kys0017.1 == &quot;merkonomi&quot;, 3,
                  ifelse(Kys0017.1 == &quot;Datanomi&quot; | Kys0017.1 == &quot;datanomi&quot;, 2, Kys0016.1)),
  track = factor(Kys0016.1, # Fix track labels first
                     levels = c(0, 1, 2, 3, 4),
                     labels = c(&quot;Other&quot;, &quot;Business IT&quot;, &quot;Business Admin&quot;, &quot;HRC&quot;, &quot;Nursing&quot;))) %&gt;% 
  select(-Kys0016.1, -Kys0017.1)

d &lt;- bind_cols(d, track)

# Separate variables for scale-creation purposes
dT1 &lt;- d %&gt;% select(contains(&quot;T1&quot;))
dT3 &lt;- d %&gt;% select(contains(&quot;T3&quot;))

# Create T1 scales

scales_T1 &lt;- list(b5agr_T1 = grep(&#39;b5agr&#39;, names(dT1), value = TRUE),
b5cons_T1 = grep(&#39;b5cons&#39;, names(dT1), value = TRUE),
b5ext_T1 = grep(&#39;b5ext&#39;, names(dT1), value = TRUE),
b5neur_T1 = grep(&#39;b5neur&#39;, names(dT1), value = TRUE),
b5open_T1 = grep(&#39;b5open&#39;, names(dT1), value = TRUE),
PA_actCop_T1 = grep(&#39;PA_actCop&#39;, names(dT1), value = TRUE),
PA_agrbct_T1 = grep(&#39;PA_agrbct&#39;, names(dT1), value = TRUE),
PA_amotivation_T1 = grep(&#39;PA_amotivation&#39;, names(dT1), value = TRUE),
PA_autonomous_T1 = grep(&#39;PA_autonomous&#39;, names(dT1), value = TRUE),
PA_controlled_T1 = grep(&#39;PA_controlled&#39;, names(dT1), value = TRUE),
PA_dnorm_T1 = grep(&#39;PA_dnorm&#39;, names(dT1), value = TRUE),
PA_frqbct_T1 = grep(&#39;PA_frqbct&#39;, names(dT1), value = TRUE),
PA_goal_T1 = grep(&#39;PA_goal&#39;, names(dT1), value = TRUE),
PA_inorm_T1 = grep(&#39;PA_inorm&#39;, names(dT1), value = TRUE),
PA_intention_T1 = grep(&#39;PA_intention&#39;, names(dT1), value = TRUE),
PA_outcomeExpectations_T1 = grep(&#39;PA_outcomeExpectations&#39;, names(dT1), value = TRUE),
PA_opportunities_T1 = grep(&#39;PA_opportunities&#39;, names(dT1), value = TRUE),
PA_pbc_T1 = grep(&#39;PA_pbc&#39;, names(dT1), value = TRUE),
PA_selfefficacy_T1 = grep(&#39;PA_selfefficacy&#39;, names(dT1), value = TRUE),
SB_dnorm_T1 = grep(&#39;SB_dnorm&#39;, names(dT1), value = TRUE),
SB_inorm_T1 = grep(&#39;SB_inorm&#39;, names(dT1), value = TRUE),
SB_intention_T1 = grep(&#39;SB_intention&#39;, names(dT1), value = TRUE),
SB_outcomeExpectations_T1 = grep(&#39;SB_outcomeExpectations&#39;, names(dT1), value = TRUE),
SB_sePbc_T1 = grep(&#39;SB_sePbc&#39;, names(dT1), value = TRUE),
symptom_T1 = grep(&#39;symptom&#39;, names(dT1), value = TRUE),
PA_actionplan_T1 = grep(&#39;actplan&#39;, names(dT1), value = TRUE),
PA_copingplan_T1 = grep(&#39;copplan&#39;, names(dT1), value = TRUE)
)

# Append the aggregate variables to the data frame
newdf &lt;- userfriendlyscience::makeScales(dT1, scales_T1)

# Create T3 scales

scales_T3 &lt;- list(b5agr_T3 = grep(&#39;b5agr&#39;, names(dT3), value = TRUE),
b5cons_T3 = grep(&#39;b5cons&#39;, names(dT3), value = TRUE),
b5ext_T3 = grep(&#39;b5ext&#39;, names(dT3), value = TRUE),
b5neur_T3 = grep(&#39;b5neur&#39;, names(dT3), value = TRUE),
b5open_T3 = grep(&#39;b5open&#39;, names(dT3), value = TRUE),
PA_actCop_T3 = grep(&#39;PA_actCop&#39;, names(dT3), value = TRUE),
PA_agrbct_T3 = grep(&#39;PA_agrbct&#39;, names(dT3), value = TRUE),
PA_amotivation_T3 = grep(&#39;PA_amotivation&#39;, names(dT3), value = TRUE),
PA_autonomous_T3 = grep(&#39;PA_autonomous&#39;, names(dT3), value = TRUE),
PA_controlled_T3 = grep(&#39;PA_controlled&#39;, names(dT3), value = TRUE),
PA_dnorm_T3 = grep(&#39;PA_dnorm&#39;, names(dT3), value = TRUE),
PA_frqbct_T3 = grep(&#39;PA_frqbct&#39;, names(dT3), value = TRUE),
PA_goal_T3 = grep(&#39;PA_goal&#39;, names(dT3), value = TRUE),
PA_inorm_T3 = grep(&#39;PA_inorm&#39;, names(dT3), value = TRUE),
PA_intention_T3 = grep(&#39;PA_intention&#39;, names(dT3), value = TRUE),
PA_outcomeExpectations_T3 = grep(&#39;PA_outcomeExpectations&#39;, names(dT3), value = TRUE),
PA_opportunities_T3 = grep(&#39;PA_opportunities&#39;, names(dT3), value = TRUE),
PA_pbc_T3 = grep(&#39;PA_pbc&#39;, names(dT3), value = TRUE),
PA_selfefficacy_T3 = grep(&#39;PA_selfefficacy&#39;, names(dT3), value = TRUE),
SB_dnorm_T3 = grep(&#39;SB_dnorm&#39;, names(dT3), value = TRUE),
SB_inorm_T3 = grep(&#39;SB_inorm&#39;, names(dT3), value = TRUE),
SB_intention_T3 = grep(&#39;SB_intention&#39;, names(dT3), value = TRUE),
SB_outcomeExpectations_T3 = grep(&#39;SB_outcomeExpectations&#39;, names(dT3), value = TRUE),
SB_sePbc_T3 = grep(&#39;SB_sePbc&#39;, names(dT3), value = TRUE),
symptom_T3 = grep(&#39;symptom&#39;, names(dT3), value = TRUE),
PA_actionplan_T3 = grep(&#39;actplan&#39;, names(dT3), value = TRUE),
PA_copingplan_T3 = grep(&#39;copplan&#39;, names(dT3), value = TRUE)
)

# Append the aggregate variables to the data frame
newdf2 &lt;- userfriendlyscience::makeScales(dT3, scales_T3)

# Take the demographic variables from d, combine with the variables with T1 or T3 in the name. 
df &lt;- cbind(d[ , c(&quot;id&quot;, &quot;intervention&quot;, &quot;group&quot;, &quot;school&quot;, &quot;girl&quot;, &quot;track&quot;)], newdf[, ], newdf2[, ])

# Create composite of self-efficacy and perceived behavioural control
df &lt;- df %&gt;% rowwise %&gt;%
    mutate(PA_sePbc_T1 = mean(c(PA_pbc_T1, PA_selfefficacy_T1), na.rm = T),
           PA_sePbc_T3 = mean(c(PA_pbc_T3, PA_selfefficacy_T3), na.rm = T))
## Fix the &quot;NaN&quot;s
df$PA_sePbc_T1[is.nan(df$PA_sePbc_T1)] &lt;- NA
df$PA_sePbc_T3[is.nan(df$PA_sePbc_T3)] &lt;- NA

# Create composite of action planning and coping planning
df &lt;- df %&gt;% rowwise %&gt;%
    mutate(PA_actCop_T1 = mean(c(PA_actionplan_T1, PA_copingplan_T1), na.rm = T),
           PA_actCop_T3 = mean(c(PA_actionplan_T3, PA_copingplan_T3), na.rm = T))
## Fix the &quot;NaN&quot;s
df$PA_actCop_T1[is.nan(df$PA_actCop_T1)] &lt;- NA
df$PA_actCop_T3[is.nan(df$PA_actCop_T3)] &lt;- NA

# Create variables for motivational regulations

regulationVariables_T1 &lt;- lmi %&gt;% select(
  PA_extrinsic_01_T1 = Kys0080.1,
  PA_extrinsic_02_T1 = Kys0081.1,
  PA_extrinsic_03_T1 = Kys0083.1,
  PA_introjected_01_T1 = Kys0084.1,
  PA_introjected_02_T1 = Kys0085.1,
  PA_identified_01_T1 = Kys0087.1,
  PA_identified_02_T1 = Kys0088.1,
  PA_identified_03_T1 = Kys0090.1,
  PA_integrated_01_T1 = Kys0089.1,
  PA_integrated_02_T1 = Kys0092.1,
  PA_integrated_03_T1 = Kys0094.1,
  PA_intrinsic_01_T1 = Kys0091.1,
  PA_intrinsic_02_T1 = Kys0093.1,
  PA_intrinsic_03_T1 = Kys0095.1)

regulationVariables_T3 &lt;- lmi %&gt;% select(
  PA_extrinsic_01_T3 = Kys0080.3,
  PA_extrinsic_02_T3 = Kys0081.3,
  PA_extrinsic_03_T3 = Kys0083.3,
  PA_introjected_01_T3 = Kys0084.3,
  PA_introjected_02_T3 = Kys0085.3,
  PA_identified_01_T3 = Kys0087.3,
  PA_identified_02_T3 = Kys0088.3,
  PA_identified_03_T3 = Kys0090.3,
  PA_integrated_01_T3 = Kys0089.3,
  PA_integrated_02_T3 = Kys0092.3,
  PA_integrated_03_T3 = Kys0094.3,
  PA_intrinsic_01_T3 = Kys0091.3,
  PA_intrinsic_02_T3 = Kys0093.3,
  PA_intrinsic_03_T3 = Kys0095.3
)

motiscales_T1 &lt;- list(
  PA_intrinsic_T1 = grep(&#39;intrinsic&#39;, names(regulationVariables_T1), value = TRUE),
  PA_integrated_T1 = grep(&#39;integrated&#39;, names(regulationVariables_T1), value = TRUE),
  PA_identified_T1 = grep(&#39;identified&#39;, names(regulationVariables_T1), value = TRUE),
  PA_introjected_T1 = grep(&#39;introjected&#39;, names(regulationVariables_T1), value = TRUE),
  PA_extrinsic_T1 = grep(&#39;extrinsic&#39;, names(regulationVariables_T1), value = TRUE))

motiscales_T3 &lt;- list(
  PA_intrinsic_T3 = grep(&#39;intrinsic&#39;, names(regulationVariables_T3), value = TRUE),
  PA_integrated_T3 = grep(&#39;integrated&#39;, names(regulationVariables_T3), value = TRUE),
  PA_identified_T3 = grep(&#39;identified&#39;, names(regulationVariables_T3), value = TRUE),
  PA_introjected_T3 = grep(&#39;introjected&#39;, names(regulationVariables_T3), value = TRUE),
  PA_extrinsic_T3 = grep(&#39;extrinsic&#39;, names(regulationVariables_T3), value = TRUE))

motidf1 &lt;- userfriendlyscience::makeScales(regulationVariables_T1, motiscales_T1)
motidf2 &lt;- userfriendlyscience::makeScales(regulationVariables_T3, motiscales_T3)

df &lt;- cbind(df, motidf1, motidf2)

# Create change scores
t1_vars &lt;- grep(&quot;_T1&quot;, colnames(df), value = TRUE)
t1_vars &lt;- grep(&quot;b5|fat|paLastweek|PA_opportunitiesReverseCoded_08|sitBreaks_T1&quot;, t1_vars, value = TRUE, invert = TRUE) # drop variables not in T3
t3_vars &lt;- grep(&quot;_T3&quot;, colnames(df), value = TRUE)
df[, paste0(stringr::str_sub(t1_vars, end = -4), &quot;_diff&quot;)] &lt;- df[, t3_vars] - df[, t1_vars]

# Create a combination of track and school variables
df &lt;- df %&gt;% dplyr::mutate(trackSchool = paste0(track, school)) </code></pre>
</div>
<div id="means-with-cis-taking-clustering-into-account" class="section level1">
<h1>Means with CIs taking clustering into account</h1>
<p>The code chunks below create linear models for all variables. The results are used to estimate confidence intervals and intra-class correlations (ICC)</p>
<div id="create-a-table-with-all-variables-their-means-cis-and-iccs." class="section level2">
<h2>Create a table with all variables, their means, CIs and ICCs.</h2>
<p>This table contains all variables with their ICCs.</p>
<pre class="r"><code># Create a vector with all names of the variables we want. Exclude T3 variables.
names &lt;- df %&gt;% select(-id, -intervention, -group, -school, -girl, -track, -trackSchool, -contains(&quot;_T3&quot;), -contains(&quot;_diff&quot;)) %&gt;% names(.)

# Create empty soon-to-be-filled objects
m &lt;- NA
mean &lt;- NA
m_p &lt;- NA
ci_low &lt;- NA
ci_high &lt;- NA
ICC_group &lt;- NA
ICC_School &lt;- NA
nonmissings &lt;- NA

## Use this to test a single variable:
# dftest &lt;- df #%&gt;% na.omit()
# m &lt;- lme4::lmer(sitLieAccelerometer_diff ~ (1|school) + (1|group), data=dftest)
# mean &lt;- lme4::fixef(m)
# m_p &lt;- profile(m, which = &quot;beta_&quot;)
# ci_low &lt;- confint(m_p)[, 1]
# ci_high &lt;- confint(m_p)[, 2]
# ICC_group &lt;- icc(m)[1]
# ICC_School &lt;- icc(m)[2]
# nonmissings &lt;- length(m@resp$y)


# Loop over each variable name, extract statistics: 

# all participants
for (i in names){
m &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group)&quot;), data=df)
mean[i] &lt;- lme4::fixef(m)
m_p &lt;- profile(m, which = &quot;beta_&quot;)
ci_low[i] &lt;- confint(m_p)[, 1]
ci_high[i] &lt;- confint(m_p)[, 2]
ICC_group[i] &lt;- sjstats::icc(m)[1]
ICC_School[i] &lt;- sjstats::icc(m)[2]
nonmissings[i] &lt;- length(m@resp$y)
}
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation


vardatatable &lt;- data_frame(
  Variable = stringr::str_sub(names(mean), end = -4), #remove &quot;_T1&quot; from names
  Mean = round(mean, 2), 
  CI95 = paste(round(ci_low, 2), &quot;-&quot;, round(ci_high, 2)), 
  &quot;ICC class&quot; =ifelse(round(ICC_group, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_group, 3)), 
  &quot;ICC school&quot; = ifelse(round(ICC_School, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_School, 3)),
  n = nonmissings) %&gt;% 
  dplyr::arrange(Variable) %&gt;% 
  filter(Variable != &quot;&quot;) %&gt;% #remove first row, which is empty
  mutate(`ICC class` = as.numeric(`ICC class`)) %&gt;% 
  as.data.frame()
## Warning in evalq(as.numeric(`ICC class`), &lt;environment&gt;): NAs introduced by
## coercion</code></pre>
<div id="selected-items" class="section level3">
<h3>Selected items</h3>
<pre class="r"><code>options(tibble.print_max = 1000)
 
vardatatable %&gt;% 
  filter(Variable == &quot;paAccelerometer&quot; | Variable == &quot;fatpct&quot; | Variable == &quot;sitLieAccelerometer&quot; | Variable == &quot;sitBreaks&quot;) %&gt;% 
    papaja::apa_table(
        caption = &quot;All variables with their class and school ICCs&quot;,
        escape = T,
        digits = c(0, 2, 0, 0, 0, 0))</code></pre>
<caption>
(#tab:selected-total)
</caption>
<caption>
<em>All variables with their class and school ICCs</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Mean</th>
<th align="left">CI95</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fatpct</td>
<td align="left">26</td>
<td align="left">22.38 - 28.67</td>
<td align="left">0</td>
<td align="left">0.123</td>
<td align="left">942</td>
</tr>
<tr class="even">
<td align="left">paAccelerometer</td>
<td align="left">183.13</td>
<td align="left">165.99 - 200.45</td>
<td align="left">0.07</td>
<td align="left">0.096</td>
<td align="left">706.00</td>
</tr>
<tr class="odd">
<td align="left">sitBreaks</td>
<td align="left">28</td>
<td align="left">24.69 - 31.37</td>
<td align="left">0</td>
<td align="left">0.085</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">sitLieAccelerometer</td>
<td align="left">574</td>
<td align="left">535.48 - 611.8</td>
<td align="left">0</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
</tbody>
</table>
</div>
<div id="all-items" class="section level3">
<h3>All items</h3>
<pre class="r"><code>options(tibble.print_max = 1000)
 
vardatatable %&gt;%
    papaja::apa_table(
        caption = &quot;All variables with their class and school ICCs&quot;,
        escape = T,
        digits = c(1, 2, 2, 3, 3, 0))</code></pre>
<caption>
(#tab:allvars-total)
</caption>
<caption>
<em>All variables with their class and school ICCs</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Mean</th>
<th align="left">CI95</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b5agr</td>
<td align="left">5.3</td>
<td align="left">5.18 - 5.5</td>
<td align="left">0.0</td>
<td align="left">0.012</td>
<td align="left">1,068.0</td>
</tr>
<tr class="even">
<td align="left">b5agr_01</td>
<td align="left">5.51</td>
<td align="left">5.38 - 5.66</td>
<td align="left">0.04</td>
<td align="left">0.002</td>
<td align="left">1,061.00</td>
</tr>
<tr class="odd">
<td align="left">b5agrReverseCoded_02</td>
<td align="left">5.16</td>
<td align="left">4.95 - 5.37</td>
<td align="left">0.00</td>
<td align="left">0.01</td>
<td align="left">1,064.00</td>
</tr>
<tr class="even">
<td align="left">b5cons</td>
<td align="left">5.030</td>
<td align="left">4.91 - 5.17</td>
<td align="left">NA</td>
<td align="left">0.007</td>
<td align="left">1,067.000</td>
</tr>
<tr class="odd">
<td align="left">b5cons_01</td>
<td align="left">5.440</td>
<td align="left">5.25 - 5.65</td>
<td align="left">0.014</td>
<td align="left">0.015</td>
<td align="left">1,059.000</td>
</tr>
<tr class="even">
<td align="left">b5consReverseCoded_02</td>
<td align="left">5</td>
<td align="left">4.49 - 4.78</td>
<td align="left">NA</td>
<td align="left">0.002</td>
<td align="left">1,065</td>
</tr>
<tr class="odd">
<td align="left">b5ext</td>
<td align="left">4.5</td>
<td align="left">4.3 - 4.77</td>
<td align="left">0.0</td>
<td align="left">0.022</td>
<td align="left">1,068.0</td>
</tr>
<tr class="even">
<td align="left">b5ext_01</td>
<td align="left">4.97</td>
<td align="left">4.73 - 5.24</td>
<td align="left">0.05</td>
<td align="left">0.013</td>
<td align="left">1,063.00</td>
</tr>
<tr class="odd">
<td align="left">b5extReverseCoded_02</td>
<td align="left">4.07</td>
<td align="left">3.84 - 4.32</td>
<td align="left">0.00</td>
<td align="left">0.012</td>
<td align="left">1,062.00</td>
</tr>
<tr class="even">
<td align="left">b5neur</td>
<td align="left">3.820</td>
<td align="left">3.64 - 4</td>
<td align="left">0.014</td>
<td align="left">0.012</td>
<td align="left">1,068.000</td>
</tr>
<tr class="odd">
<td align="left">b5neur_01</td>
<td align="left">4.110</td>
<td align="left">3.85 - 4.39</td>
<td align="left">0.017</td>
<td align="left">0.014</td>
<td align="left">1,064.000</td>
</tr>
<tr class="even">
<td align="left">b5neurReverseCoded_02</td>
<td align="left">4</td>
<td align="left">3.39 - 3.67</td>
<td align="left">0</td>
<td align="left">0.002</td>
<td align="left">1,061</td>
</tr>
<tr class="odd">
<td align="left">b5open</td>
<td align="left">4.9</td>
<td align="left">4.67 - 5.12</td>
<td align="left">0.0</td>
<td align="left">0.03</td>
<td align="left">1,068.0</td>
</tr>
<tr class="even">
<td align="left">b5open_01</td>
<td align="left">5.35</td>
<td align="left">5.13 - 5.59</td>
<td align="left">0.02</td>
<td align="left">0.016</td>
<td align="left">1,062.00</td>
</tr>
<tr class="odd">
<td align="left">b5openReverseCoded_02</td>
<td align="left">4.42</td>
<td align="left">4.19 - 4.67</td>
<td align="left">NA</td>
<td align="left">0.016</td>
<td align="left">1,066.00</td>
</tr>
<tr class="even">
<td align="left">fatpct</td>
<td align="left">25.520</td>
<td align="left">22.38 - 28.67</td>
<td align="left">0.003</td>
<td align="left">0.123</td>
<td align="left">942.000</td>
</tr>
<tr class="odd">
<td align="left">PA_actCop</td>
<td align="left">2.630</td>
<td align="left">2.56 - 2.69</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.000</td>
</tr>
<tr class="even">
<td align="left">PA_actionplan</td>
<td align="left">3</td>
<td align="left">2.69 - 2.83</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_01</td>
<td align="left">2.6</td>
<td align="left">2.52 - 2.68</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.0</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_02</td>
<td align="left">2.80</td>
<td align="left">2.73 - 2.88</td>
<td align="left">0.03</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.00</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_03</td>
<td align="left">2.85</td>
<td align="left">2.78 - 2.93</td>
<td align="left">0.04</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.00</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_04</td>
<td align="left">2.780</td>
<td align="left">2.7 - 2.86</td>
<td align="left">0.038</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.000</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct</td>
<td align="left">3.110</td>
<td align="left">3 - 3.23</td>
<td align="left">0.052</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071.000</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_01</td>
<td align="left">4</td>
<td align="left">3.51 - 3.85</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_02</td>
<td align="left">3.2</td>
<td align="left">3.05 - 3.33</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071.0</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_03</td>
<td align="left">2.44</td>
<td align="left">2.31 - 2.57</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071.00</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_04</td>
<td align="left">2.52</td>
<td align="left">2.38 - 2.67</td>
<td align="left">0.04</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071.00</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_05</td>
<td align="left">2.630</td>
<td align="left">2.49 - 2.78</td>
<td align="left">0.055</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071.000</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_06</td>
<td align="left">3.220</td>
<td align="left">3.08 - 3.38</td>
<td align="left">0.028</td>
<td align="left">0.001</td>
<td align="left">1,071.000</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_07</td>
<td align="left">3</td>
<td align="left">2.91 - 3.16</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_08</td>
<td align="left">3.1</td>
<td align="left">2.97 - 3.25</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071.0</td>
</tr>
<tr class="even">
<td align="left">PA_agrbct_09</td>
<td align="left">3.67</td>
<td align="left">3.52 - 3.85</td>
<td align="left">0.03</td>
<td align="left">0.001</td>
<td align="left">1,071.00</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_10</td>
<td align="left">3.63</td>
<td align="left">3.48 - 3.79</td>
<td align="left">0.04</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071.00</td>
</tr>
<tr class="even">
<td align="left">PA_amotivation</td>
<td align="left">1.540</td>
<td align="left">1.45 - 1.61</td>
<td align="left">0.035</td>
<td align="left">0.002</td>
<td align="left">1,072.000</td>
</tr>
<tr class="odd">
<td align="left">PA_amotivation_01</td>
<td align="left">1.510</td>
<td align="left">1.44 - 1.59</td>
<td align="left">0.031</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,062.000</td>
</tr>
<tr class="even">
<td align="left">PA_amotivation_02</td>
<td align="left">2</td>
<td align="left">1.42 - 1.63</td>
<td align="left">0</td>
<td align="left">0.005</td>
<td align="left">1,057</td>
</tr>
<tr class="odd">
<td align="left">PA_amotivation_03</td>
<td align="left">1.6</td>
<td align="left">1.51 - 1.69</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,067.0</td>
</tr>
<tr class="even">
<td align="left">PA_amotivation_04</td>
<td align="left">1.47</td>
<td align="left">1.39 - 1.55</td>
<td align="left">0.03</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.00</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous</td>
<td align="left">3.41</td>
<td align="left">3.31 - 3.52</td>
<td align="left">0.07</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,078.00</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_01</td>
<td align="left">3.120</td>
<td align="left">2.96 - 3.29</td>
<td align="left">0.002</td>
<td align="left">0.012</td>
<td align="left">1,063.000</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_02</td>
<td align="left">3.760</td>
<td align="left">3.66 - 3.86</td>
<td align="left">0.031</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,063.000</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_03</td>
<td align="left">3</td>
<td align="left">3.24 - 3.51</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_04</td>
<td align="left">3.3</td>
<td align="left">3.17 - 3.47</td>
<td align="left">0.1</td>
<td align="left">0.004</td>
<td align="left">1,070.0</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_05</td>
<td align="left">3.26</td>
<td align="left">3.15 - 3.39</td>
<td align="left">0.05</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,062.00</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_06</td>
<td align="left">3.09</td>
<td align="left">2.96 - 3.22</td>
<td align="left">0.07</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.00</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_07</td>
<td align="left">3.720</td>
<td align="left">3.58 - 3.88</td>
<td align="left">0.072</td>
<td align="left">0.005</td>
<td align="left">1,070.000</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_08</td>
<td align="left">3.630</td>
<td align="left">3.53 - 3.76</td>
<td align="left">0.057</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.000</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_09</td>
<td align="left">4</td>
<td align="left">3.39 - 3.62</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,057</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled</td>
<td align="left">1.8</td>
<td align="left">1.78 - 1.9</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.0</td>
</tr>
<tr class="even">
<td align="left">PA_controlled_01</td>
<td align="left">1.66</td>
<td align="left">1.59 - 1.73</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,068.00</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled_02</td>
<td align="left">1.48</td>
<td align="left">1.41 - 1.55</td>
<td align="left">0.02</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069.00</td>
</tr>
<tr class="even">
<td align="left">PA_controlled_03</td>
<td align="left">1.550</td>
<td align="left">1.49 - 1.61</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064.000</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled_04</td>
<td align="left">2.180</td>
<td align="left">2.08 - 2.28</td>
<td align="left">NA</td>
<td align="left">0.001</td>
<td align="left">1,068.000</td>
</tr>
<tr class="even">
<td align="left">PA_controlled_05</td>
<td align="left">2</td>
<td align="left">2.22 - 2.4</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="odd">
<td align="left">PA_copingplan</td>
<td align="left">2.5</td>
<td align="left">2.44 - 2.56</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.0</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_01</td>
<td align="left">2.41</td>
<td align="left">2.34 - 2.47</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.00</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_02</td>
<td align="left">2.43</td>
<td align="left">2.37 - 2.5</td>
<td align="left">0.00</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.00</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_03</td>
<td align="left">2.460</td>
<td align="left">2.39 - 2.54</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.000</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_04</td>
<td align="left">2.690</td>
<td align="left">2.62 - 2.77</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.000</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm</td>
<td align="left">4</td>
<td align="left">4.24 - 4.58</td>
<td align="left">0</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">4.5</td>
<td align="left">4.3 - 4.71</td>
<td align="left">0.0</td>
<td align="left">0.004</td>
<td align="left">1,073.0</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm_02</td>
<td align="left">4.31</td>
<td align="left">4.11 - 4.52</td>
<td align="left">0.03</td>
<td align="left">0.004</td>
<td align="left">1,073.00</td>
</tr>
<tr class="odd">
<td align="left">PA_extrinsic</td>
<td align="left">1.56</td>
<td align="left">1.5 - 1.62</td>
<td align="left">0.02</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069.00</td>
</tr>
<tr class="even">
<td align="left">PA_extrinsic_01</td>
<td align="left">1.660</td>
<td align="left">1.59 - 1.73</td>
<td align="left">0.010</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,068.000</td>
</tr>
<tr class="odd">
<td align="left">PA_extrinsic_02</td>
<td align="left">1.480</td>
<td align="left">1.41 - 1.55</td>
<td align="left">0.024</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069.000</td>
</tr>
<tr class="even">
<td align="left">PA_extrinsic_03</td>
<td align="left">2</td>
<td align="left">1.49 - 1.61</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct</td>
<td align="left">2.5</td>
<td align="left">2.45 - 2.62</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.0</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_01</td>
<td align="left">3.73</td>
<td align="left">3.63 - 3.84</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.00</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_02</td>
<td align="left">1.87</td>
<td align="left">1.76 - 1.98</td>
<td align="left">0.02</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.00</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_03</td>
<td align="left">2.030</td>
<td align="left">1.93 - 2.13</td>
<td align="left">0.007</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.000</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_04</td>
<td align="left">1.900</td>
<td align="left">1.78 - 2.02</td>
<td align="left">0.035</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.000</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_05</td>
<td align="left">2</td>
<td align="left">2.36 - 2.64</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_06</td>
<td align="left">3.4</td>
<td align="left">3.29 - 3.54</td>
<td align="left">0.0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.0</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_07</td>
<td align="left">2.20</td>
<td align="left">2.1 - 2.3</td>
<td align="left">0.00</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.00</td>
</tr>
<tr class="odd">
<td align="left">PA_frqbct_08</td>
<td align="left">2.39</td>
<td align="left">2.28 - 2.5</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.00</td>
</tr>
<tr class="even">
<td align="left">PA_frqbct_09</td>
<td align="left">2.790</td>
<td align="left">2.67 - 2.9</td>
<td align="left">0.007</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.000</td>
</tr>
<tr class="odd">
<td align="left">PA_goal</td>
<td align="left">0.550</td>
<td align="left">0.51 - 0.59</td>
<td align="left">0.046</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,061.000</td>
</tr>
<tr class="even">
<td align="left">PA_goal_01</td>
<td align="left">1</td>
<td align="left">0.51 - 0.59</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,061</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">3.4</td>
<td align="left">3.3 - 3.54</td>
<td align="left">0.0</td>
<td align="left">0.004</td>
<td align="left">1,074.0</td>
</tr>
<tr class="even">
<td align="left">PA_identified_01</td>
<td align="left">3.12</td>
<td align="left">2.96 - 3.29</td>
<td align="left">0.00</td>
<td align="left">0.012</td>
<td align="left">1,063.00</td>
</tr>
<tr class="odd">
<td align="left">PA_identified_02</td>
<td align="left">3.76</td>
<td align="left">3.66 - 3.86</td>
<td align="left">0.03</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,063.00</td>
</tr>
<tr class="even">
<td align="left">PA_identified_03</td>
<td align="left">3.360</td>
<td align="left">3.24 - 3.51</td>
<td align="left">0.058</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070.000</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm</td>
<td align="left">4.660</td>
<td align="left">4.48 - 4.84</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073.000</td>
</tr>
<tr class="even">
<td align="left">PA_inorm_01</td>
<td align="left">5</td>
<td align="left">4.48 - 4.84</td>
<td align="left">0</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated</td>
<td align="left">3.2</td>
<td align="left">3.11 - 3.34</td>
<td align="left">0.1</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.0</td>
</tr>
<tr class="even">
<td align="left">PA_integrated_01</td>
<td align="left">3.30</td>
<td align="left">3.17 - 3.47</td>
<td align="left">0.06</td>
<td align="left">0.004</td>
<td align="left">1,070.00</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated_02</td>
<td align="left">3.26</td>
<td align="left">3.15 - 3.39</td>
<td align="left">0.05</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,062.00</td>
</tr>
<tr class="even">
<td align="left">PA_integrated_03</td>
<td align="left">3.090</td>
<td align="left">2.96 - 3.22</td>
<td align="left">0.072</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.000</td>
</tr>
<tr class="odd">
<td align="left">PA_intention</td>
<td align="left">5.380</td>
<td align="left">5.19 - 5.57</td>
<td align="left">0.105</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.000</td>
</tr>
<tr class="even">
<td align="left">PA_intention_01</td>
<td align="left">5</td>
<td align="left">5.16 - 5.55</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">5.4</td>
<td align="left">5.21 - 5.61</td>
<td align="left">0.1</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073.0</td>
</tr>
<tr class="even">
<td align="left">PA_intrinsic</td>
<td align="left">3.61</td>
<td align="left">3.51 - 3.74</td>
<td align="left">0.07</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074.00</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic_01</td>
<td align="left">3.72</td>
<td align="left">3.58 - 3.88</td>
<td align="left">0.07</td>
<td align="left">0.005</td>
<td align="left">1,070.00</td>
</tr>
<tr class="even">
<td align="left">PA_intrinsic_02</td>
<td align="left">3.630</td>
<td align="left">3.53 - 3.76</td>
<td align="left">0.057</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.000</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic_03</td>
<td align="left">3.500</td>
<td align="left">3.39 - 3.62</td>
<td align="left">0.055</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,057.000</td>
</tr>
<tr class="even">
<td align="left">PA_introjected</td>
<td align="left">2</td>
<td align="left">2.16 - 2.33</td>
<td align="left">NA</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected_01</td>
<td align="left">2.2</td>
<td align="left">2.08 - 2.28</td>
<td align="left">NA</td>
<td align="left">0.001</td>
<td align="left">1,068.0</td>
</tr>
<tr class="even">
<td align="left">PA_introjected_02</td>
<td align="left">2.31</td>
<td align="left">2.22 - 2.4</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.00</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities</td>
<td align="left">5.12</td>
<td align="left">5.05 - 5.19</td>
<td align="left">0.02</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075.00</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities_01</td>
<td align="left">4.650</td>
<td align="left">4.32 - 4.98</td>
<td align="left">0.037</td>
<td align="left">0.02</td>
<td align="left">1,070.000</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities_02</td>
<td align="left">5.500</td>
<td align="left">5.38 - 5.62</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,067.000</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities_04</td>
<td align="left">6</td>
<td align="left">5.37 - 5.75</td>
<td align="left">0</td>
<td align="left">0.008</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities_05</td>
<td align="left">5.3</td>
<td align="left">5.21 - 5.43</td>
<td align="left">NA</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064.0</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities_07</td>
<td align="left">4.63</td>
<td align="left">4.49 - 4.77</td>
<td align="left">0.01</td>
<td align="left">0.001</td>
<td align="left">1,068.00</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunitiesReverseCoded_03</td>
<td align="left">5.11</td>
<td align="left">5 - 5.23</td>
<td align="left">NA</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,065.00</td>
</tr>
<tr class="even">
<td align="left">PA_opportunitiesReverseCoded_06</td>
<td align="left">3.630</td>
<td align="left">3.31 - 3.95</td>
<td align="left">NA</td>
<td align="left">0.024</td>
<td align="left">1,059.000</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunitiesReverseCoded_08</td>
<td align="left">6.580</td>
<td align="left">6.49 - 6.68</td>
<td align="left">0.020</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.000</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations</td>
<td align="left">5</td>
<td align="left">4.48 - 4.74</td>
<td align="left">0</td>
<td align="left">0.013</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_01</td>
<td align="left">5.5</td>
<td align="left">5.27 - 5.7</td>
<td align="left">0.0</td>
<td align="left">0.011</td>
<td align="left">1,071.0</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_03</td>
<td align="left">5.20</td>
<td align="left">4.94 - 5.47</td>
<td align="left">0.01</td>
<td align="left">0.018</td>
<td align="left">1,064.00</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_04</td>
<td align="left">5.47</td>
<td align="left">5.3 - 5.65</td>
<td align="left">0.01</td>
<td align="left">0.007</td>
<td align="left">1,071.00</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_05</td>
<td align="left">5.190</td>
<td align="left">5 - 5.39</td>
<td align="left">0.023</td>
<td align="left">0.011</td>
<td align="left">1,067.000</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_06</td>
<td align="left">5.400</td>
<td align="left">5.18 - 5.63</td>
<td align="left">0.030</td>
<td align="left">0.016</td>
<td align="left">1,071.000</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_07</td>
<td align="left">5</td>
<td align="left">4.73 - 5.13</td>
<td align="left">0</td>
<td align="left">0.008</td>
<td align="left">1,062</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_10</td>
<td align="left">5.3</td>
<td align="left">5.18 - 5.54</td>
<td align="left">0.0</td>
<td align="left">0.006</td>
<td align="left">1,069.0</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_11</td>
<td align="left">5.13</td>
<td align="left">4.91 - 5.38</td>
<td align="left">0.06</td>
<td align="left">0.011</td>
<td align="left">1,063.00</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations_12</td>
<td align="left">5.19</td>
<td align="left">4.95 - 5.45</td>
<td align="left">0.04</td>
<td align="left">0.014</td>
<td align="left">1,070.00</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectationsNegative_02</td>
<td align="left">2.870</td>
<td align="left">2.73 - 3.02</td>
<td align="left">0.046</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066.000</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectationsNegative_08</td>
<td align="left">2.530</td>
<td align="left">2.34 - 2.69</td>
<td align="left">0.038</td>
<td align="left">0.004</td>
<td align="left">1,063.000</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectationsNegative_09</td>
<td align="left">3</td>
<td align="left">2.45 - 2.68</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">PA_pbc</td>
<td align="left">5.3</td>
<td align="left">5.19 - 5.45</td>
<td align="left">0.0</td>
<td align="left">0.004</td>
<td align="left">1,071.0</td>
</tr>
<tr class="even">
<td align="left">PA_pbc_01</td>
<td align="left">5.86</td>
<td align="left">5.74 - 5.98</td>
<td align="left">0.03</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,069.00</td>
</tr>
<tr class="odd">
<td align="left">PA_pbc_03</td>
<td align="left">5.19</td>
<td align="left">4.97 - 5.4</td>
<td align="left">0.01</td>
<td align="left">0.01</td>
<td align="left">1,066.00</td>
</tr>
<tr class="even">
<td align="left">PA_pbcReverseCoded_02</td>
<td align="left">4.920</td>
<td align="left">4.7 - 5.11</td>
<td align="left">0.005</td>
<td align="left">0.005</td>
<td align="left">1,063.000</td>
</tr>
<tr class="odd">
<td align="left">PA_selfefficacy</td>
<td align="left">5.220</td>
<td align="left">5.1 - 5.35</td>
<td align="left">0.007</td>
<td align="left">0.005</td>
<td align="left">1,071.000</td>
</tr>
<tr class="even">
<td align="left">PA_selfefficacy_01</td>
<td align="left">6</td>
<td align="left">5.75 - 5.96</td>
<td align="left">0</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="odd">
<td align="left">PA_selfefficacyReverseCoded_02</td>
<td align="left">4.6</td>
<td align="left">4.41 - 4.77</td>
<td align="left">0.0</td>
<td align="left">0.005</td>
<td align="left">1,071.0</td>
</tr>
<tr class="even">
<td align="left">PA_sePbc</td>
<td align="left">5.27</td>
<td align="left">5.15 - 5.4</td>
<td align="left">0.03</td>
<td align="left">0.007</td>
<td align="left">1,071.00</td>
</tr>
<tr class="odd">
<td align="left">paAccelerometer</td>
<td align="left">183.13</td>
<td align="left">165.99 - 200.45</td>
<td align="left">0.07</td>
<td align="left">0.096</td>
<td align="left">706.00</td>
</tr>
<tr class="even">
<td align="left">padaysLastweek</td>
<td align="left">2.790</td>
<td align="left">2.63 - 2.95</td>
<td align="left">0.047</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082.000</td>
</tr>
<tr class="odd">
<td align="left">pafreqUsually</td>
<td align="left">2.560</td>
<td align="left">2.4 - 2.73</td>
<td align="left">0.094</td>
<td align="left">0.003</td>
<td align="left">1,082.000</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">5</td>
<td align="left">4.7 - 6.16</td>
<td align="left">0</td>
<td align="left">0.007</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">pahrsUsually</td>
<td align="left">3.1</td>
<td align="left">2.88 - 3.36</td>
<td align="left">0.1</td>
<td align="left">0.005</td>
<td align="left">1,082.0</td>
</tr>
<tr class="even">
<td align="left">paLastweek</td>
<td align="left">339.67</td>
<td align="left">295.99 - 382.07</td>
<td align="left">0.02</td>
<td align="left">0.006</td>
<td align="left">1,082.00</td>
</tr>
<tr class="odd">
<td align="left">paminLastweek</td>
<td align="left">1.44</td>
<td align="left">1.38 - 1.5</td>
<td align="left">NA</td>
<td align="left">0.01</td>
<td align="left">1,082.00</td>
</tr>
<tr class="even">
<td align="left">SB_dnorm</td>
<td align="left">3.250</td>
<td align="left">3.1 - 3.41</td>
<td align="left">0.003</td>
<td align="left">0.007</td>
<td align="left">1,062.000</td>
</tr>
<tr class="odd">
<td align="left">SB_dnorm_01</td>
<td align="left">3.070</td>
<td align="left">2.94 - 3.22</td>
<td align="left">NA</td>
<td align="left">0.004</td>
<td align="left">1,059.000</td>
</tr>
<tr class="even">
<td align="left">SB_dnorm_02</td>
<td align="left">3</td>
<td align="left">3.24 - 3.59</td>
<td align="left">0</td>
<td align="left">0.007</td>
<td align="left">1,060</td>
</tr>
<tr class="odd">
<td align="left">SB_inorm</td>
<td align="left">4.0</td>
<td align="left">3.9 - 4.14</td>
<td align="left">0.0</td>
<td align="left">0.004</td>
<td align="left">1,064.0</td>
</tr>
<tr class="even">
<td align="left">SB_inorm_01</td>
<td align="left">3.93</td>
<td align="left">3.76 - 4.11</td>
<td align="left">NA</td>
<td align="left">0.008</td>
<td align="left">1,056.00</td>
</tr>
<tr class="odd">
<td align="left">SB_inorm_02</td>
<td align="left">4.10</td>
<td align="left">3.95 - 4.28</td>
<td align="left">0.03</td>
<td align="left">0.005</td>
<td align="left">1,053.00</td>
</tr>
<tr class="even">
<td align="left">SB_intention</td>
<td align="left">3.740</td>
<td align="left">3.42 - 4.06</td>
<td align="left">0.014</td>
<td align="left">0.035</td>
<td align="left">1,064.000</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_01</td>
<td align="left">3.330</td>
<td align="left">3.03 - 3.64</td>
<td align="left">NA</td>
<td align="left">0.025</td>
<td align="left">1,059.000</td>
</tr>
<tr class="even">
<td align="left">SB_intention_02</td>
<td align="left">3</td>
<td align="left">3.17 - 3.81</td>
<td align="left">NA</td>
<td align="left">0.034</td>
<td align="left">1,056</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_03</td>
<td align="left">4.0</td>
<td align="left">3.68 - 4.37</td>
<td align="left">0.0</td>
<td align="left">0.027</td>
<td align="left">1,054.0</td>
</tr>
<tr class="even">
<td align="left">SB_intention_04</td>
<td align="left">4.09</td>
<td align="left">3.77 - 4.43</td>
<td align="left">0.03</td>
<td align="left">0.027</td>
<td align="left">1,055.00</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectations</td>
<td align="left">4.41</td>
<td align="left">4.3 - 4.53</td>
<td align="left">0.03</td>
<td align="left">0.005</td>
<td align="left">1,064.00</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectations_02</td>
<td align="left">4.840</td>
<td align="left">4.63 - 5.06</td>
<td align="left">0.017</td>
<td align="left">0.014</td>
<td align="left">1,056.000</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectations_03</td>
<td align="left">4.640</td>
<td align="left">4.41 - 4.88</td>
<td align="left">0.024</td>
<td align="left">0.014</td>
<td align="left">1,058.000</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectations_04</td>
<td align="left">5</td>
<td align="left">4.74 - 5.12</td>
<td align="left">0</td>
<td align="left">0.005</td>
<td align="left">1,063</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectations_05</td>
<td align="left">4.9</td>
<td align="left">4.73 - 5.09</td>
<td align="left">0.0</td>
<td align="left">0.004</td>
<td align="left">1,060.0</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectations_06</td>
<td align="left">4.87</td>
<td align="left">4.65 - 5.11</td>
<td align="left">0.05</td>
<td align="left">0.011</td>
<td align="left">1,058.00</td>
</tr>
<tr class="odd">
<td align="left">SB_outcomeExpectationsNegative_01</td>
<td align="left">3.40</td>
<td align="left">3.28 - 3.51</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,063.00</td>
</tr>
<tr class="even">
<td align="left">SB_outcomeExpectationsNegative_07</td>
<td align="left">3.350</td>
<td align="left">3.18 - 3.51</td>
<td align="left">0.012</td>
<td align="left">0.003</td>
<td align="left">1,057.000</td>
</tr>
<tr class="odd">
<td align="left">SB_sePbc</td>
<td align="left">4.970</td>
<td align="left">4.82 - 5.14</td>
<td align="left">0.015</td>
<td align="left">0.011</td>
<td align="left">1,064.000</td>
</tr>
<tr class="even">
<td align="left">SB_sePbc_01</td>
<td align="left">4</td>
<td align="left">4.14 - 4.6</td>
<td align="left">0</td>
<td align="left">0.014</td>
<td align="left">1,062</td>
</tr>
<tr class="odd">
<td align="left">SB_sePbc_02</td>
<td align="left">4.3</td>
<td align="left">4.07 - 4.54</td>
<td align="left">0.0</td>
<td align="left">0.015</td>
<td align="left">1,061.0</td>
</tr>
<tr class="even">
<td align="left">SB_sePbc_03</td>
<td align="left">5.74</td>
<td align="left">5.63 - 5.87</td>
<td align="left">0.03</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,060.00</td>
</tr>
<tr class="odd">
<td align="left">SB_sePbc_04</td>
<td align="left">5.74</td>
<td align="left">5.62 - 5.88</td>
<td align="left">0.03</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,060.00</td>
</tr>
<tr class="even">
<td align="left">SB_sePbc_05</td>
<td align="left">4.680</td>
<td align="left">4.46 - 4.91</td>
<td align="left">0.005</td>
<td align="left">0.012</td>
<td align="left">1,054.000</td>
</tr>
<tr class="odd">
<td align="left">sitBreaks</td>
<td align="left">28.020</td>
<td align="left">24.69 - 31.37</td>
<td align="left">0.058</td>
<td align="left">0.085</td>
<td align="left">706.000</td>
</tr>
<tr class="even">
<td align="left">sitLieAccelerometer</td>
<td align="left">574</td>
<td align="left">535.48 - 611.8</td>
<td align="left">0</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
<tr class="odd">
<td align="left">symptom</td>
<td align="left">2.0</td>
<td align="left">1.83 - 2.11</td>
<td align="left">0.0</td>
<td align="left">0.039</td>
<td align="left">1,084.0</td>
</tr>
<tr class="even">
<td align="left">symptom_headAche</td>
<td align="left">1.99</td>
<td align="left">1.83 - 2.16</td>
<td align="left">0.01</td>
<td align="left">0.027</td>
<td align="left">1,055.00</td>
</tr>
<tr class="odd">
<td align="left">symptom_irritabilityAngerbursts</td>
<td align="left">1.91</td>
<td align="left">1.8 - 2.04</td>
<td align="left">0.03</td>
<td align="left">0.01</td>
<td align="left">1,039.00</td>
</tr>
<tr class="even">
<td align="left">symptom_lowerBackPain</td>
<td align="left">1.760</td>
<td align="left">1.68 - 1.85</td>
<td align="left">0.004</td>
<td align="left">0.005</td>
<td align="left">1,053.000</td>
</tr>
<tr class="odd">
<td align="left">symptom_neckShoulderPain</td>
<td align="left">1.970</td>
<td align="left">1.78 - 2.17</td>
<td align="left">0.011</td>
<td align="left">0.033</td>
<td align="left">1,047.000</td>
</tr>
<tr class="even">
<td align="left">symptom_sleepDifficulty</td>
<td align="left">2</td>
<td align="left">1.92 - 2.27</td>
<td align="left">0</td>
<td align="left">0.023</td>
<td align="left">1,052</td>
</tr>
<tr class="odd">
<td align="left">symptom_stomachAche</td>
<td align="left">1.7</td>
<td align="left">1.61 - 1.86</td>
<td align="left">0.0</td>
<td align="left">0.023</td>
<td align="left">1,026.0</td>
</tr>
<tr class="even">
<td align="left">symptom_tensionNervousness</td>
<td align="left">1.92</td>
<td align="left">1.77 - 2.08</td>
<td align="left">0.01</td>
<td align="left">0.024</td>
<td align="left">1,051.00</td>
</tr>
<tr class="odd">
<td align="left">symptom_tirednessFaintness</td>
<td align="left">2.28</td>
<td align="left">2.15 - 2.4</td>
<td align="left">0.02</td>
<td align="left">0.009</td>
<td align="left">1,058.00</td>
</tr>
</tbody>
</table>
</div>
<div id="top-20-items-sorted-by-classroom" class="section level3">
<h3>Top 20 items, sorted by classroom</h3>
<pre class="r"><code>
vardatatable %&gt;% 
  select(Variable, `ICC class`, `ICC school`, n) %&gt;% 
  arrange(desc(`ICC class`)) %&gt;% slice(1:20) %&gt;% 
  as.tbl() %&gt;% 
  papaja::apa_table(caption = &quot;Intra-class correlations sorted by classroom ICC&quot;,
        format.args = list(digits = c(3, 0), margin = 2))</code></pre>
<caption>
(#tab:icc-school-class-sortbyclass)
</caption>
<caption>
<em>Intra-class correlations sorted by classroom ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">0.111</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.105</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">pafreqUsually</td>
<td align="left">0.094</td>
<td align="left">0.003</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">PA_intention_01</td>
<td align="left">0.088</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">sitLieAccelerometer</td>
<td align="left">0.086</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">pahrsUsually</td>
<td align="left">0.085</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.074</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous_06</td>
<td align="left">0.072</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_07</td>
<td align="left">0.072</td>
<td align="left">0.005</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated_03</td>
<td align="left">0.072</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,066</td>
</tr>
<tr class="even">
<td align="left">PA_intrinsic_01</td>
<td align="left">0.072</td>
<td align="left">0.005</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">paAccelerometer</td>
<td align="left">0.072</td>
<td align="left">0.096</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">PA_integrated</td>
<td align="left">0.071</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_agrbct_01</td>
<td align="left">0.061</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,071</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_04</td>
<td align="left">0.059</td>
<td align="left">0.004</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated_01</td>
<td align="left">0.059</td>
<td align="left">0.004</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous_03</td>
<td align="left">0.058</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="odd">
<td align="left">PA_identified_03</td>
<td align="left">0.058</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">sitBreaks</td>
<td align="left">0.058</td>
<td align="left">0.085</td>
<td align="left">706</td>
</tr>
</tbody>
</table>
</div>
<div id="top-20-items-sorted-by-school" class="section level3">
<h3>Top 20 items, sorted by school</h3>
<pre class="r"><code>
vardatatable %&gt;% select(Variable, `ICC class`, `ICC school`, n) %&gt;% 
  arrange(desc(`ICC school`)) %&gt;% 
  slice(1:20) %&gt;% 
  papaja::apa_table(caption = &quot;Intra-class correlations sorted by school ICC&quot;,
        format.args = list(digits = c(3, 0), margin = 2))</code></pre>
<caption>
(#tab:icc-school-class-sortbyschool)
</caption>
<caption>
<em>Intra-class correlations sorted by school ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">sitLieAccelerometer</td>
<td align="left">0.086</td>
<td align="left">0.145</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">fatpct</td>
<td align="left">0.003</td>
<td align="left">0.123</td>
<td align="left">942</td>
</tr>
<tr class="odd">
<td align="left">paAccelerometer</td>
<td align="left">0.072</td>
<td align="left">0.096</td>
<td align="left">706</td>
</tr>
<tr class="even">
<td align="left">sitBreaks</td>
<td align="left">0.058</td>
<td align="left">0.085</td>
<td align="left">706</td>
</tr>
<tr class="odd">
<td align="left">symptom</td>
<td align="left">0.023</td>
<td align="left">0.039</td>
<td align="left">1,084</td>
</tr>
<tr class="even">
<td align="left">SB_intention</td>
<td align="left">0.014</td>
<td align="left">0.035</td>
<td align="left">1,064</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_02</td>
<td align="left">NA</td>
<td align="left">0.034</td>
<td align="left">1,056</td>
</tr>
<tr class="even">
<td align="left">symptom_neckShoulderPain</td>
<td align="left">0.011</td>
<td align="left">0.033</td>
<td align="left">1,047</td>
</tr>
<tr class="odd">
<td align="left">b5open</td>
<td align="left">0.010</td>
<td align="left">0.03</td>
<td align="left">1,068</td>
</tr>
<tr class="even">
<td align="left">SB_intention_03</td>
<td align="left">0.023</td>
<td align="left">0.027</td>
<td align="left">1,054</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_04</td>
<td align="left">0.028</td>
<td align="left">0.027</td>
<td align="left">1,055</td>
</tr>
<tr class="even">
<td align="left">symptom_headAche</td>
<td align="left">0.007</td>
<td align="left">0.027</td>
<td align="left">1,055</td>
</tr>
<tr class="odd">
<td align="left">SB_intention_01</td>
<td align="left">NA</td>
<td align="left">0.025</td>
<td align="left">1,059</td>
</tr>
<tr class="even">
<td align="left">PA_opportunitiesReverseCoded_06</td>
<td align="left">NA</td>
<td align="left">0.024</td>
<td align="left">1,059</td>
</tr>
<tr class="odd">
<td align="left">symptom_tensionNervousness</td>
<td align="left">0.007</td>
<td align="left">0.024</td>
<td align="left">1,051</td>
</tr>
<tr class="even">
<td align="left">symptom_sleepDifficulty</td>
<td align="left">0.010</td>
<td align="left">0.023</td>
<td align="left">1,052</td>
</tr>
<tr class="odd">
<td align="left">symptom_stomachAche</td>
<td align="left">0.015</td>
<td align="left">0.023</td>
<td align="left">1,026</td>
</tr>
<tr class="even">
<td align="left">b5ext</td>
<td align="left">0.020</td>
<td align="left">0.022</td>
<td align="left">1,068</td>
</tr>
<tr class="odd">
<td align="left">PA_opportunities_01</td>
<td align="left">0.037</td>
<td align="left">0.02</td>
<td align="left">1,070</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations_03</td>
<td align="left">0.008</td>
<td align="left">0.018</td>
<td align="left">1,064</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="add-educational-track" class="section level2">
<h2>Add educational track</h2>
<p>The model below is the same as the one above, except it adds educational track.</p>
<p><strong>IT MAY NOT MAKE SENSE TO HAVE BOTH TRACK AND SCHOOL HERE, AS THEY’RE ALMOST THE SAME?</strong></p>
<p>As before, we create a table with all variables, their means, CIs and ICCs.</p>
<pre class="r"><code>#library(sjstats)
#library(lme4)

names &lt;- df %&gt;% select(-id, -intervention, -group, -school, -girl, -track, -trackSchool, -contains(&quot;_T3&quot;), -contains(&quot;_diff&quot;)) %&gt;% names(.)

# Create empty soon-to-be-filled objects
m &lt;- NA
mean &lt;- NA
m_p &lt;- NA
ci_low &lt;- NA
ci_high &lt;- NA
ICC_group &lt;- NA
ICC_School &lt;- NA
nonmissings &lt;- NA
ICC_track &lt;- NA


## To test the code with a single variable:
# dftest &lt;- df #%&gt;% na.omit()
# m &lt;- lmer(sitLieAccelerometer_T1 ~ (1|school) + (1|group) + (1|track), data=df)
# mean &lt;- fixef(m)
# m_p &lt;- profile(m)
# ci_low &lt;- confint(m_p)[5]
# ci_high &lt;- confint(m_p)[10]
# ICC_group &lt;- icc(m)[1]
# ICC_School &lt;- icc(m)[2]
# nonmissings &lt;- length(m@resp$y)

# Loop over each variable name, extract statistics: 

# all participants  
for (i in names){
m &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + (1|track)&quot;), data=df)
mean[i] &lt;- lme4::fixef(m)
m_p &lt;- profile(m, which = &quot;beta_&quot;)
ci_low[i] &lt;- confint(m_p)[5]
ci_high[i] &lt;- confint(m_p)[10]
ICC_group[i] &lt;- sjstats::icc(m)[1]
ICC_School[i] &lt;- sjstats::icc(m)[3]
ICC_track[i] &lt;- sjstats::icc(m)[2]
nonmissings[i] &lt;- length(m@resp$y)
}
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): Last two rows have
## identical or NA .zeta values: using minstep
## Warning in sqrt(fv - base): NaNs produced
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m, which = &quot;beta_&quot;): non-monotonic profile for
## (Intercept)
## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

## Warning in confint.thpr(m_p): bad spline fit for (Intercept): falling back
## to linear interpolation

vardatatable &lt;- data_frame(
  Variable = stringr::str_sub(names(mean), end = -4), #remove &quot;_T1&quot; from names
  Mean = round(mean, 2), 
  CI95 = paste(round(ci_low, 2), &quot;-&quot;, round(ci_high, 2)), 
  &quot;ICC class&quot; =ifelse(round(ICC_group, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_group, 3)), 
  &quot;ICC school&quot; = ifelse(round(ICC_School, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_School, 3)),
  &quot;ICC educational track&quot; = ifelse(round(ICC_track, 3) == 0, &quot;&lt; 0.001&quot;, round(ICC_track, 3)),
  n = nonmissings) %&gt;% 
  dplyr::arrange(Variable) %&gt;% 
  filter(Variable != &quot;&quot;) #remove first row, which is empty

options(tibble.print_max = 15)</code></pre>
<div id="top-20-items-sorted-by-school-1" class="section level3">
<h3>Top 20 items, sorted by school</h3>
</div>
</div>
</div>
<div id="jos-toimii-laita-muihinkin-alle-digits" class="section level1">
<h1>JOS TOIMII, LAITA MUIHINKIN ALLE (DIGITS)</h1>
<pre class="r"><code>
vardatatable %&gt;% 
  select(Variable, `ICC educational track`, `ICC class`, `ICC school`, n) %&gt;% 
  arrange(desc(`ICC school`)) %&gt;% 
  top_n(20) %&gt;% 
  papaja::apa_table(caption = &quot;Intra-class correlations sorted by school ICC&quot;,
        format.args = list(digits = c(0), margin = 2))
## Selecting by n</code></pre>
<caption>
(#tab:icc-school-class-track-sortbyschool)
</caption>
<caption>
<em>Intra-class correlations sorted by school ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC educational track</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">0.054</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.012</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paminLastweek</td>
<td align="left">0.005</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.011</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_integrated</td>
<td align="left">0.082</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.008</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">0.005</td>
<td align="left">0.006</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.071</td>
<td align="left">0.009</td>
<td align="left">0.006</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">pafreqUsually</td>
<td align="left">0.069</td>
<td align="left">0.023</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm</td>
<td align="left">0.052</td>
<td align="left">0.005</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsUsually</td>
<td align="left">0.051</td>
<td align="left">0.033</td>
<td align="left">0.004</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_inorm_01</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_outcomeExpectations</td>
<td align="left">0.024</td>
<td align="left">0.029</td>
<td align="left">0.003</td>
<td align="left">1,078</td>
</tr>
<tr class="even">
<td align="left">PA_actCop</td>
<td align="left">0.036</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actionplan</td>
<td align="left">0.031</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_01</td>
<td align="left">0.033</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_02</td>
<td align="left">0.018</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_03</td>
<td align="left">0.02</td>
<td align="left">0.021</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_04</td>
<td align="left">0.038</td>
<td align="left">0.008</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_controlled</td>
<td align="left">0.051</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copingplan</td>
<td align="left">0.034</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_01</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_02</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_03</td>
<td align="left">0.034</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_04</td>
<td align="left">0.033</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm_02</td>
<td align="left">0.023</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">0.044</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.064</td>
<td align="left">0.039</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_01</td>
<td align="left">0.061</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention_02</td>
<td align="left">0.064</td>
<td align="left">0.044</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected</td>
<td align="left">0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
<tr class="odd">
<td align="left">padaysLastweek</td>
<td align="left">0.04</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">0.036</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">paLastweek</td>
<td align="left">0.037</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">symptom</td>
<td align="left">0.066</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,084</td>
</tr>
</tbody>
</table>
<div id="top-20-items-sorted-by-classroom-1" class="section level3">
<h3>Top 20 items, sorted by classroom</h3>
<pre class="r"><code>
vardatatable %&gt;% select(Variable, `ICC educational track`, `ICC class`, `ICC school`, n) %&gt;% arrange(desc(`ICC class`)) %&gt;% top_n(20) %&gt;% papaja::apa_table(caption = &quot;Intra-class correlations sorted by classroom ICC&quot;,
        format.args = list(digits = c(0), margin = 2))
## Selecting by n</code></pre>
<caption>
(#tab:icc-school-class-track-sortbyclass)
</caption>
<caption>
<em>Intra-class correlations sorted by classroom ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC educational track</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">0.064</td>
<td align="left">0.044</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.064</td>
<td align="left">0.039</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">pahrsUsually</td>
<td align="left">0.051</td>
<td align="left">0.033</td>
<td align="left">0.004</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations</td>
<td align="left">0.024</td>
<td align="left">0.029</td>
<td align="left">0.003</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_01</td>
<td align="left">0.061</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pafreqUsually</td>
<td align="left">0.069</td>
<td align="left">0.023</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_03</td>
<td align="left">0.02</td>
<td align="left">0.021</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_02</td>
<td align="left">0.018</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actionplan</td>
<td align="left">0.031</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_02</td>
<td align="left">0.023</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">symptom</td>
<td align="left">0.066</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,084</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_03</td>
<td align="left">0.034</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_04</td>
<td align="left">0.033</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.071</td>
<td align="left">0.009</td>
<td align="left">0.006</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_04</td>
<td align="left">0.038</td>
<td align="left">0.008</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actCop</td>
<td align="left">0.036</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_01</td>
<td align="left">0.033</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">0.044</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">PA_inorm</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm_01</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">padaysLastweek</td>
<td align="left">0.04</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">0.005</td>
<td align="left">0.006</td>
<td align="left">1,078</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm</td>
<td align="left">0.052</td>
<td align="left">0.005</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled</td>
<td align="left">0.051</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">0.036</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">paLastweek</td>
<td align="left">0.037</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="even">
<td align="left">PA_copingplan</td>
<td align="left">0.034</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_01</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_02</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">0.054</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.012</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_integrated</td>
<td align="left">0.082</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.008</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected</td>
<td align="left">0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paminLastweek</td>
<td align="left">0.005</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.011</td>
<td align="left">1,082</td>
</tr>
</tbody>
</table>
</div>
<div id="top-20-items-sorted-by-educational-track" class="section level3">
<h3>Top 20 items, sorted by educational track</h3>
<pre class="r"><code>
vardatatable %&gt;% select(Variable, `ICC educational track`, `ICC class`, `ICC school`, n) %&gt;% arrange(desc(`ICC educational track`)) %&gt;% top_n(20) %&gt;% papaja::apa_table(caption = &quot;Intra-class correlations sorted by educational track ICC&quot;,
        format.args = list(digits = c(0), margin = 2))
## Selecting by n</code></pre>
<caption>
(#tab:icc-school-class-track-sortbytrack)
</caption>
<caption>
<em>Intra-class correlations sorted by educational track ICC</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">ICC educational track</th>
<th align="left">ICC class</th>
<th align="left">ICC school</th>
<th align="left">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA_integrated</td>
<td align="left">0.082</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.008</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_autonomous</td>
<td align="left">0.073</td>
<td align="left">0.005</td>
<td align="left">0.006</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_intrinsic</td>
<td align="left">0.071</td>
<td align="left">0.009</td>
<td align="left">0.006</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">pafreqUsually</td>
<td align="left">0.069</td>
<td align="left">0.023</td>
<td align="left">0.005</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">symptom</td>
<td align="left">0.066</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,084</td>
</tr>
<tr class="even">
<td align="left">PA_intention</td>
<td align="left">0.064</td>
<td align="left">0.039</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_intention_02</td>
<td align="left">0.064</td>
<td align="left">0.044</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_intention_01</td>
<td align="left">0.061</td>
<td align="left">0.027</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_01</td>
<td align="left">0.054</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.012</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_dnorm</td>
<td align="left">0.052</td>
<td align="left">0.005</td>
<td align="left">0.004</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_controlled</td>
<td align="left">0.051</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsUsually</td>
<td align="left">0.051</td>
<td align="left">0.033</td>
<td align="left">0.004</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_identified</td>
<td align="left">0.044</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,074</td>
</tr>
<tr class="even">
<td align="left">padaysLastweek</td>
<td align="left">0.04</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_04</td>
<td align="left">0.038</td>
<td align="left">0.008</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paLastweek</td>
<td align="left">0.037</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_actCop</td>
<td align="left">0.036</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">pahrsLastweek</td>
<td align="left">0.036</td>
<td align="left">0.004</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_copingplan</td>
<td align="left">0.034</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_03</td>
<td align="left">0.034</td>
<td align="left">0.011</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_01</td>
<td align="left">0.033</td>
<td align="left">0.006</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_04</td>
<td align="left">0.033</td>
<td align="left">0.01</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actionplan</td>
<td align="left">0.031</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_outcomeExpectations</td>
<td align="left">0.024</td>
<td align="left">0.029</td>
<td align="left">0.003</td>
<td align="left">1,078</td>
</tr>
<tr class="odd">
<td align="left">PA_dnorm_02</td>
<td align="left">0.023</td>
<td align="left">0.013</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_copplan_01</td>
<td align="left">0.022</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_actplan_03</td>
<td align="left">0.02</td>
<td align="left">0.021</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_actplan_02</td>
<td align="left">0.018</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_copplan_02</td>
<td align="left">0.015</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">paminLastweek</td>
<td align="left">0.005</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.011</td>
<td align="left">1,082</td>
</tr>
<tr class="odd">
<td align="left">PA_introjected</td>
<td align="left">0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_inorm</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="odd">
<td align="left">PA_inorm_01</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.006</td>
<td align="left">0.003</td>
<td align="left">1,073</td>
</tr>
<tr class="even">
<td align="left">PA_opportunities</td>
<td align="left">&lt; 0.001</td>
<td align="left">0.018</td>
<td align="left">&lt; 0.001</td>
<td align="left">1,075</td>
</tr>
</tbody>
</table>
</div>
<div id="create-confidence-bounds-for-all-items-by-gender-and-intervention-allocation" class="section level2">
<h2>Create confidence bounds for all items by gender and intervention allocation</h2>
<p>These numbers are visualised with diamond plots later.</p>
<pre class="r"><code>names &lt;- df %&gt;% select(-id, -intervention, -group, -school, -girl, -track, -trackSchool, -contains(&quot;_T3&quot;), -contains(&quot;_diff&quot;)) %&gt;% names(.)

# Intercepts for boys; when boy is 1, girl is 0, but boy is a factor, so intercept is for boys even though boy is 1 for boys and 0 for girls.
m.boys &lt;- NA
mean.boys &lt;- NA
m_p.boys &lt;- NA
ci_low.boys &lt;- NA
ci_high.boys &lt;- NA
ICC_group.boys &lt;- NA
ICC_School.boys &lt;- NA
nonmissings.boys &lt;- NA

df.boys &lt;- df %&gt;% mutate(boy = factor(ifelse(girl == 1, 0, 1), levels = c(1, 0)))

for (i in names){
m.boys &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + boy&quot;), data=df.boys)
mean.boys[i] &lt;- lme4::fixef(m.boys)
m_p.boys &lt;- profile(m.boys, which = &quot;beta_&quot;)
ci_low.boys[i] &lt;- confint(m_p.boys)[1, 1]
ci_high.boys[i] &lt;- confint(m_p.boys)[1, 2]
ICC_group.boys[i] &lt;- sjstats::icc(m.boys)[1]
ICC_School.boys[i] &lt;- sjstats::icc(m.boys)[2]
nonmissings.boys[i] &lt;- length(m.boys@resp$y)
}
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.boys, which = &quot;beta_&quot;): non-monotonic profile
## for (Intercept)
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in confint.thpr(m_p.boys): bad spline fit for (Intercept): falling
## back to linear interpolation

## Warning in confint.thpr(m_p.boys): bad spline fit for (Intercept): falling
## back to linear interpolation
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower =
## fitted@lower): convergence code 1 from bobyqa: bobyqa -- maximum number of
## function evaluations exceeded
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.boys[i] &lt;- lme4::fixef(m.boys): number of items to replace
## is not a multiple of replacement length

cat(&quot;The labels are arranged such that intercept is not for girls:&quot;, labels(lme4::fixef(m.boys))[2] == &quot;boy0&quot;)
## The labels are arranged such that intercept is not for girls: TRUE

ci_boys &lt;- data.frame(ciLo = ci_low.boys, mean = mean.boys, ciHi = ci_high.boys)
diamondlabels &lt;- labels(ci_boys)[[1]]
ci_boys &lt;- data.frame(ci_boys, diamondlabels)

# Intercepts for girls; when boy is 1, girl is 0, but boy is a factor, so intercept is for girls even though girl is 1 for girls and 0 for boys.
m.girls &lt;- NA
mean.girls &lt;- NA
m_p.girls &lt;- NA
ci_low.girls &lt;- NA
ci_high.girls &lt;- NA
ICC_group.girls &lt;- NA
ICC_School.girls &lt;- NA
nonmissings.girls &lt;- NA

for (i in names){
m.girls &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + girl&quot;), data=df)
mean.girls[i] &lt;- lme4::fixef(m.girls)
m_p.girls &lt;- profile(m.girls, which = &quot;beta_&quot;)
ci_low.girls[i] &lt;- confint(m_p.girls)[1, 1]
ci_high.girls[i] &lt;- confint(m_p.girls)[1, 2]
ICC_group.girls[i] &lt;- sjstats::icc(m.girls)[1]
ICC_School.girls[i] &lt;- sjstats::icc(m.girls)[2]
nonmissings.girls[i] &lt;- length(m.girls@resp$y)
}
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, devfun, x@theta, lower = x@lower, calc.derivs
## = TRUE, : convergence code 3 from bobyqa: bobyqa -- a trust region step
## failed to reduce q
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.girls, which = &quot;beta_&quot;): non-monotonic profile
## for (Intercept)
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation

## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, devfun, x@theta, lower = x@lower, calc.derivs
## = TRUE, : convergence code 3 from bobyqa: bobyqa -- a trust region step
## failed to reduce q
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.girls, which = &quot;beta_&quot;): non-monotonic profile
## for (Intercept)
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation

## Warning in confint.thpr(m_p.girls): bad spline fit for (Intercept): falling
## back to linear interpolation
## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

## Warning in mean.girls[i] &lt;- lme4::fixef(m.girls): number of items to
## replace is not a multiple of replacement length

cat(&quot;The labels are arranged such that intercept is not for boys:&quot;, labels(lme4::fixef(m.girls))[2] == &quot;girl0&quot;)
## The labels are arranged such that intercept is not for boys: TRUE

ci_girls &lt;- data.frame(ciLo = ci_low.girls, mean = mean.girls, ciHi = ci_high.girls)
diamondlabels &lt;- labels(ci_girls)[[1]]
ci_girls &lt;- data.frame(ci_girls, diamondlabels)


# Intercepts for intervention
m.intervention &lt;- NA
mean.intervention &lt;- NA
m_p.intervention &lt;- NA
ci_low.intervention &lt;- NA
ci_high.intervention &lt;- NA
ICC_group.intervention &lt;- NA
ICC_School.intervention &lt;- NA
nonmissings.intervention &lt;- NA

## change &quot;intervention&quot; to be consistent regarding level order with &quot;girl&quot;.
df.intervention &lt;- df %&gt;% mutate(intervention = factor(intervention, levels = c(1, 0)))

for (i in names){
m.intervention &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + intervention&quot;), data=df.intervention)
mean.intervention[i] &lt;- lme4::fixef(m.intervention)
m_p.intervention &lt;- profile(m.intervention, which = &quot;beta_&quot;)
ci_low.intervention[i] &lt;- confint(m_p.intervention)[1, 1]
ci_high.intervention[i] &lt;- confint(m_p.intervention)[1, 2]
ICC_group.intervention[i] &lt;- sjstats::icc(m.intervention)[1]
ICC_School.intervention[i] &lt;- sjstats::icc(m.intervention)[2]
nonmissings.intervention[i] &lt;- length(m.intervention@resp$y)
}
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in optwrap(optimizer, devfun, x@theta, lower = x@lower, calc.derivs
## = TRUE, : convergence code 3 from bobyqa: bobyqa -- a trust region step
## failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for intervention0
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for intervention0
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.intervention, which = &quot;beta_&quot;): non-monotonic
## profile for intervention0
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.intervention): bad spline fit for
## intervention0: falling back to linear interpolation
## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

## Warning in mean.intervention[i] &lt;- lme4::fixef(m.intervention): number of
## items to replace is not a multiple of replacement length

cat(&quot;The labels are arranged such that intercept is not for control:&quot;, labels(lme4::fixef(m.intervention))[2] == &quot;intervention0&quot;)
## The labels are arranged such that intercept is not for control: TRUE

ci_intervention &lt;- data.frame(ciLo = ci_low.intervention, mean = mean.intervention, ciHi = ci_high.intervention)
diamondlabels &lt;- labels(ci_intervention)[[1]]
ci_intervention &lt;- data.frame(ci_intervention, diamondlabels)

# Intercepts for control

m.control &lt;- NA
mean.control &lt;- NA
m_p.control &lt;- NA
ci_low.control &lt;- NA
ci_high.control &lt;- NA
ICC_group.control &lt;- NA
ICC_School.control &lt;- NA
nonmissings.control &lt;- NA

df.control &lt;- df %&gt;% mutate(control = factor(ifelse(intervention == 1, 0, 1), levels = c(1, 0)))

for (i in names){
m.control &lt;- lme4::lmer(paste0(i,&quot; ~ (1|school) + (1|group) + control&quot;), data=df.control)
mean.control[i] &lt;- lme4::fixef(m.control)
m_p.control &lt;- profile(m.control, which = &quot;beta_&quot;)
ci_low.control[i] &lt;- confint(m_p.control)[1, 1]
ci_high.control[i] &lt;- confint(m_p.control)[1, 2]
ICC_group.control[i] &lt;- sjstats::icc(m.control)[1]
ICC_School.control[i] &lt;- sjstats::icc(m.control)[2]
nonmissings.control[i] &lt;- length(m.control@resp$y)
}
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for control0
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for control0
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length
## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q

## Warning in optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower
## = fitted@lower): convergence code 3 from bobyqa: bobyqa -- a trust region
## step failed to reduce q
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for control0
## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for control0: falling
## back to linear interpolation
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length
## Warning in nextpar(mat, cc, i, delta, lowcut, upcut): unexpected decrease
## in profile: using minstep
## Warning in profile.merMod(m.control, which = &quot;beta_&quot;): non-monotonic
## profile for (Intercept)
## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation

## Warning in confint.thpr(m_p.control): bad spline fit for (Intercept):
## falling back to linear interpolation
## Warning in mean.control[i] &lt;- lme4::fixef(m.control): number of items to
## replace is not a multiple of replacement length

cat(&quot;The labels are arranged such that intercept is not for intervention:&quot;, labels(lme4::fixef(m.control))[2] == &quot;control0&quot;)
## The labels are arranged such that intercept is not for intervention: TRUE

ci_control &lt;- data.frame(ciLo = ci_low.control, mean = mean.control, ciHi = ci_high.control)
diamondlabels &lt;- labels(ci_control)[[1]]
ci_control &lt;- data.frame(ci_control, diamondlabels)

# Same ICC results you&#39;d get with e.g.:
# m1 &lt;- as.data.frame(VarCorr(m))
# m1$vcov[1] / (m1$vcov[1] + m1$vcov[3])

# Or from broom:
# tidy(m)$estimate[2]^2 / (tidy(m)$estimate[2]^2 + tidy(m)$estimate[4]^2)

# Or from sjstats:
# sum(get_re_var(m)) / (sum(get_re_var(m)) + get_re_var(m, &quot;sigma_2&quot;))
</code></pre>
</div>
</div>
<div id="descriptive-tables" class="section level1">
<h1>Descriptive tables</h1>
<div id="prepare-data" class="section level2">
<h2>prepare data</h2>
<pre class="r"><code>
demographics &lt;- lmi %&gt;% dplyr::select(id = ID,
birthYear = Kys0004.1,
intervention = ryhma,
school = Aineisto.1,
girl = Kys0013.1,
ethnicity = Kys0005.1,
studyYear = Kys0014.1) %&gt;% 
  mutate(age = 2016 - birthYear,
         intervention = ifelse(intervention == 1, 1, 0),
         intervention = as.numeric(intervention),
         girl = ifelse(girl == 2, 1, 0),
          girl = as.numeric(girl, levels = c(&quot;1&quot;, &quot;0&quot;)),
         school = factor(school, levels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;)),
         bornInFinland = as.numeric(ifelse(ethnicity == 1, 1, 0)),
         studyYear = ifelse(studyYear == 0, NA, studyYear)) # Remove &quot;other&quot; from study year

# Insert track variable with those who answered &quot;other&quot; with one of the actual category labels given the appropriate category:
Track &lt;- lmi %&gt;% select(Kys0016.1, Kys0017.1) %&gt;% mutate(
  Kys0016.1 = ifelse(Kys0017.1 == &quot;Merkonomi&quot; | Kys0017.1 == &quot;merkonomi&quot;, 3,
                  ifelse(Kys0017.1 == &quot;Datanomi&quot; | Kys0017.1 == &quot;datanomi&quot;, 2, Kys0016.1)),
  Track = factor(Kys0016.1, # Fix track labels first
                     levels = c(0, 1, 2, 3, 4),
                     labels = c(&quot;Other&quot;, &quot;Business IT&quot;, &quot;Business Admin&quot;, &quot;HRC&quot;, &quot;Nursing&quot;))) %&gt;% 
  select(-Kys0016.1, -Kys0017.1)

demographics &lt;- bind_cols(demographics, Track)</code></pre>
</div>
<div id="create-demographic-tables" class="section level2">
<h2>Create demographic tables</h2>
<div id="by-educational-track" class="section level3">
<h3>By educational track</h3>
<pre class="r"><code>demotable &lt;- demographics %&gt;% 
  group_by(Track) %&gt;% 
  summarise(&quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(Track)) 
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf

demotable_total &lt;- demographics %&gt;% 
  summarise(&quot;Track&quot; = &quot;Full sample&quot;,
            &quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n())

demotable &lt;- bind_rows(demotable, demotable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

demotable &lt;- demotable %&gt;% tidyr::gather(Variable, val, 2:ncol(demotable)) %&gt;% tidyr::spread(Track, val)

# For some reason, sum of n&#39;s of all tracks is 1084.

papaja::apa_table(demotable, caption = &quot;Baseline demographics of educational tracks&quot;, digits = c(0, 1, 1, 1, 1, 1, 0))</code></pre>
<caption>
(#tab:demographics-table-track)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Business Admin</th>
<th align="left">Business IT</th>
<th align="left">Full sample</th>
<th align="left">HRC</th>
<th align="left">Nursing</th>
<th align="left">Other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">% born in Finland</td>
<td align="left">87.1</td>
<td align="left">87.9</td>
<td align="left">83.1</td>
<td align="left">88.2</td>
<td align="left">80</td>
<td align="left">54.2</td>
</tr>
<tr class="even">
<td align="left">% girl</td>
<td align="left">39</td>
<td align="left">16</td>
<td align="left">56.5</td>
<td align="left">60.6</td>
<td align="left">82.3</td>
<td align="left">70.8</td>
</tr>
<tr class="odd">
<td align="left">% intervention</td>
<td align="left">53.5</td>
<td align="left">46.6</td>
<td align="left">53.6</td>
<td align="left">31.5</td>
<td align="left">68.9</td>
<td align="left">41.7</td>
</tr>
<tr class="even">
<td align="left">Mean age (range)</td>
<td align="left">19 (17-36)</td>
<td align="left">19.5 (18-44)</td>
<td align="left">19.3 (17-50)</td>
<td align="left">18.5 (17-27)</td>
<td align="left">19.8 (17-50)</td>
<td align="left">21 (17-45)</td>
</tr>
<tr class="odd">
<td align="left">Mean study year (sd)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.9 (0.7)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">2 (1.4)</td>
</tr>
<tr class="even">
<td align="left">n</td>
<td align="left">282</td>
<td align="left">163</td>
<td align="left">1165</td>
<td align="left">213</td>
<td align="left">402</td>
<td align="left">24</td>
</tr>
</tbody>
</table>
</div>
<div id="by-gender" class="section level3">
<h3>By gender</h3>
<pre class="r"><code>demographics$Girl &lt;- factor(demographics$girl)

demotable &lt;- demographics %&gt;% 
  group_by(Girl) %&gt;% 
  summarise(&quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(Girl)) 
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf

demotable_total &lt;- demographics %&gt;% 
  summarise(&quot;Girl&quot; = &quot;Full sample&quot;,
            &quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% intervention&quot; = round(mean(intervention, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n())

demotable &lt;- bind_rows(demotable, demotable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

demotable &lt;- demotable %&gt;% tidyr::gather(Variable, val, 2:ncol(demotable)) %&gt;% tidyr::spread(Girl, val)

names(demotable) &lt;- c(&quot;&quot;, &quot;Boy&quot;, &quot;Girl&quot;, &quot;Full sample&quot;)

# For some reason, sum of n&#39;s of all tracks is 1084.

papaja::apa_table(demotable, caption = &quot;Baseline demographics of educational tracks&quot;, digits = c(0, 1, 1, 1, 1, 0))</code></pre>
<caption>
(#tab:demographics-table-gender)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">Boy</th>
<th align="left">Girl</th>
<th align="left">Full sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>% born in Finland</td>
<td align="left">88.2</td>
<td align="left">80.1</td>
<td align="left">83.1</td>
</tr>
<tr class="even">
<td>% intervention</td>
<td align="left">50.5</td>
<td align="left">56</td>
<td align="left">53.6</td>
</tr>
<tr class="odd">
<td>Mean age (range)</td>
<td align="left">19.1 (17-36)</td>
<td align="left">19.5 (17-50)</td>
<td align="left">19.3 (17-50)</td>
</tr>
<tr class="even">
<td>Mean study year (sd)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.8)</td>
<td align="left">1.7 (0.9)</td>
</tr>
<tr class="odd">
<td>n</td>
<td align="left">471</td>
<td align="left">613</td>
<td align="left">1165</td>
</tr>
</tbody>
</table>
</div>
<div id="by-intervention-participation" class="section level3">
<h3>By intervention participation</h3>
<pre class="r"><code>demographics$intervention &lt;- factor(demographics$intervention)
demographics$girl &lt;- as.numeric(demographics$girl)

demotable &lt;- demographics %&gt;% 
  group_by(intervention) %&gt;% 
  summarise(&quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(intervention)) 
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf

demotable_total &lt;- demographics %&gt;% 
  summarise(&quot;intervention&quot; = &quot;Full sample&quot;,
            &quot;Mean age (range)&quot; = paste0(round(mean(age, na.rm = T), 1),&quot; (&quot;, 
                                        range(age, na.rm = T)[1], &quot;-&quot;,
                                        range(age, na.rm = T)[2], &quot;)&quot;),
            &quot;Mean study year (sd)&quot; = paste0(round(mean(studyYear, na.rm = T), 1),&quot; (&quot;, 
                                               round(sd(studyYear, na.rm = T), 1), &quot;)&quot;),
            &quot;% girl&quot; = round(mean(girl, na.rm = T)*100, 1),
            &quot;% born in Finland&quot; = round(mean(bornInFinland, na.rm = T)*100, 1),
            n = n())

demotable &lt;- bind_rows(demotable, demotable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

demotable &lt;- demotable %&gt;% tidyr::gather(Variable, val, 2:ncol(demotable)) %&gt;% tidyr::spread(intervention, val)

names(demotable) &lt;- c(&quot;&quot;, &quot;Control&quot;, &quot;Intervention&quot;, &quot;Full sample&quot;)

# For some reason, sum of n&#39;s of all tracks is 1084.

papaja::apa_table(demotable, caption = &quot;Baseline demographics of educational tracks&quot;, digits = c(0, 1, 1, 1, 1, 0))</code></pre>
<caption>
(#tab:demographics-table-intervention)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">Control</th>
<th align="left">Intervention</th>
<th align="left">Full sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>% born in Finland</td>
<td align="left">87.5</td>
<td align="left">79.6</td>
<td align="left">83.1</td>
</tr>
<tr class="even">
<td>% girl</td>
<td align="left">53.7</td>
<td align="left">59</td>
<td align="left">56.5</td>
</tr>
<tr class="odd">
<td>Mean age (range)</td>
<td align="left">19 (17-39)</td>
<td align="left">19.6 (17-50)</td>
<td align="left">19.3 (17-50)</td>
</tr>
<tr class="even">
<td>Mean study year (sd)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
<td align="left">1.7 (0.9)</td>
</tr>
<tr class="odd">
<td>n</td>
<td align="left">503</td>
<td align="left">581</td>
<td align="left">1165</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="create-outcome-tables" class="section level2">
<h2>Create outcome tables</h2>
<pre class="r"><code>
outtable_track &lt;- df %&gt;%
  select(paAccelerometer_T1, sitLieAccelerometer_T1, sitBreaks_T1, # Main outcomes 
          PA_actionplan_T1,
          PA_copingplan_T1,
          PA_agrbct_T1,
          PA_frqbct_T1,
          PA_amotivation_T1,
          PA_autonomous_T1,
          PA_controlled_T1,
          PA_goal_T1,
          PA_inorm_T1,
          PA_dnorm_T1,
          PA_intention_T1,
          PA_outcomeExpectations_T1,
          PA_opportunities_T1,
          PA_pbc_T1,
          PA_selfefficacy_T1,
          SB_dnorm_T1,
          SB_inorm_T1,
          SB_intention_T1,
          SB_outcomeExpectations_T1,
          SB_sePbc_T1,
         track, girl, intervention) %&gt;% 
  group_by(track) %&gt;% 
  summarise(
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n()) %&gt;% 
  filter(complete.cases(.)) %&gt;% 
  arrange(desc(track)) %&gt;% 
  filter(track != &quot;Other&quot;)

outtable_intervention &lt;- df %&gt;%
  select(paAccelerometer_T1, sitLieAccelerometer_T1, sitBreaks_T1, # Main outcomes 
          PA_actionplan_T1,
          PA_copingplan_T1,
          PA_agrbct_T1,
          PA_frqbct_T1,
          PA_amotivation_T1,
          PA_autonomous_T1,
          PA_controlled_T1,
          PA_goal_T1,
          PA_inorm_T1,
          PA_dnorm_T1,
          PA_intention_T1,
          PA_outcomeExpectations_T1,
          PA_opportunities_T1,
          PA_pbc_T1,
          PA_selfefficacy_T1,
          SB_dnorm_T1,
          SB_inorm_T1,
          SB_intention_T1,
          SB_outcomeExpectations_T1,
          SB_sePbc_T1,
         track, girl, intervention) %&gt;% 
  group_by(intervention) %&gt;% 
  summarise(
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n()) %&gt;% 
  filter(complete.cases(.))

outtable_girl &lt;- df %&gt;%
  select(paAccelerometer_T1, sitLieAccelerometer_T1, sitBreaks_T1, # Main outcomes 
          PA_actionplan_T1,
          PA_copingplan_T1,
          PA_agrbct_T1,
          PA_frqbct_T1,
          PA_amotivation_T1,
          PA_autonomous_T1,
          PA_controlled_T1,
          PA_goal_T1,
          PA_inorm_T1,
          PA_dnorm_T1,
          PA_intention_T1,
          PA_outcomeExpectations_T1,
          PA_opportunities_T1,
          PA_pbc_T1,
          PA_selfefficacy_T1,
          SB_dnorm_T1,
          SB_inorm_T1,
          SB_intention_T1,
          SB_outcomeExpectations_T1,
          SB_sePbc_T1,
         track, girl, intervention) %&gt;% 
  group_by(girl) %&gt;% 
  summarise(
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n()) %&gt;% 
  filter(complete.cases(.))

outtable_total &lt;- df %&gt;% 
  summarise(&#39;girl&#39; = &quot;Full sample&quot;,
            &#39;PA action planning&#39; = paste0(round(mean(PA_actionplan_T1, na.rm = TRUE), 1), &quot; (&quot;, round(sd(PA_actionplan_T1, na.rm = T), 1), &quot;)&quot;),
            &#39;PA coping planning&#39; = paste0(round(mean(PA_copingplan_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_copingplan_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA agreement-BCTs&#39; = paste0(round(mean(PA_agrbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_agrbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA frequency-BCTs&#39; = paste0(round(mean(PA_frqbct_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_frqbct_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA amotivation&#39; = paste0(round(mean(PA_amotivation_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_amotivation_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA autonomous regulation&#39; = paste0(round(mean(PA_autonomous_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_autonomous_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA controlled regulation&#39; = paste0(round(mean(PA_controlled_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_controlled_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA injunctive norm&#39; = paste0(round(mean(PA_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA descriptive norm&#39; = paste0(round(mean(PA_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA intention&#39; = paste0(round(mean(PA_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA outcome expectations&#39; = paste0(round(mean(PA_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA opportunities&#39; = paste0(round(mean(PA_opportunities_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_opportunities_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA perceived behavioural control&#39; = paste0(round(mean(PA_pbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_pbc_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;PA self-efficacy&#39; = paste0(round(mean(PA_selfefficacy_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(PA_selfefficacy_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB descriptive norm&#39; = paste0(round(mean(SB_dnorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_dnorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB injunctive norm&#39; = paste0(round(mean(SB_inorm_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_inorm_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB intention&#39; = paste0(round(mean(SB_intention_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_intention_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB outcome expectations&#39; = paste0(round(mean(SB_outcomeExpectations_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_outcomeExpectations_T1, na.rm = T), 1), &#39;)&#39;),
            &#39;SB self-efficacy &amp; perceived behavioural control&#39; = paste0(round(mean(SB_sePbc_T1, na.rm = TRUE), 1), &#39; (&#39;, round(sd(SB_sePbc_T1, na.rm = T), 1), &#39;)&#39;),

            &quot;Mean daily MVPA minutes&quot; = paste0(round(mean(paAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(paAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily minutes spent sitting or lying down&quot; = paste0(round(mean(sitLieAccelerometer_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitLieAccelerometer_T1, na.rm = T), 1), &quot;)&quot;),
            &quot;Mean daily breaks in sitting&quot; = paste0(round(mean(sitBreaks_T1, na.rm = T), 1),&quot; (&quot;, 
                                        round(sd(sitBreaks_T1, na.rm = T), 1), &quot;)&quot;),
            n = n())



# Transpose each table
outtable_track &lt;- outtable_track %&gt;% tidyr::gather(Variable, val, 2:ncol(.)) %&gt;% tidyr::spread(track, val)

outtable_intervention &lt;- outtable_intervention %&gt;% tidyr::gather(Variable, val, 2:ncol(.)) %&gt;% tidyr::spread(intervention, val)
names(outtable_intervention) &lt;- c(&quot;Variable&quot;, &quot;Control&quot;, &quot;Intervention&quot;)

## In the last table, have a column for total before transposing
outtable_girl &lt;- bind_rows(outtable_girl, outtable_total)
## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector
outtable_girl &lt;- outtable_girl %&gt;% tidyr::gather(Variable, val, 2:ncol(.)) %&gt;% tidyr::spread(girl, val)
names(outtable_girl) &lt;- c(&quot;Variable&quot;, &quot;Boy&quot;, &quot;Girl&quot;, &quot;Full sample&quot;)

# Are all variables the same?
identical(outtable_track$Variable, outtable_girl$Variable)</code></pre>
<p>[1] TRUE</p>
<pre class="r"><code>identical(outtable_track$Variable, outtable_intervention$Variable)</code></pre>
<p>[1] TRUE</p>
<pre class="r"><code>
# Create large table with all variables
outtable_mega &lt;- bind_cols(outtable_track, outtable_intervention, outtable_girl) %&gt;% 
  select(-Variable1, -Variable2) 

# Move n to be the first row
out1 &lt;- outtable_mega %&gt;% filter(Variable == &quot;n&quot;)
out2 &lt;- outtable_mega %&gt;% filter(Variable != &quot;n&quot;)
outtable_mega &lt;- bind_rows(out1, out2)

# Fix names: leave first blank, have the rest as they were
names(outtable_mega) &lt;- c(&quot;&quot;, names(outtable_mega)[2:(length(names(outtable_mega)))])

papaja::apa_table(outtable_mega, caption = &quot;Baseline demographics of educational tracks&quot;)</code></pre>
<caption>
(#tab:outcome-table)
</caption>
<caption>
<em>Baseline demographics of educational tracks</em>
</caption>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">Business IT</th>
<th align="left">Business Admin</th>
<th align="left">HRC</th>
<th align="left">Nursing</th>
<th align="left">Control</th>
<th align="left">Intervention</th>
<th align="left">Boy</th>
<th align="left">Girl</th>
<th align="left">Full sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n</td>
<td align="left">163</td>
<td align="left">282</td>
<td align="left">213</td>
<td align="left">402</td>
<td align="left">503</td>
<td align="left">581</td>
<td align="left">471</td>
<td align="left">613</td>
<td align="left">1165</td>
</tr>
<tr class="even">
<td>Mean daily breaks in sitting</td>
<td align="left">20 (9)</td>
<td align="left">27.5 (10)</td>
<td align="left">27.5 (9.6)</td>
<td align="left">31.7 (11.3)</td>
<td align="left">27.2 (10.4)</td>
<td align="left">29 (11.6)</td>
<td align="left">23.4 (9.5)</td>
<td align="left">31.3 (11)</td>
<td align="left">28.2 (11.1)</td>
</tr>
<tr class="odd">
<td>Mean daily minutes spent sitting or lying down</td>
<td align="left">652.8 (86.3)</td>
<td align="left">586.8 (93)</td>
<td align="left">557.8 (101.2)</td>
<td align="left">554.4 (82.1)</td>
<td align="left">568.5 (100.9)</td>
<td align="left">585.9 (92.7)</td>
<td align="left">612.5 (95.6)</td>
<td align="left">554.9 (90.9)</td>
<td align="left">578.2 (97.2)</td>
</tr>
<tr class="even">
<td>Mean daily MVPA minutes</td>
<td align="left">141.3 (51.6)</td>
<td align="left">179.6 (48.4)</td>
<td align="left">183.1 (52.2)</td>
<td align="left">201.2 (49.2)</td>
<td align="left">179.5 (52)</td>
<td align="left">187.3 (55.1)</td>
<td align="left">173.5 (59.4)</td>
<td align="left">190.4 (48.6)</td>
<td align="left">183.8 (53.8)</td>
</tr>
<tr class="odd">
<td>PA action planning</td>
<td align="left">2.4 (1.1)</td>
<td align="left">2.9 (0.9)</td>
<td align="left">2.8 (0.9)</td>
<td align="left">2.8 (0.9)</td>
<td align="left">2.8 (1)</td>
<td align="left">2.7 (0.9)</td>
<td align="left">2.8 (1)</td>
<td align="left">2.7 (0.9)</td>
<td align="left">2.8 (0.9)</td>
</tr>
<tr class="even">
<td>PA agreement-BCTs</td>
<td align="left">2.6 (1.3)</td>
<td align="left">3.5 (1.2)</td>
<td align="left">3.1 (1.3)</td>
<td align="left">3 (1.3)</td>
<td align="left">3.2 (1.3)</td>
<td align="left">3 (1.3)</td>
<td align="left">3.1 (1.4)</td>
<td align="left">3.1 (1.3)</td>
<td align="left">3.1 (1.3)</td>
</tr>
<tr class="odd">
<td>PA amotivation</td>
<td align="left">1.8 (1)</td>
<td align="left">1.5 (0.8)</td>
<td align="left">1.5 (0.8)</td>
<td align="left">1.4 (0.7)</td>
<td align="left">1.6 (0.8)</td>
<td align="left">1.5 (0.8)</td>
<td align="left">1.6 (0.9)</td>
<td align="left">1.5 (0.7)</td>
<td align="left">1.5 (0.8)</td>
</tr>
<tr class="even">
<td>PA autonomous regulation</td>
<td align="left">2.9 (1.1)</td>
<td align="left">3.6 (1)</td>
<td align="left">3.4 (1.1)</td>
<td align="left">3.5 (1)</td>
<td align="left">3.5 (1)</td>
<td align="left">3.4 (1.1)</td>
<td align="left">3.5 (1.1)</td>
<td align="left">3.4 (1)</td>
<td align="left">3.4 (1.1)</td>
</tr>
<tr class="odd">
<td>PA controlled regulation</td>
<td align="left">1.9 (0.8)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.8 (0.9)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.9 (0.9)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.8 (0.8)</td>
<td align="left">1.9 (0.8)</td>
<td align="left">1.8 (0.8)</td>
</tr>
<tr class="even">
<td>PA coping planning</td>
<td align="left">2.2 (0.9)</td>
<td align="left">2.7 (0.8)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.5 (0.9)</td>
<td align="left">2.6 (0.9)</td>
<td align="left">2.5 (0.8)</td>
<td align="left">2.5 (0.9)</td>
</tr>
<tr class="odd">
<td>PA descriptive norm</td>
<td align="left">3.8 (1.6)</td>
<td align="left">4.8 (1.5)</td>
<td align="left">4.5 (1.5)</td>
<td align="left">4.2 (1.6)</td>
<td align="left">4.5 (1.6)</td>
<td align="left">4.3 (1.6)</td>
<td align="left">4.5 (1.6)</td>
<td align="left">4.3 (1.6)</td>
<td align="left">4.4 (1.6)</td>
</tr>
<tr class="even">
<td>PA frequency-BCTs</td>
<td align="left">2.2 (1.1)</td>
<td align="left">2.8 (1.2)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.6 (1.1)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.6 (1.2)</td>
<td align="left">2.5 (1.1)</td>
<td align="left">2.5 (1.1)</td>
</tr>
<tr class="odd">
<td>PA injunctive norm</td>
<td align="left">4.7 (2)</td>
<td align="left">4.8 (2)</td>
<td align="left">4.7 (2)</td>
<td align="left">4.5 (2)</td>
<td align="left">4.8 (2)</td>
<td align="left">4.5 (2)</td>
<td align="left">4.8 (2)</td>
<td align="left">4.6 (2)</td>
<td align="left">4.6 (2)</td>
</tr>
<tr class="even">
<td>PA intention</td>
<td align="left">4.3 (2.1)</td>
<td align="left">5.7 (1.7)</td>
<td align="left">5.5 (1.8)</td>
<td align="left">5.5 (1.7)</td>
<td align="left">5.4 (1.9)</td>
<td align="left">5.4 (1.8)</td>
<td align="left">5.3 (1.9)</td>
<td align="left">5.4 (1.8)</td>
<td align="left">5.4 (1.8)</td>
</tr>
<tr class="odd">
<td>PA opportunities</td>
<td align="left">5.1 (0.9)</td>
<td align="left">5.2 (1)</td>
<td align="left">5.1 (0.9)</td>
<td align="left">5.1 (1)</td>
<td align="left">5.2 (0.9)</td>
<td align="left">5.1 (1)</td>
<td align="left">5.2 (0.9)</td>
<td align="left">5.1 (1)</td>
<td align="left">5.1 (0.9)</td>
</tr>
<tr class="even">
<td>PA outcome expectations</td>
<td align="left">4.3 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.7 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.6 (0.9)</td>
<td align="left">4.5 (0.9)</td>
<td align="left">4.7 (0.9)</td>
<td align="left">4.6 (0.9)</td>
</tr>
<tr class="odd">
<td>PA perceived behavioural control</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.5 (1.2)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.5 (1.2)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
</tr>
<tr class="even">
<td>PA self-efficacy</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.4 (1.4)</td>
<td align="left">5.1 (1.2)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.2 (1.3)</td>
<td align="left">5.3 (1.3)</td>
<td align="left">5.1 (1.3)</td>
<td align="left">5.2 (1.3)</td>
</tr>
<tr class="odd">
<td>SB descriptive norm</td>
<td align="left">2.8 (1.5)</td>
<td align="left">3.2 (1.4)</td>
<td align="left">3.4 (1.4)</td>
<td align="left">3.4 (1.5)</td>
<td align="left">3.3 (1.4)</td>
<td align="left">3.2 (1.5)</td>
<td align="left">3.3 (1.5)</td>
<td align="left">3.2 (1.4)</td>
<td align="left">3.2 (1.5)</td>
</tr>
<tr class="even">
<td>SB injunctive norm</td>
<td align="left">4 (1.1)</td>
<td align="left">3.8 (1.3)</td>
<td align="left">4 (1.2)</td>
<td align="left">4.1 (1.3)</td>
<td align="left">4.1 (1.2)</td>
<td align="left">3.9 (1.3)</td>
<td align="left">4 (1.2)</td>
<td align="left">4 (1.3)</td>
<td align="left">4 (1.3)</td>
</tr>
<tr class="odd">
<td>SB intention</td>
<td align="left">3 (1.6)</td>
<td align="left">3.6 (1.5)</td>
<td align="left">3.7 (1.6)</td>
<td align="left">4 (1.6)</td>
<td align="left">3.7 (1.6)</td>
<td align="left">3.7 (1.6)</td>
<td align="left">3.5 (1.7)</td>
<td align="left">3.9 (1.6)</td>
<td align="left">3.7 (1.6)</td>
</tr>
<tr class="even">
<td>SB outcome expectations</td>
<td align="left">4.1 (1.1)</td>
<td align="left">4.4 (1)</td>
<td align="left">4.4 (1)</td>
<td align="left">4.5 (1)</td>
<td align="left">4.4 (1)</td>
<td align="left">4.4 (1.1)</td>
<td align="left">4.3 (1.1)</td>
<td align="left">4.5 (1)</td>
<td align="left">4.4 (1)</td>
</tr>
<tr class="odd">
<td>SB self-efficacy &amp; perceived behavioural control</td>
<td align="left">5 (1.3)</td>
<td align="left">4.9 (1.2)</td>
<td align="left">5.1 (1.2)</td>
<td align="left">4.9 (1.3)</td>
<td align="left">5.1 (1.2)</td>
<td align="left">4.9 (1.3)</td>
<td align="left">5 (1.3)</td>
<td align="left">4.9 (1.2)</td>
<td align="left">4.9 (1.3)</td>
</tr>
</tbody>
</table>
</div>
<div id="pa-psychosocial-determinants-self-report-scales-t1" class="section level2">
<h2>PA psychosocial determinants: self report scales T1</h2>
<pre class="r"><code>PA_ci_girls &lt;- ci_girls %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

PA_ci_boys &lt;- ci_boys %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

PA_ci_intervention &lt;- ci_intervention %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

PA_ci_control &lt;- ci_control %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; grepl(&quot;PA_&quot;, diamondlabels) &amp; !grepl(&quot;bct&quot;, diamondlabels))

ICClabels &lt;- vardatatable %&gt;% filter(Variable %in% PA_ci_control$diamondlabels)

library(ggplot2)
plot1 &lt;- userfriendlyscience::diamondPlot(PA_ci_girls, color = &#39;green&#39;, alpha=.3, yLabels = PA_ci_girls$diamondlabels, fixedSize = 0.3, xlab = NULL) +
  userfriendlyscience::diamondPlot(PA_ci_boys, returnLayerOnly = TRUE, color=&#39;blue&#39;, alpha=.3, fixedSize = 0.3) +
  scale_x_continuous(limits = c(1, 7), breaks = 1:7)

plot2 &lt;- userfriendlyscience::diamondPlot(PA_ci_intervention, color = &#39;red&#39;, alpha=.3, yLabels = c(rep(&quot;&quot;, length(PA_ci_girls$diamondlabels))), fixedSize = 0.3, xlab = NULL, ylab = NULL) +
  userfriendlyscience::diamondPlot(PA_ci_control, returnLayerOnly = TRUE, color=&#39;black&#39;, alpha=.3, fixedSize = 0.3) +
  scale_x_continuous(limits = c(1, 7), breaks = 1:7)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-6-1.png" width="2100" /></p>
<pre class="r"><code>
# dat2 &lt;- data.frame(ciLo = c(3, 2), mean = c(4, 2.5), ciHi = c(6, 3));
# userfriendlyscience::diamondPlot(dat1, color = &#39;blue&#39;, alpha=.3, yLabels = dat1$diamondlabels) +
# userfriendlyscience::diamondPlot(dat2, returnLayerOnly = TRUE, color=&#39;red&#39;, alpha=.3)
 </code></pre>
<p>Note: action and coping planning on a scale from 1 to 4.</p>
</div>
</div>
<div id="visualising-random-effects-using-full-posterior-under-construction" class="section level1">
<h1>Visualising random effects using full posterior (UNDER CONSTRUCTION)</h1>
<div id="using-rstanarm" class="section level2">
<h2>Using rstanarm</h2>
<p>Plot below shows credible intervals deviations</p>
<pre class="r"><code>library(rstanarm)
# grep(&quot;PA_&quot;, names(df), value = TRUE)

# Centre the variable:
df &lt;- df %&gt;% mutate(paAccelerometer_T1_centred = paAccelerometer_T1 - mean(paAccelerometer_T1, na.rm = TRUE))

m_1 &lt;- stan_glmer(paAccelerometer_T1_centred ~ (1 | group), data = df, chains = 2, iter = 2000) 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 1).
## 
## Gradient evaluation took 0 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 2.011 seconds (Warm-up)
##                1.311 seconds (Sampling)
##                3.322 seconds (Total)
## 
## 
## SAMPLING FOR MODEL &#39;continuous&#39; NOW (CHAIN 2).
## 
## Gradient evaluation took 0 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 1.581 seconds (Warm-up)
##                1.019 seconds (Sampling)
##                2.6 seconds (Total)
pt &lt;- ranef(m_1) 
posteriors &lt;- data.frame(posterior_interval(m_1, prob = 0.90)) 
school_int &lt;- posteriors[-c(1, nrow(posteriors)-1, nrow(posteriors)),] #remove intercept and sigma parameters, leaving only class intervals 

# This not needed any more:
# groupmeans &lt;- df %&gt;% select(paAccelerometer_T1, group) %&gt;% group_by(group) %&gt;% 
#   summarise(mean = mean(paAccelerometer_T1, na.rm = T)) %&gt;% filter(complete.cases(.))

dat_plt &lt;- data.frame(pt$group, school_int) 
colnames(dat_plt) &lt;- c(&quot;pt&quot;, &quot;low&quot;, &quot;up&quot;) 
dat_plt &lt;- dat_plt %&gt;% arrange(pt) 
dat_plt$index &lt;- 1:nrow(dat_plt) 
dat_plt %&gt;% ggplot(aes(x = index, y = pt)) + geom_errorbar(aes(ymin = low, ymax = up)) + geom_point(size = 4, shape = 18) + geom_point(size = 2.5, shape = 18, color = &quot;white&quot;) + theme_bw()</code></pre>
<p><img src="baseline-supplement_files/figure-html/randeff-plot-rstanarm-1.png" width="2100" /></p>
</div>
<div id="using-brms-and-diamondplot" class="section level2">
<h2>Using brms and diamondPlot</h2>
<pre class="r"><code>
library(brms)
# I keep needing this:
# Sys.setenv(&quot;BINPREF&quot; = &quot;C:/HYApp/Rtools3.4/mingw_$(WIN)/bin/&quot;)

# Centre the variable:
df &lt;- df %&gt;% mutate(paAccelerometer_T1_centred = 
                      paAccelerometer_T1 - mean(paAccelerometer_T1, na.rm = TRUE))

m_1 &lt;- brms::bf(paAccelerometer_T1_centred ~ (1 | group)) 
get_prior(m_1, data = df)
## Warning: Rows containing NAs were excluded from the model
##                     prior     class      coef group resp dpar nlpar bound
## 1 student_t(3, -2.38, 54) Intercept                                      
## 2     student_t(3, 0, 54)        sd                                      
## 3                                sd           group                      
## 4                                sd Intercept group                      
## 5     student_t(3, 0, 54)     sigma

fit_1 &lt;- brms::brm(m_1, df)
## Warning: Rows containing NAs were excluded from the model
## Compiling the C++ model
## Warning: running command &#39;C:/PROGRA~1/R/R-34~1.3/bin/x64/R CMD SHLIB
## file2f543d6b70eb.cpp 2&gt; file2f543d6b70eb.cpp.err.txt&#39; had status 1
## Error in compileCode(f, code, language = language, verbose = verbose): Compilation ERROR, function(s)/method(s) not created! C:/Rtools/mingw_64/bin/g++: not found
## make: *** [file2f543d6b70eb.o] Error 127
## Warning message:
## running command &#39;make -f &quot;C:/PROGRA~1/R/R-34~1.3/etc/x64/Makeconf&quot; -f &quot;C:/PROGRA~1/R/R-34~1.3/share/make/winshlib.mk&quot; -f &quot;//ATKK/home/h/hema/Documents/.R/Makevars&quot; SHLIB_LDFLAGS=&#39;$(SHLIB_CXXLDFLAGS)&#39; SHLIB_LD=&#39;$(SHLIB_CXXLD)&#39; SHLIB=&quot;file2f543d6b70eb.dll&quot; WIN=64 TCLBIN=64 OBJECTS=&quot;file2f543d6b70eb.o&quot;&#39; had status 2

pt &lt;- brms::ranef(fit_1, robust = TRUE) %&gt;% 
  data.frame %&gt;% 
  select(credintLow = group.2.5.ile.Intercept,
         intercept = group.Estimate.Intercept, 
         credintHigh = group.97.5.ile.Intercept) %&gt;% 
  arrange(intercept)
## Error in brms::ranef(fit_1, robust = TRUE): object &#39;fit_1&#39; not found


plot1 &lt;- userfriendlyscience::diamondPlot(pt, color = &#39;green&#39;, alpha=.3, yLabels = 1:58, fixedSize = 0.3, xlab = NULL) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average MVPA&quot;, y = &quot;Group&quot;)
## Error in 1:nrow(data): argument of length 0


df %&gt;% ggplot(aes(x = group, y = paAccelerometer_T1_centred)) +
  userfriendlyscience::diamondPlot(pt, color = &#39;green&#39;, alpha=.3, yLabels = 1:58, fixedSize = 0.3, xlab = NULL, returnLayerOnly = TRUE) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average MVPA&quot;, y = &quot;Group&quot;)
## Error in 1:nrow(data): argument of length 0
   
forest(fit_1)
## Error in unique(model$ranef$group): object &#39;fit_1&#39; not found</code></pre>
</div>
<div id="random-effects-in-autonomous-motivation" class="section level2">
<h2>Random effects in autonomous motivation</h2>
<pre class="r"><code>
# Centre the variable:
df &lt;- df %&gt;% mutate(PA_autonomous_T1_centred = PA_autonomous_T1 - mean(PA_autonomous_T1, na.rm = TRUE))

m_1 &lt;- brms::bf(PA_autonomous_T1_centred ~ (1 | group)) 
get_prior(m_1, data = df)
## Warning: Rows containing NAs were excluded from the model
##                    prior     class      coef group resp dpar nlpar bound
## 1 student_t(3, 0.03, 10) Intercept                                      
## 2    student_t(3, 0, 10)        sd                                      
## 3                               sd           group                      
## 4                               sd Intercept group                      
## 5    student_t(3, 0, 10)     sigma

fit_1 &lt;- brms::brm(m_1, df)
## Warning: Rows containing NAs were excluded from the model
## Compiling the C++ model
## Warning: running command &#39;C:/PROGRA~1/R/R-34~1.3/bin/x64/R CMD SHLIB
## file2f5446917dd0.cpp 2&gt; file2f5446917dd0.cpp.err.txt&#39; had status 1
## Error in compileCode(f, code, language = language, verbose = verbose): Compilation ERROR, function(s)/method(s) not created! C:/Rtools/mingw_64/bin/g++: not found
## make: *** [file2f5446917dd0.o] Error 127
## Warning message:
## running command &#39;make -f &quot;C:/PROGRA~1/R/R-34~1.3/etc/x64/Makeconf&quot; -f &quot;C:/PROGRA~1/R/R-34~1.3/share/make/winshlib.mk&quot; -f &quot;//ATKK/home/h/hema/Documents/.R/Makevars&quot; SHLIB_LDFLAGS=&#39;$(SHLIB_CXXLDFLAGS)&#39; SHLIB_LD=&#39;$(SHLIB_CXXLD)&#39; SHLIB=&quot;file2f5446917dd0.dll&quot; WIN=64 TCLBIN=64 OBJECTS=&quot;file2f5446917dd0.o&quot;&#39; had status 2

pt &lt;- brms::ranef(fit_1, robust = TRUE) %&gt;% 
  data.frame %&gt;% 
  select(credintLow = group.2.5.ile.Intercept,
         intercept = group.Estimate.Intercept, 
         credintHigh = group.97.5.ile.Intercept) %&gt;% 
  arrange(intercept)
## Error in brms::ranef(fit_1, robust = TRUE): object &#39;fit_1&#39; not found


plot1 &lt;- userfriendlyscience::diamondPlot(pt, color = &#39;blue&#39;, alpha=.3, yLabels = 1:59, fixedSize = 0.3, xlab = NULL) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average motivation&quot;, y = &quot;Group&quot;)
## Error in 1:nrow(data): argument of length 0


df %&gt;% ggplot(aes(x = group, y = PA_autonomous_T1_centred)) +
  userfriendlyscience::diamondPlot(pt, color = &#39;blue&#39;, alpha=.3, yLabels = 1:59, fixedSize = 0.3, xlab = NULL, returnLayerOnly = TRUE) +
  coord_flip(expand = TRUE) +
  labs(x = &quot;Deviance from average motivation&quot;, y = &quot;Group&quot;)
## Error in 1:nrow(data): argument of length 0</code></pre>
</div>
</div>
<div id="ridge-plots" class="section level1">
<h1>Ridge plots</h1>
<div id="pa-motivation" class="section level2">
<h2>PA motivation</h2>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;PA autonomous \nmotivation&#39; = PA_autonomous_T1,
&#39;PA controlled \nmotivation&#39; = PA_controlled_T1,
&#39;PA amotivation&#39; = PA_amotivation_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA amotivation 0&quot;, &quot;PA amotivation 1&quot;),
                      labels = c( &#39;PA amotivation 0&#39; = &quot;Boy&quot;, &#39;PA amotivation 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;PA autonomous motivation&#39; = PA_autonomous_T1,
&#39;PA controlled motivation&#39; = PA_controlled_T1,
&#39;PA amotivation&#39; = PA_amotivation_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA amotivation 1&quot;, &quot;PA amotivation 0&quot;),
                      labels = c(&#39;PA amotivation 1&#39; = &quot;Intervention&quot;, &#39;PA amotivation 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

# grid.arrange(plot1, plot2, ncol = 2)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.216
## Warning: Removed 272 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.216
## Warning: Removed 272 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-7-1.png" width="2100" /></p>
</div>
<div id="big-5-personality-traits" class="section level2">
<h2>Big 5 personality traits</h2>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Agreeableness&#39; = b5agr_T1,
&#39;Conscientiousness&#39; = b5cons_T1,
&#39;Extraversion&#39; = b5ext_T1,
&#39;Neuroticism&#39; = b5neur_T1,
&#39;Openness&#39; = b5open_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreeableness 0&quot;, &quot;Agreeableness 1&quot;),
                      labels = c( &#39;Agreeableness 0&#39; = &quot;Boy&quot;, &#39;Agreeableness 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Agreeableness&#39; = b5agr_T1,
&#39;Conscientiousness&#39; = b5cons_T1,
&#39;Extraversion&#39; = b5ext_T1,
&#39;Neuroticism&#39; = b5neur_T1,
&#39;Openness&#39; = b5open_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreeableness 1&quot;, &quot;Agreeableness 0&quot;),
                      labels = c(&#39;Agreeableness 1&#39; = &quot;Intervention&quot;, &#39;Agreeableness 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

# grid.arrange(plot1, plot2, ncol = 2)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.315
## Warning: Removed 486 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.305
## Warning: Removed 486 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-8-1.png" width="2100" /></p>
</div>
<div id="bct-use" class="section level2">
<h2>BCT use</h2>
<div id="regression-analysis" class="section level3">
<h3>Regression analysis</h3>
<pre class="r"><code>
df %&gt;% select(PA_agrbct_T1, trackSchool) %&gt;% dplyr::group_by(trackSchool) %&gt;% summarise(mean = mean(PA_agrbct_T1, na.rm = TRUE), n = n())
## # A tibble: 17 x 3
##    trackSchool       mean     n
##    &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;
##  1 Business Admin1   3.34   149
##  2 Business Admin2   3.60   131
##  3 Business Admin4   3.05     2
##  4 Business IT1      2.49    76
##  5 Business IT2      2.64    87
##  6 HRC1              3.10    67
##  7 HRC2              1.00     1
##  8 HRC5              3.18   145
##  9 NANA            NaN       81
## 10 Nursing2          3.30     1
## # ... with 7 more rows

# Create combination of track and school variables, show means
df %&gt;% dplyr::mutate(trackSchool = paste0(track, school)) %&gt;% select(PA_agrbct_T1, track, school, trackSchool) %&gt;% dplyr::group_by(trackSchool) %&gt;% summarise(mean = mean(PA_agrbct_T1, na.rm = TRUE), n = n())
## # A tibble: 17 x 3
##    trackSchool       mean     n
##    &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;
##  1 Business Admin1   3.34   149
##  2 Business Admin2   3.60   131
##  3 Business Admin4   3.05     2
##  4 Business IT1      2.49    76
##  5 Business IT2      2.64    87
##  6 HRC1              3.10    67
##  7 HRC2              1.00     1
##  8 HRC5              3.18   145
##  9 NANA            NaN       81
## 10 Nursing2          3.30     1
## # ... with 7 more rows

m_lmer_agrbct &lt;- lme4::lmer(PA_agrbct_T1 ~ (1 | trackSchool), data = df) 
visreg(m_lmer_agrbct, &quot;trackSchool&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-9-1.png" width="2100" /></p>
</div>
<div id="forest-plots-of-posteriors" class="section level3">
<h3>Forest plots of posteriors</h3>
<pre class="r"><code>
m_agrbct &lt;- brms::bf(PA_agrbct_T1 ~ (1 | trackSchool)) 
brms::get_prior(m_agrbct, data = df)
## Warning: Rows containing NAs were excluded from the model
##                   prior     class      coef       group resp dpar nlpar
## 1 student_t(3, 3.1, 10) Intercept                                      
## 2   student_t(3, 0, 10)        sd                                      
## 3                              sd           trackSchool                
## 4                              sd Intercept trackSchool                
## 5   student_t(3, 0, 10)     sigma                                      
##   bound
## 1      
## 2      
## 3      
## 4      
## 5

fit_agrbct &lt;- brms::brm(m_agrbct, df, control = list(adapt_delta = 0.95))
## Warning: Rows containing NAs were excluded from the model
## Compiling the C++ model
## Warning: running command &#39;C:/PROGRA~1/R/R-34~1.3/bin/x64/R CMD SHLIB
## file2f54a5f4bc1.cpp 2&gt; file2f54a5f4bc1.cpp.err.txt&#39; had status 1
## Error in compileCode(f, code, language = language, verbose = verbose): Compilation ERROR, function(s)/method(s) not created! C:/Rtools/mingw_64/bin/g++: not found
## make: *** [file2f54a5f4bc1.o] Error 127
## Warning message:
## running command &#39;make -f &quot;C:/PROGRA~1/R/R-34~1.3/etc/x64/Makeconf&quot; -f &quot;C:/PROGRA~1/R/R-34~1.3/share/make/winshlib.mk&quot; -f &quot;//ATKK/home/h/hema/Documents/.R/Makevars&quot; SHLIB_LDFLAGS=&#39;$(SHLIB_CXXLDFLAGS)&#39; SHLIB_LD=&#39;$(SHLIB_CXXLD)&#39; SHLIB=&quot;file2f54a5f4bc1.dll&quot; WIN=64 TCLBIN=64 OBJECTS=&quot;file2f54a5f4bc1.o&quot;&#39; had status 2

forest(fit_agrbct, sort = TRUE)
## Error in unique(model$ranef$group): object &#39;fit_agrbct&#39; not found

plot(fit_agrbct)
## Error in plot(fit_agrbct): object &#39;fit_agrbct&#39; not found
pairs(fit_agrbct)
## Error in pairs(fit_agrbct): object &#39;fit_agrbct&#39; not found
stanplot(fit_agrbct, &quot;b_Intercept&quot;, type = &quot;trace&quot;)
## Error in stanplot(fit_agrbct, &quot;b_Intercept&quot;, type = &quot;trace&quot;): object &#39;fit_agrbct&#39; not found
pp_check(fit_agrbct, nsamples = 100)
## Error in pp_check(fit_agrbct, nsamples = 100): object &#39;fit_agrbct&#39; not found</code></pre>
</div>
<div id="ridge-plots-for-means" class="section level3">
<h3>Ridge plots for means</h3>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Frequency-\nrelated BCTs&#39; = PA_frqbct_T1,
&#39;Agreement-\nrelated BCTs&#39; = PA_agrbct_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreement-\nrelated BCTs 0&quot;, &quot;Agreement-\nrelated BCTs 1&quot;),
                      labels = c( &#39;Agreement-\nrelated BCTs 0&#39; = &quot;Boy&quot;, &#39;Agreement-\nrelated BCTs 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Frequency-\nrelated BCTs&#39; = PA_frqbct_T1,
&#39;Agreement-\nrelated BCTs&#39; = PA_agrbct_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;Agreement-\nrelated BCTs 1&quot;, &quot;Agreement-\nrelated BCTs 0&quot;),
                      labels = c(&#39;Agreement-\nrelated BCTs 1&#39; = &quot;Intervention&quot;, &#39;Agreement-\nrelated BCTs 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.319
## Warning: Removed 189 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.318
## Warning: Removed 189 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-11-1.png" width="2100" /></p>
<pre class="r"><code>


# grid.arrange(plot1, plot2, ncol = 2)</code></pre>
</div>
<div id="sm-kernel-density-plots-for-means" class="section level3">
<h3>sm kernel density plots for means</h3>
<div id="frequency-measured-bcts" class="section level4">
<h4>Frequency-measured BCTs</h4>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- df
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_frqbct_T1, intervention) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_frqbct_T1_1 &lt;- sm.density.compare2(as.numeric(dens$PA_frqbct_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.31
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_frqbct_T1, girl) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_frqbct_T1_2 &lt;- sm.density.compare2(as.numeric(dens$PA_frqbct_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.11
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_frqbct_T1, school) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_frqbct_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$PA_frqbct_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-12-1.png" width="2100" /></p>
</div>
<div id="agreement-measured-bcts" class="section level4">
<h4>Agreement-measured BCTs</h4>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- df
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_agrbct_T1, intervention) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_agrbct_T1_1 &lt;- sm.density.compare2(as.numeric(dens$PA_agrbct_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_agrbct_T1, girl) %&gt;% 
  na.omit(.)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_agrbct_T1_2 &lt;- sm.density.compare2(as.numeric(dens$PA_agrbct_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.27
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(PA_agrbct_T1, school) %&gt;% 
  na.omit(.)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.PA_agrbct_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$PA_agrbct_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-13-1.png" width="2100" /></p>
</div>
</div>
<div id="histograms-for-individual-items" class="section level3">
<h3>Histograms for individual items</h3>
<div id="frequency-measured-bcts-1" class="section level4">
<h4>Frequency-measured BCTs</h4>
<p>These questions were asked with the lead “Have you done the following during the last three weeks?”.</p>
<p>The answer scale was as follows:</p>
<p>0 = not once 1 = once 2 = twice 3 = weekly 4 = about every second day 5 = daily</p>
<p>Items are as follows:</p>
<ol style="list-style-type: decimal">
<li>I have reminded myself even in my spare time, what kind of positive consequences frequent PA would have in my life.</li>
<li>I have monitored my PA by marking the PA occasions on an exercise log on paper.</li>
<li>I have monitored my PA by using a smart phone, e.g. the Moves-app.</li>
<li>I use mnemonic cues with which I remember to implement my PA intention.</li>
<li>I have compared my actualized PA with the PA goal I have set.</li>
<li>I have thought about which reasons to do PA are important to me personally.</li>
<li>I have made changes in my home (e.g. my room or my computer), so that starting PA would be easier.</li>
<li>I have asked my friends or family for support to reach my PA goals.</li>
<li>If I haven’t reached my PA goal, I have evaluated, what went wrong.</li>
</ol>
<pre class="r"><code>
bctGirls &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Girls&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctBoys &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Boys&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctInt &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Intervention&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctCont &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;Reminded self of positive consequences&#39; = PA_frqbct_01_T1,
&#39;Has logged PA on paper&#39; = PA_frqbct_02_T1,
&#39;Has monitored PA on smartphone&#39; = PA_frqbct_03_T1,
&#39;Uses mnemonic cues&#39; = PA_frqbct_04_T1,
&#39;Has compared actual with goal&#39; = PA_frqbct_05_T1,
&#39;Has thought of relevance of PA&#39; = PA_frqbct_06_T1,
&#39;Has made changes at home&#39; = PA_frqbct_07_T1,
&#39;Has sought social support&#39; = PA_frqbct_08_T1,
&#39;Has evaluated why goal not reached&#39; = PA_frqbct_09_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Control&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(bctInt, bctGirls, bctCont, bctBoys, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;))
## Warning: Removed 54 rows containing non-finite values (stat_binline).
## Warning: Removed 72 rows containing non-finite values (stat_binline).
## Warning: Removed 54 rows containing non-finite values (stat_binline).
## Warning: Removed 72 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-14-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
# grid.newpage()
# grid.draw(rbind(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), size = &quot;last&quot;), cbind(ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;)))</code></pre>
</div>
<div id="agreement-measured-bcts-1" class="section level4">
<h4>Agreement-measured BCTs</h4>
<p>These questions were asked with the lead “Have you done the following during the last three weeks?”.</p>
<p>The answer scale was as follows:</p>
<p>0 = not at all true 1 … 4 [unlabeled] 5 = completely true</p>
<p>Items are as follows:</p>
<ol style="list-style-type: decimal">
<li>I have set PA goals for myself.</li>
<li>I have personally made a specific plan (“what, where, how”) to implement my PA.</li>
<li>I have a PA plan, which has been made by someone else, e.g. my sports club (e.g. a workout schedule).</li>
<li>I have a way by which I remind myself of my PA plan, e.g. I write it down in the calendar.</li>
<li>I have cut larger PA goals to smaller subgoals.</li>
<li>I have tried out new ways for me to be physically active.</li>
<li>I have pondered, what kind of difficult situations or barriers prevent me from implementing my PA plan.</li>
<li>I have planned for ways to overcome barriers to doing PA.</li>
<li>I have thought about how PA fits my identity (self concept).</li>
<li>I have attempted to find ways to exercise so, that it won’t obstruct but instead helps actualise my other life values.</li>
</ol>
<pre class="r"><code>
bctGirls &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Girls&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctBoys &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Boys&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctInt &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Intervention&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

bctCont &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Has set goals&#39; = PA_agrbct_01_T1,
  &#39;Has made plan&#39; = PA_agrbct_02_T1,
  &#39;Plan made by other&#39; = PA_agrbct_03_T1,
  &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
  &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
  &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
  &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
  &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
  &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Control&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 6.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(bctInt, bctGirls, bctCont, bctBoys, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;))
## Warning: Removed 60 rows containing non-finite values (stat_binline).
## Warning: Removed 70 rows containing non-finite values (stat_binline).
## Warning: Removed 60 rows containing non-finite values (stat_binline).
## Warning: Removed 70 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-15-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
# grid.newpage()
# grid.draw(rbind(cbind(ggplotGrob(bctInt), ggplotGrob(bctCont), size = &quot;last&quot;), cbind(ggplotGrob(bctGirls), ggplotGrob(bctBoys), size = &quot;last&quot;)))

# bctBoys &lt;- df %&gt;% dplyr::select(id,
#   intervention,
#   group,
#   school,
#   girl,
#   &#39;Has set goals&#39; = PA_agrbct_01_T1,
#   &#39;Has made plan&#39; = PA_agrbct_02_T1,
#   &#39;Plan made by other&#39; = PA_agrbct_03_T1,
#   &#39;Has reminder of plan&#39; = PA_agrbct_04_T1,
#   &#39;Has cut goals to subgoals&#39; = PA_agrbct_05_T1,
#   &#39;Has tried new PA options&#39; = PA_agrbct_06_T1,
#   &#39;Has thought of barriers&#39; = PA_agrbct_07_T1,
#   &#39;Has planned for barriers&#39; = PA_agrbct_08_T1,
#   &#39;Has thought of PA identity&#39; = PA_agrbct_09_T1,
#   &#39;Has fitted PA to life values&#39; = PA_agrbct_10_T1)
# 
# mean(bctBoys$`Has set goals`, na.rm = T)
# mean(bctBoys$`Has made plan`, na.rm = T)
# mean(bctBoys$`Plan made by other`, na.rm = T)
# mean(bctBoys$`Has reminder of plan`, na.rm = T)
# mean(bctBoys$`Has cut goals to subgoals`, na.rm = T)
# mean(bctBoys$`Has tried new PA options`, na.rm = T)
# mean(bctBoys$`Has thought of barriers`, na.rm = T)
# mean(bctBoys$`Has planned for barriers`, na.rm = T)
# mean(bctBoys$`Has thought of PA identity`, na.rm = T)
# mean(bctBoys$`Has fitted PA to life values`, na.rm = T)</code></pre>
</div>
</div>
</div>
<div id="pa-determinants" class="section level2">
<h2>PA determinants</h2>
<pre class="r"><code>plot1 &lt;- df %&gt;% dplyr::select(id,
                              intervention,
                              group,
                              school,
                              girl,
                              &#39;PA intention&#39; = PA_intention_T1,
                              &#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
                              &#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
                              &#39;PA self efficacy&#39; = PA_selfefficacy_T1,
                              &#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
                              &#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
                              &#39;PA injunctive\nnorm&#39; = PA_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;%
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, colour = paste(Variable, girl), 
                                    fill = paste(Variable, girl)), 
                                    alpha = 0, size = 0.75, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 0&quot;, &quot;PA injunctive\nnorm 1&quot;),
                                labels = c( &#39;PA injunctive\nnorm 0&#39; = &quot;Boy&quot;, &#39;PA injunctive\nnorm 1&#39; = &quot;Girl&quot;),
                                values = viridis(4, end = 0.8)[c(1, 3)], #c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                                name = &quot;&quot;, guide = guide_legend(override.aes = list(alpha = 1))) +
  ggridges::scale_colour_cyclical(values = viridis(4, end = 0.8, alpha = 0.9)[c(1, 3)]) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10)) +
  geom_hline(yintercept = 1:7)
## Warning: attributes are not identical across measure variables;
## they will be dropped

target = c(
&quot;PA_intention_T1&quot;,
&quot;PA_outcomeExpectations_T1&quot;,
&quot;PA_pbc_T1&quot;,
&quot;PA_selfefficacy_T1&quot;,
&quot;PA_opportunities_T1&quot;,
&quot;PA_dnorm_T1&quot;,
&quot;PA_inorm_T1&quot;)

PA_ci_girls &lt;- ci_girls %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_girls &lt;- PA_ci_girls[match(target, PA_ci_girls$diamondlabels), ]

PA_ci_boys &lt;- ci_boys %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_boys &lt;- PA_ci_boys[match(target, PA_ci_boys$diamondlabels), ]

plot1 &lt;- plot1 + userfriendlyscience::diamondPlot(PA_ci_girls, returnLayerOnly = TRUE, color=viridis(4, end = 0.8)[c(3)], 
                alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_boys, returnLayerOnly = TRUE, color=viridis(4, end = 0.8)[c(1)],  
                alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

plot2 &lt;- df %&gt;% dplyr::select(id,
                              intervention,
                              group,
                              school,
                              girl,
                              &#39;PA intention&#39; = PA_intention_T1,
                              &#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
                              &#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
                              &#39;PA self efficacy&#39; = PA_selfefficacy_T1,
                              &#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
                              &#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
                              &#39;PA injunctive\nnorm&#39; = PA_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;%
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, colour = paste(Variable, intervention), 
                                    fill = paste(Variable, intervention)), 
                                    alpha = 0, size = 0.75, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 0&quot;, &quot;PA injunctive\nnorm 1&quot;),
                                labels = c( &#39;PA injunctive\nnorm 0&#39; = &quot;Control&quot;, &#39;PA injunctive\nnorm 1&#39; = &quot;Intervention&quot;),
                                values = c(viridis(4, end = 0.8)[c(2, 4)], viridis(6, end = 0.8)[c(2, 4)]), # get 2 x 2 colors, close to each other
                                name = &quot;&quot;, guide = guide_legend(override.aes = list(alpha = 1))) +
  ggridges::scale_colour_cyclical(values = viridis(4, end = 0.8, alpha = 0.9)[c(2, 4)]) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10)) +
  geom_hline(yintercept = 1:7)
## Warning: attributes are not identical across measure variables;
## they will be dropped

PA_ci_intervention &lt;- ci_intervention %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_intervention &lt;- PA_ci_intervention[match(target, PA_ci_intervention$diamondlabels), ]

PA_ci_control &lt;- ci_control %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_control &lt;- PA_ci_control[match(target, PA_ci_control$diamondlabels), ]

plot2 &lt;- plot2 + 
  userfriendlyscience::diamondPlot(PA_ci_intervention, returnLayerOnly = TRUE, color=viridis(4, end = 0.8)[c(4)],
              alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_control, returnLayerOnly = TRUE, color=viridis(4, end = 0.8)[c(2)], 
              alpha=.6, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

# grid.arrange(plot1, plot2, ncol = 2)
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.355
## Warning: Removed 641 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.359
## Warning: Removed 641 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-16-1.png" width="2100" /></p>
<pre class="r"><code>library(viridis)
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;PA action and\ncoping planning&#39; = PA_actCop_T1,
&#39;PA intention&#39; = PA_intention_T1,
&#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
&#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
&#39;PA self efficacy&#39; = PA_selfefficacy_T1,
&#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
&#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
&#39;PA injunctive\nnorm&#39; = PA_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .1, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 0&quot;, &quot;PA injunctive\nnorm 1&quot;),
                      labels = c( &#39;PA injunctive\nnorm 0&#39; = &quot;Boy&quot;, &#39;PA injunctive\nnorm 1&#39; = &quot;Girl&quot;),
                      values = viridis(4)[1:2], #c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10))
## Warning: attributes are not identical across measure variables;
## they will be dropped

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;PA action and\ncoping planning&#39; = PA_actCop_T1,
&#39;PA intention&#39; = PA_intention_T1,
&#39;PA outcome\nexpectations&#39; = PA_outcomeExpectations_T1,
&#39;PA perceived\nbehavioural control&#39; = PA_pbc_T1,
&#39;PA self efficacy&#39; = PA_selfefficacy_T1,
&#39;PA perceived\nopportunities&#39; = PA_opportunities_T1,
&#39;PA descriptive\nnorm&#39; = PA_dnorm_T1,
&#39;PA injunctive\nnorm&#39; = PA_inorm_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.), factor_key = TRUE) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .9, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;PA injunctive\nnorm 1&quot;, &quot;PA injunctive\nnorm 0&quot;),
                      labels = c(&#39;PA injunctive\nnorm 1&#39; = &quot;Intervention&quot;, &#39;PA injunctive\nnorm 0&#39; = &quot;Control&quot;),
                      values = viridis(4)[3:4], #c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;, axis.text=element_text(size=10))
## Warning: attributes are not identical across measure variables;
## they will be dropped

target = c(&quot;PA_actCop_T1&quot;,
&quot;PA_intention_T1&quot;,
&quot;PA_outcomeExpectations_T1&quot;,
&quot;PA_pbc_T1&quot;,
&quot;PA_selfefficacy_T1&quot;,
&quot;PA_opportunities_T1&quot;,
&quot;PA_dnorm_T1&quot;,
&quot;PA_inorm_T1&quot;)

PA_ci_girls &lt;- ci_girls %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_girls &lt;- PA_ci_girls[match(target, PA_ci_girls$diamondlabels), ]

PA_ci_boys &lt;- ci_boys %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_boys &lt;- PA_ci_boys[match(target, PA_ci_boys$diamondlabels), ]

plot1 &lt;- plot1 + 
  userfriendlyscience::diamondPlot(PA_ci_girls, returnLayerOnly = TRUE, color=viridis(4)[1],# &#39;blue&#39;, 
                alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_boys, returnLayerOnly = TRUE, color=viridis(4)[2], #&#39;green&#39;, 
                alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

PA_ci_intervention &lt;- ci_intervention %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_intervention &lt;- PA_ci_intervention[match(target, PA_ci_intervention$diamondlabels), ]

PA_ci_control &lt;- ci_control %&gt;% filter(diamondlabels %in% names(scales_T1) &amp; 
                                     grepl(&quot;PA_actCop_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_intention_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_outcomeExpectations_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_pbc_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_selfefficacy_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_opportunities_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_dnorm_T1&quot;, diamondlabels) | 
                                     grepl(&quot;PA_inorm_T1&quot;, diamondlabels))

PA_ci_control &lt;- PA_ci_control[match(target, PA_ci_control$diamondlabels), ]

plot2 &lt;- plot2 + 
  userfriendlyscience::diamondPlot(PA_ci_intervention, returnLayerOnly = TRUE, color=viridis(4)[4],# &#39;blue&#39;,
              alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2)) +
  userfriendlyscience::diamondPlot(PA_ci_control, returnLayerOnly = TRUE, color=viridis(4)[3], #&#39;red&#39;, 
              alpha=.95, fixedSize = 0.15, otherAxisCol = (1:length(target) + .2))

# grid.arrange(plot1, plot2, ncol = 2)
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(plot1), ggplotGrob(plot2), size = &quot;first&quot;))
## Picking joint bandwidth of 0.337
## Warning: Removed 733 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.341
## Warning: Removed 733 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-17-1.png" width="2100" /></p>
<pre class="r"><code>library(visreg)
library(broom)

m_pbcgirl &lt;- lme4::lmer(PA_pbc_T1 ~ girl + (1 | school), data = df)
summary(m_pbcgirl)
## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: PA_pbc_T1 ~ girl + (1 | school)
##    Data: df
## 
## REML criterion at convergence: 3561.2
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2903 -0.6705  0.1155  0.9014  1.4253 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. 
##  school   (Intercept) 1.393e-14 1.180e-07
##  Residual             1.619e+00 1.272e+00
## Number of obs: 1071, groups:  school, 5
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  5.18644    0.05164  100.43
## girl0        0.32578    0.07846    4.15
## 
## Correlation of Fixed Effects:
##       (Intr)
## girl0 -0.658

visreg::visreg(m_pbcgirl, &quot;school&quot;, type = &quot;contrast&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-18-1.png" width="2100" /></p>
<pre class="r"><code>
visreg(m_pbcgirl, &quot;girl&quot;, by=&quot;school&quot;, re.form=~(1|school))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-18-2.png" width="2100" /></p>
<pre class="r"><code>
glance(m_pbcgirl)
##      sigma    logLik      AIC      BIC deviance df.residual
## 1 1.272372 -1780.624 3569.247 3589.153 3553.336        1067</code></pre>
</div>
<div id="sb-determinants" class="section level2">
<h2>SB determinants</h2>
<pre class="r"><code>
plot1 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;SB intention&#39; = SB_intention_T1,
&#39;SB outcome\nexpectations&#39; = SB_outcomeExpectations_T1,
&#39;SB self-efficacy\nand perceived\nbehavioural control&#39; = SB_sePbc_T1,
&#39;SB descriptive\nnorm&#39; = SB_dnorm_T1,
&#39;SB injunctive\nnorm&#39; = SB_inorm_T1)  %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, girl)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;SB injunctive\nnorm 0&quot;, &quot;SB injunctive\nnorm 1&quot;),
                      labels = c( &#39;SB injunctive\nnorm 0&#39; = &quot;Boy&quot;, &#39;SB injunctive\nnorm 1&#39; = &quot;Girl&quot;),
                      values = c(&quot;#3bc600&quot;, &quot;#0000ff&quot;, &quot;#9cc68b&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

plot2 &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
&#39;SB intention&#39; = SB_intention_T1,
&#39;SB outcome\nexpectations&#39; = SB_outcomeExpectations_T1,
&#39;SB self-efficacy\nand perceived\nbehavioural control&#39; = SB_sePbc_T1,
&#39;SB descriptive\nnorm&#39; = SB_dnorm_T1,
&#39;SB injunctive\nnorm&#39; = SB_inorm_T1) %&gt;%
  # select(noquote(order(colnames(.)))) %&gt;% # Orders columns alphabetically
  tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;% 
  ggplot(aes(y = Variable)) +
  ggridges::geom_density_ridges(aes(x = Value, fill = paste(Variable, intervention)), 
           alpha = .6, color = &quot;black&quot;, from = 1, to = 7) +
  labs(x = &quot;&quot;,
       y = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), labels = NULL) +
  scale_x_continuous(expand = c(0.01, 0)) +
  ggridges::scale_fill_cyclical(breaks = c(&quot;SB injunctive\nnorm 1&quot;, &quot;SB injunctive\nnorm 0&quot;),
                      labels = c(&#39;SB injunctive\nnorm 1&#39; = &quot;Intervention&quot;, &#39;SB injunctive\nnorm 0&#39; = &quot;Control&quot;),
                      values = c(&quot;#ff0000&quot;, &quot;#0000ff&quot;, &quot;#ff8080&quot;, &quot;#8080ff&quot;),
                      name = &quot;&quot;, guide = &quot;legend&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(legend.position=&quot;bottom&quot;)

gridExtra::grid.arrange(plot1, plot2, ncol = 2)
## Picking joint bandwidth of 0.311
## Warning: Removed 507 rows containing non-finite values
## (stat_density_ridges).
## Picking joint bandwidth of 0.317
## Warning: Removed 507 rows containing non-finite values
## (stat_density_ridges).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-19-1.png" width="2100" /></p>
</div>
</div>
<div id="ciber-not-included-for-now" class="section level1">
<h1>CIBER (not included for now)</h1>
<pre class="r"><code>#p_install(&quot;userfriendlyscience&quot;)

# cat(names(df), sep = &quot;\&quot;,\n\&quot;&quot;)

# Make variables numeric, and d as data frame
d_num &lt;- df %&gt;% mutate_all(as.numeric) 
d_num &lt;- as.data.frame(d_num)

userfriendlyscience::CIBER(data = d_num,
      determinants = c(
        &quot;actCop_T1&quot;,
        &quot;agrbct_T1&quot;,
        &quot;amotivation_T1&quot;,
        &quot;autonomous_T1&quot;,
        &quot;b5agr_T1.1&quot;,
        &quot;b5cons_T1.1&quot;,
        &quot;b5ext_T1.1&quot;,
        &quot;b5neur_T1.1&quot;,
        &quot;b5open_T1.1&quot;,
        &quot;controlled_T1&quot;,
        &quot;dnorm_T1&quot;,
        &quot;frqbct_T1&quot;,
        &quot;goal_T1&quot;,
        &quot;inorm_T1&quot;,
        &quot;intention_T1&quot;,
        &quot;outcomeExpectations_T1&quot;,
        &quot;opportunities_T1&quot;,
        &quot;pbc_T1&quot;,
        &quot;selfefficacy_T1&quot;),
      targets = c(&quot;paT1&quot;, &quot;fatpct_T1&quot;),
      conf.level = list(means = 0.9999,
                        associations = 0.99)
      )

userfriendlyscience::CIBER(data = d_num,
      determinants = c(
        &quot;actCop_T1&quot;,
        &quot;agrbct_T1&quot;,
        &quot;frqbct_T1&quot;,
        &quot;amotivation_T1&quot;,
        &quot;autonomous_T1&quot;,
        &quot;controlled_T1&quot;,
        &quot;dnorm_T1&quot;,
        &quot;intention_T1&quot;,
        &quot;outcomeExpectations_T1&quot;,
        &quot;opportunities_T1&quot;,
        &quot;sePbc_T1&quot;),
      targets = c(&quot;paT1&quot;, &quot;fatpct_T1&quot;),
      conf.level = list(means = 0.9999,
                        associations = 0.99)
      )

# to create variable list for CIBER:
# cat(names(d), sep = &quot;\&quot;,\n\&quot;&quot;)

userfriendlyscience::CIBER(data = d_num,
  determinants = c(
  &quot;agrbct_01_T1&quot;,
  &quot;agrbct_02_T1&quot;,
  &quot;agrbct_03_T1&quot;,
  &quot;agrbct_04_T1&quot;,
  &quot;agrbct_05_T1&quot;,
  &quot;agrbct_06_T1&quot;,
  &quot;agrbct_07_T1&quot;,
  &quot;agrbct_08_T1&quot;,
  &quot;agrbct_09_T1&quot;,
  &quot;agrbct_10_T1&quot;,
  &quot;frqbct_01_T1&quot;,
  &quot;frqbct_02_T1&quot;,
  &quot;frqbct_03_T1&quot;,
  &quot;frqbct_04_T1&quot;,
  &quot;frqbct_05_T1&quot;,
  &quot;frqbct_06_T1&quot;,
  &quot;frqbct_07_T1&quot;,
  &quot;frqbct_08_T1&quot;,
  &quot;frqbct_09_T1&quot;),
   targets = c(&quot;MVPA&quot;, &quot;SB&quot;),
  leftAnchors = rep(&quot;&quot;, 19),
  rightAnchors = rep(&quot;&quot;, 19))

userfriendlyscience::CIBER(data = d_num,
  determinants = c(
  &quot;autonomous_01_T1&quot;,
  &quot;autonomous_02_T1&quot;,
  &quot;autonomous_03_T1&quot;,
  &quot;autonomous_04_T1&quot;,
  &quot;autonomous_05_T1&quot;,
  &quot;autonomous_06_T1&quot;,
  &quot;autonomous_07_T1&quot;,
  &quot;autonomous_08_T1&quot;,
  &quot;autonomous_09_T1&quot;),
   targets = c(&quot;MVPA&quot;, &quot;SB&quot;),
  leftAnchors = rep(&quot;&quot;, 9),
  rightAnchors = rep(&quot;&quot;, 9))

userfriendlyscience::CIBER(data = d_num,
  determinants = c(
  &quot;intention_01_T1&quot;,
  &quot;intention_02_T1&quot;,
  &quot;selfefficacy_01_T1&quot;,
  &quot;selfefficacy_02_T1&quot;,
  &quot;pbc_01_T1&quot;,
  &quot;pbc_02_T1&quot;,
  &quot;pbc_03_T1&quot;,
  &quot;norm_01_T1&quot;,
  &quot;norm_02_T1&quot;,
  &quot;outcomeExpectations_01_T1&quot;,
  &quot;outcomeExpectations_02_T1&quot;,
  &quot;outcomeExpectations_03_T1&quot;,
  &quot;outcomeExpectations_04_T1&quot;,
  &quot;outcomeExpectations_05_T1&quot;,
  &quot;outcomeExpectations_06_T1&quot;,
  &quot;outcomeExpectations_07_T1&quot;,
  &quot;outcomeExpectations_08_T1&quot;,
  &quot;outcomeExpectations_09_T1&quot;,
  &quot;outcomeExpectations_10_T1&quot;,
  &quot;outcomeExpectations_11_T1&quot;,
  &quot;outcomeExpectations_12_T1&quot;),
   targets = c(&quot;MVPA&quot;, &quot;SB&quot;),
  leftAnchors = rep(&quot;&quot;, 21),
  rightAnchors = rep(&quot;&quot;, 21))</code></pre>
</div>
<div id="density-plots" class="section level1">
<h1>Density plots</h1>
<div id="accelerometer-measured-pa" class="section level2">
<h2>Accelerometer-measured PA</h2>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- d
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(paAccelerometer_T1, intervention) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.paAccelerometer_T1_1 &lt;- sm.density.compare2(as.numeric(dens$paAccelerometer_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.25
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(paAccelerometer_T1, girl) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)
# Make plot
sm.paAccelerometer_T1_2 &lt;- sm.density.compare2(as.numeric(dens$paAccelerometer_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(paAccelerometer_T1, school) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Make plot
sm.paAccelerometer_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$paAccelerometer_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-21-1.png" width="2100" /></p>
</div>
<div id="time-spent-sitting-and-lying-down" class="section level2">
<h2>Time spent sitting and lying down</h2>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- d
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(sitLieAccelerometer_T1, intervention) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.sitLieAccelerometer_T1_1 &lt;- sm.density.compare2(as.numeric(dens$sitLieAccelerometer_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.09
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(sitLieAccelerometer_T1, girl) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.sitLieAccelerometer_T1_2 &lt;- sm.density.compare2(as.numeric(dens$sitLieAccelerometer_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(sitLieAccelerometer_T1, school) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)

# Make plot
sm.sitLieAccelerometer_T1_3 &lt;- sm::sm.density.compare(as.numeric(dens$sitLieAccelerometer_T1), dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;none&quot;)
legend(&quot;topright&quot;, c(&quot;Intervention school&quot;, &quot;Control school&quot;), col = c(4, 3), lty = c(1, 2), lwd = c(2, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-22-1.png" width="2100" /></p>
</div>
</div>
<div id="symptoms" class="section level1">
<h1>Symptoms</h1>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- df
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
 layout(matrix(c(1,2,3,3), nrow = 2, ncol = 2, byrow = TRUE), heights=c(2.5, 2))

## Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(symptom_T1, intervention) %&gt;% na.omit(densplot)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.symptom_T1_1 &lt;- sm.density.compare2(as.numeric(dens$symptom_T1), as.factor(dens$intervention), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.59
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

## Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(symptom_T1, girl)  %&gt;% na.omit(densplot)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.symptom_T1_2 &lt;- sm.density.compare2(as.numeric(dens$symptom_T1), as.factor(dens$girl), xlab=&quot;&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))

## Differences in schools
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(&quot;Symptom sum score&quot; = symptom_T1, school) %&gt;% na.omit(densplot)

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Intervention groups with solid thicker lines
linetypes &lt;- c(1,2,2,1,2)
linewidths &lt;- c(2,1,1,2,1)

# Make plot
sm.symptom_T1_3 &lt;- sm::sm.density.compare(dens$`Symptom sum score`, dens$school, xlab=&quot;&quot;, col=colfill, lty=linetypes, model=&quot;equal&quot;, lwd=linewidths)
## Reference band available to compare two groups only.</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-23-1.png" width="2100" /></p>
<pre><code>## 
## Test of equal densities:  p-value =  0
xlab = &quot;&quot;
</code></pre>
<div id="symptom-histograms" class="section level2">
<h2>Symptom histograms</h2>
<div id="intervention-gender" class="section level3">
<h3>intervention / gender</h3>
<pre class="r"><code>
sympGirls &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Girls&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympBoys &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Boys&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympInt &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Intervention&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympCont &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Control&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(sympInt, sympGirls, sympCont, sympBoys, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(sympInt), ggplotGrob(sympCont), ggplotGrob(sympGirls), ggplotGrob(sympBoys), size = &quot;last&quot;))
## Warning: Removed 198 rows containing non-finite values (stat_binline).
## Warning: Removed 93 rows containing non-finite values (stat_binline).
## Warning: Removed 197 rows containing non-finite values (stat_binline).
## Warning: Removed 94 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-24-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
#grid.newpage()
#grid.draw(rbind(cbind(ggplotGrob(sympInt), ggplotGrob(sympCont), size = &quot;last&quot;), cbind(ggplotGrob(sympGirls), ggplotGrob(sympBoys), size = &quot;last&quot;)))
</code></pre>
</div>
<div id="educational-track" class="section level3">
<h3>educational track</h3>
<pre class="r"><code>
sympHRC &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;HRC&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;HRC&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympNursing &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;Nursing&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Nursing&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympIT &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;Business IT&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Business IT&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

sympBA &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(track == &quot;Business Admin&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:4), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Business Admin&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5, size = 10),
        axis.text=element_text(size=10, face=&quot;bold&quot;)) +
coord_cartesian(xlim = c(0.5, 4.5))
## Warning: attributes are not identical across measure variables;
## they will be dropped

#grid.arrange(sympIT, sympHRC, sympBA, sympNursing, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(sympIT), ggplotGrob(sympBA), ggplotGrob(sympHRC), ggplotGrob(sympNursing), size = &quot;last&quot;))
## Warning: Removed 26 rows containing non-finite values (stat_binline).
## Warning: Removed 49 rows containing non-finite values (stat_binline).

## Warning: Removed 49 rows containing non-finite values (stat_binline).
## Warning: Removed 141 rows containing non-finite values (stat_binline).</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-25-1.png" width="2100" /></p>
<pre class="r"><code>
# This draws 2 histograms per row:
#grid.newpage()
#grid.draw(rbind(cbind(ggplotGrob(sympIT), ggplotGrob(sympBA), size = &quot;last&quot;), cbind(ggplotGrob(sympHRC), ggplotGrob(sympNursing), size = &quot;last&quot;)))
</code></pre>
</div>
</div>
</div>
<div id="under-construction-networks-of-psychosocial-variables" class="section level1">
<h1>UNDER CONSTRUCTION: Networks of psychosocial variables</h1>
</div>
<div id="bcts" class="section level1">
<h1>BCTs</h1>
<div id="graph-analysis" class="section level2">
<h2>Graph analysis</h2>
<div id="ising-networks" class="section level3">
<h3>Ising networks</h3>
<p>Prepare and dichotomise data (lots of skew in distributions).</p>
<pre class="r"><code>nItems &lt;- 19

bctdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;goal setting&#39; = PA_agrbct_01_T1,
  &#39;implementation plan&#39; = PA_agrbct_02_T1,
  &#39;plan by other&#39; = PA_agrbct_03_T1,
  &#39;reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;subgoals&#39; = PA_agrbct_05_T1,
  &#39;new PA options&#39; = PA_agrbct_06_T1,
  &#39;barrier identification&#39; = PA_agrbct_07_T1,
  &#39;coping planning&#39; = PA_agrbct_08_T1,
  &#39;PA identity&#39; = PA_agrbct_09_T1,
  &#39;PA life values&#39; = PA_agrbct_10_T1,
  &#39;positive consequences&#39; = PA_frqbct_01_T1,
  &#39;log on paper&#39; = PA_frqbct_02_T1,
  &#39;smartphone&#39; = PA_frqbct_03_T1,
  &#39;mnemonic cues&#39; = PA_frqbct_04_T1,
  &#39;goal contrast&#39; = PA_frqbct_05_T1,
  &#39;relevance of PA&#39; = PA_frqbct_06_T1,
  &#39;changes at home&#39; = PA_frqbct_07_T1,
  &#39;social support&#39; = PA_frqbct_08_T1,
  &#39;failure contemplated&#39; = PA_frqbct_09_T1) %&gt;%
 mutate(
  &#39;goal setting&#39; = ifelse(`goal setting` == 1, 0, 1),
  &#39;plan&#39; = ifelse(`plan` == 1, 0, 1),
  &#39;plan by other&#39; = ifelse(`plan by other` == 1, 0, 1),
  &#39;reminder of plan&#39; = ifelse(`reminder of plan` == 1, 0, 1),
  &#39;subgoals&#39; = ifelse(`subgoals` == 1, 0, 1),
  &#39;new PA options&#39; = ifelse(`new PA options` == 1, 0, 1),
  &#39;barrier identification&#39; = ifelse(`barrier identification` == 1, 0, 1),
  &#39;coping planning&#39; = ifelse(`coping planning` == 1, 0, 1),
  &#39;PA identity&#39; = ifelse(`PA identity` == 1, 0, 1),
  &#39;PA life values&#39; = ifelse(`PA life values` == 1, 0, 1),
  &#39;positive consequences&#39; = ifelse(`positive consequences` == 1, 0, 1),
  &#39;log on paper&#39; = ifelse(`log on paper` == 1, 0, 1),
  &#39;smartphone&#39; = ifelse(`smartphone` == 1, 0, 1),
  &#39;mnemonic cues&#39; = ifelse(`mnemonic cues` == 1, 0, 1),
  &#39;goal contrast&#39; = ifelse(`goal contrast` == 1, 0, 1),
  &#39;relevance of PA&#39; = ifelse(`relevance of PA` == 1, 0, 1),
  &#39;changes at home&#39; = ifelse(`changes at home` == 1, 0, 1),
  &#39;social support&#39; = ifelse(`social support` == 1, 0, 1),
  &#39;failure contemplated&#39; = ifelse(`failure contemplated` == 1, 0, 1)) %&gt;% 
  data.frame
## Error in mutate_impl(.data, dots): Evaluation error: object &#39;plan&#39; not found.

S.boys &lt;- bctdf %&gt;% filter(girl == 0) %&gt;% select(6:ncol(bctdf)) %&gt;% na.omit(.) 
S.girls &lt;- bctdf %&gt;% filter(girl == 1) %&gt;% select(6:ncol(bctdf)) %&gt;% na.omit(.)
nwBoys &lt;- bootnet::estimateNetwork(S.boys, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Error in y %*% rep(1, nc): non-conformable arguments
nwGirls &lt;- bootnet::estimateNetwork(S.girls, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Error in y %*% rep(1, nc): non-conformable arguments

# Create means for filling nodes

girlmeans &lt;- bctdf %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:(5+nItems-1)),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 1) %&gt;% 
  select(-1)

boymeans &lt;- bctdf %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:(5+nItems-1)),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 0) %&gt;% 
  select(-1)</code></pre>
<div id="plot-bct-ising-networks" class="section level4">
<h4>Plot BCT Ising-networks</h4>
<p>For girls and boys.</p>
<pre class="r"><code>
# Find average layout for comparability and plot graphs next to each other

Layout &lt;- averageLayout(nwGirls, nwBoys)

layout(t(1:2))

plot(nwGirls, layout = Layout, label.scale = FALSE, title = &quot;Girls&quot;, label.cex = 0.75,
     pie = girlmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in qgraph::qgraph(wMat, labels = labels, directed = directed, parallelEdge = parallelEdge, : Length of &#39;pie&#39; argument must be equal to number of nodes.

plot(nwBoys, layout = Layout, label.scale = FALSE, title = &quot;Boys&quot;, label.cex = 0.75, 
     pie = boymeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in qgraph::qgraph(wMat, labels = labels, directed = directed, parallelEdge = parallelEdge, : Length of &#39;pie&#39; argument must be equal to number of nodes.</code></pre>
<p>For all participants.</p>
<pre class="r"><code>
S.total &lt;- bctdf %&gt;% select(6:ncol(bctdf))
nwBCT &lt;- bootnet::estimateNetwork(S.total, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Error in y %*% rep(1, nc): non-conformable arguments

# smallworldIndex(plot(nwBCT))

# Create means for filling nodes
piefill &lt;- S.total %&gt;%
  summarise_all(funs(mean(., na.rm = TRUE))) 

# Plot network
plot(nwBCT, layout = &quot;spring&quot;, label.scale = FALSE, title = &quot;Ising fit&quot;, label.cex = 0.75,
     pie = piefill, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in qgraph::qgraph(wMat, labels = labels, directed = directed, parallelEdge = parallelEdge, : Length of &#39;pie&#39; argument must be equal to number of nodes.

# Estimate ising network without regularisation
nwBCT_nonreg &lt;- bootnet::estimateNetwork(S.total, default=&quot;IsingSampler&quot;)
## Estimating Network. Using package::function:
##   - IsingSampler::EstimateIsing for network computation
## &#39;method&#39; set to &#39;uni&#39;
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: algorithm did not converge

plot(nwBCT_nonreg, layout = &quot;spring&quot;, label.scale = FALSE, title = &quot;Non-regularised Ising model&quot;, label.cex = 0.75,
     pie = piefill, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Warning in qgraph::qgraph(wMat, labels = labels, directed = directed,
## parallelEdge = parallelEdge, : Non-finite weights are omitted
## Error in drawNode(x, y, shape[i], vsize[i], vsize2[i], borders[i], vertex.colors[i], : All elements in &#39;pie&#39; must be between 0 and 1.</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-28-1.png" width="2100" /></p>
<pre class="r"><code>
nItems &lt;- 19

bctdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;goal setting&#39; = PA_agrbct_01_T1,
  &#39;implementation plan&#39; = PA_agrbct_02_T1,
  &#39;plan by other&#39; = PA_agrbct_03_T1,
  &#39;reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;subgoals&#39; = PA_agrbct_05_T1,
  &#39;new PA options&#39; = PA_agrbct_06_T1,
  &#39;barrier identification&#39; = PA_agrbct_07_T1,
  &#39;coping planning&#39; = PA_agrbct_08_T1,
  &#39;PA identity&#39; = PA_agrbct_09_T1,
  &#39;PA life values&#39; = PA_agrbct_10_T1,
  &#39;positive consequences&#39; = PA_frqbct_01_T1,
  &#39;log on paper&#39; = PA_frqbct_02_T1,
  &#39;smartphone&#39; = PA_frqbct_03_T1,
  &#39;mnemonic cues&#39; = PA_frqbct_04_T1,
  &#39;goal contrast&#39; = PA_frqbct_05_T1,
  &#39;relevance of PA&#39; = PA_frqbct_06_T1,
  &#39;changes at home&#39; = PA_frqbct_07_T1,
  &#39;social support&#39; = PA_frqbct_08_T1,
  &#39;failure contemplated&#39; = PA_frqbct_09_T1) %&gt;%
 mutate(
  &#39;goals&#39; = ifelse(`goal setting` == 1, 0, 1),
  &#39;plan&#39; = ifelse(`plan` == 1, 0, 1),
  &#39;plan by other&#39; = ifelse(`plan by other` == 1, 0, 1),
  &#39;reminder of plan&#39; = ifelse(`reminder of plan` == 1, 0, 1),
  &#39;subgoals&#39; = ifelse(`subgoals` == 1, 0, 1),
  &#39;new PA options&#39; = ifelse(`new PA options` == 1, 0, 1),
  &#39;barrier identification&#39; = ifelse(`barrier identification` == 1, 0, 1),
  &#39;coping planning&#39; = ifelse(`coping planning` == 1, 0, 1),
  &#39;PA identity&#39; = ifelse(`PA identity` == 1, 0, 1),
  &#39;PA life values&#39; = ifelse(`PA life values` == 1, 0, 1),
  &#39;positive consequences&#39; = ifelse(`positive consequences` == 1, 0, 1),
  &#39;log on paper&#39; = ifelse(`log on paper` == 1, 0, 1),
  &#39;smartphone&#39; = ifelse(`smartphone` == 1, 0, 1),
  &#39;mnemonic cues&#39; = ifelse(`mnemonic cues` == 1, 0, 1),
  &#39;goal contrast&#39; = ifelse(`goal contrast` == 1, 0, 1),
  &#39;relevance of PA&#39; = ifelse(`relevance of PA` == 1, 0, 1),
  &#39;changes at home&#39; = ifelse(`changes at home` == 1, 0, 1),
  &#39;social support&#39; = ifelse(`social support` == 1, 0, 1),
  &#39;failure contemplated&#39; = ifelse(`failure contemplated` == 1, 0, 1)) %&gt;% 
  data.frame
## Error in mutate_impl(.data, dots): Evaluation error: object &#39;plan&#39; not found.

S.boys &lt;- bctdf %&gt;% filter(girl == 0) %&gt;% select(6:ncol(bctdf)) %&gt;% na.omit(.) 
S.girls &lt;- bctdf %&gt;% filter(girl == 1) %&gt;% select(6:ncol(bctdf)) %&gt;% na.omit(.)
nwBoys &lt;- bootnet::estimateNetwork(S.boys, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Error in y %*% rep(1, nc): non-conformable arguments
nwGirls &lt;- bootnet::estimateNetwork(S.girls, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Error in y %*% rep(1, nc): non-conformable arguments

# Create means for filling nodes

girlmeans &lt;- bctdf %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:(5+nItems-1)),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 1) %&gt;% 
  select(-1)

boymeans &lt;- bctdf %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:(5+nItems-1)),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 0) %&gt;% 
  select(-1)

# Find average layout for comparability and plot graphs next to each other

Layout &lt;- averageLayout(nwGirls, nwBoys)

layout(t(1:2))
plot(nwGirls, layout = Layout, label.scale = FALSE, title = &quot;Girls&quot;, label.cex = 0.75,
     pie = girlmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in qgraph::qgraph(wMat, labels = labels, directed = directed, parallelEdge = parallelEdge, : Length of &#39;pie&#39; argument must be equal to number of nodes.

plot(nwBoys, layout = Layout, label.scale = FALSE, title = &quot;Boys&quot;, label.cex = 0.75, 
     pie = boymeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in qgraph::qgraph(wMat, labels = labels, directed = directed, parallelEdge = parallelEdge, : Length of &#39;pie&#39; argument must be equal to number of nodes.</code></pre>
</div>
<div id="combine-items" class="section level4">
<h4>Combine items</h4>
<pre class="r"><code>nItems &lt;- 17

bctdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;goal setting&#39; = PA_agrbct_01_T1,
  &#39;implementation plan&#39; = PA_agrbct_02_T1,
  &#39;plan by other&#39; = PA_agrbct_03_T1,
  &#39;reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;subgoals&#39; = PA_agrbct_05_T1,
  &#39;new PA options&#39; = PA_agrbct_06_T1,
  &#39;barrier identification&#39; = PA_agrbct_07_T1,
  &#39;coping planning&#39; = PA_agrbct_08_T1,
  &#39;PA identity&#39; = PA_agrbct_09_T1,
  &#39;PA life values&#39; = PA_agrbct_10_T1,
  &#39;positive consequences&#39; = PA_frqbct_01_T1,
  &#39;log on paper&#39; = PA_frqbct_02_T1,
  &#39;smartphone&#39; = PA_frqbct_03_T1,
#  &#39;mnemonic cues&#39; = PA_frqbct_04_T1,
  &#39;goal contrast&#39; = PA_frqbct_05_T1,
  &#39;relevance of PA&#39; = PA_frqbct_06_T1,
  &#39;changes at home&#39; = PA_frqbct_07_T1,
  &#39;social support&#39; = PA_frqbct_08_T1,
  &#39;failure contemplated&#39; = PA_frqbct_09_T1) %&gt;%
 mutate(
  &#39;goals&#39; = ifelse(`goal setting` == 1, 0, 1),
  &#39;plan&#39; = ifelse(`plan` == 1 &amp; `plan by other` == 1, 0, 1),
  &#39;reminder of plan&#39; = ifelse(`reminder of plan` == 1, 0, 1),
  &#39;subgoals&#39; = ifelse(`subgoals` == 1, 0, 1),
  &#39;new PA options&#39; = ifelse(`new PA options` == 1, 0, 1),
  &#39;barrier identification&#39; = ifelse(`barrier identification` == 1, 0, 1),
  &#39;coping planning&#39; = ifelse(`coping planning` == 1, 0, 1),
  &#39;PA identity&#39; = ifelse(`PA identity` == 1, 0, 1),
  &#39;PA life values&#39; = ifelse(`PA life values` == 1, 0, 1),
  &#39;positive consequences&#39; = ifelse(`positive consequences` == 1, 0, 1),
  &#39;monitored PA&#39; = ifelse(`log on paper` == 1 &amp; `smartphone` == 1, 0, 1),
#  &#39;mnemonic cues&#39; = ifelse(`mnemonic cues` == 1, 0, 1),
  &#39;goal contrast&#39; = ifelse(`goal contrast` == 1, 0, 1),
  &#39;relevance of PA&#39; = ifelse(`relevance of PA` == 1, 0, 1),
  &#39;changes at home&#39; = ifelse(`changes at home` == 1, 0, 1),
  &#39;social support&#39; = ifelse(`social support` == 1, 0, 1),
  &#39;failure contemplated&#39; = ifelse(`failure contemplated` == 1, 0, 1)) %&gt;%
  select(-`log on paper`, -`smartphone`, -`plan by other`) %&gt;% 
  data.frame
## Error in mutate_impl(.data, dots): Evaluation error: object &#39;plan&#39; not found.

# S.boys &lt;- bctdf %&gt;% filter(girl == 0) %&gt;% select(6:ncol(bctdf)) %&gt;% na.omit(.) 
# S.girls &lt;- bctdf %&gt;% filter(girl == 1) %&gt;% select(6:ncol(bctdf)) %&gt;% na.omit(.)
# nwBoys &lt;- bootnet::estimateNetwork(S.boys, default=&quot;IsingFit&quot;)
# nwGirls &lt;- bootnet::estimateNetwork(S.girls, default=&quot;IsingFit&quot;)
# 
# # Create means for filling nodes
# 
# girlmeans &lt;- bctdf %&gt;% group_by(girl) %&gt;% 
#   summarise_at(vars(5:(5+nItems-1)),
#   funs(mean(., na.rm = TRUE))) %&gt;% 
#   filter(girl == 1) %&gt;% 
#   select(-1)
# 
# boymeans &lt;- bctdf %&gt;% group_by(girl) %&gt;% 
#   summarise_at(vars(5:(5+nItems-1)),
#   funs(mean(., na.rm = TRUE))) %&gt;% 
#   filter(girl == 0) %&gt;% 
#   select(-1)
# 
# # Find average layout for comparability and plot graphs next to each other
# 
# Layout &lt;- averageLayout(nwGirls, nwBoys)
# 
# layout(t(1:2))
# plot(nwGirls, layout = Layout, label.scale = FALSE, title = &quot;Girls&quot;, label.cex = 0.75,
#      pie = girlmeans, 
#      color = &quot;skyblue&quot;,
#      pieBorder = 1)
# 
# plot(nwBoys, layout = Layout, label.scale = FALSE, title = &quot;Boys&quot;, label.cex = 0.75, 
#      pie = boymeans, 
#      color = &quot;skyblue&quot;,
#      pieBorder = 1)

# Network for all participants

S.total &lt;- bctdf %&gt;% select(6:ncol(bctdf))
nwBCT &lt;- bootnet::estimateNetwork(S.total, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Error in y %*% rep(1, nc): non-conformable arguments

# smallworldIndex(plot(nwBCT))

# Create means for filling nodes
piefill &lt;- S.total %&gt;%
  summarise_all(funs(mean(., na.rm = TRUE))) 

# Plot network
plot(nwBCT, layout = &quot;spring&quot;, label.scale = FALSE, title = &quot;Ising fit&quot;, label.cex = 0.75,
     pie = piefill, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in qgraph::qgraph(wMat, labels = labels, directed = directed, parallelEdge = parallelEdge, : Length of &#39;pie&#39; argument must be equal to number of nodes.

# # Estimate ising network without regularisation
# nwBCT_nonreg &lt;- bootnet::estimateNetwork(S.total, default=&quot;IsingSampler&quot;)
# 
# plot(nwBCT_nonreg, layout = &quot;spring&quot;, label.scale = FALSE, title = &quot;Non-regularised Ising model&quot;, label.cex = 0.75,
#      pie = piefill, 
#      color = &quot;skyblue&quot;,
#      pieBorder = 1)</code></pre>
</div>
<div id="centrality-and-stability" class="section level4">
<h4>Centrality and stability</h4>
<pre class="r"><code>qgraph::centralityPlot(nwBCT)
## Note: z-scores are shown on x-axis rather than raw centrality indices.</code></pre>
<p><img src="baseline-supplement_files/figure-html/BCTstability-1.png" width="2100" /></p>
<pre class="r"><code>
boot2 &lt;- bootnet::bootnet(nwBCT, nBoots = 2500, type = &quot;case&quot;, nCores = 2)
## Estimating sample network...
## Estimating Network. Using package::function:
##   - qgraph::EBICglasso for EBIC model selection
##     - using glasso::glasso
##   - qgraph::cor_auto for correlation computation
##     - using lavaan::lavCor
## Variables detected as ordinal: goal.setting; implementation.plan; plan.by.other; reminder.of.plan; subgoals; new.PA.options; barrier.identification; coping.planning; PA.identity; PA.life.values; positive.consequences; goal.contrast; relevance.of.PA; changes.at.home; social.support
## Bootstrapping...
## Computing statistics...
bootnet::corStability(boot2)
## === Correlation Stability Analysis === 
## 
## Sampling levels tested:
##    nPerson Drop%   n
## 1      291  75.0 236
## 2      382  67.2 261
## 3      472  59.5 252
## 4      563  51.7 235
## 5      654  43.9 231
## 6      744  36.1 253
## 7      835  28.3 250
## 8      926  20.5 240
## 9     1016  12.8 279
## 10    1107   5.0 263
## 
## Maximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:
## 
## betweenness: 0.361
##   - For more accuracy, run bootnet(..., caseMin = 0.283, caseMax = 0.439) 
## 
## closeness: 0.672
##   - For more accuracy, run bootnet(..., caseMin = 0.595, caseMax = 0.75) 
## 
## strength: 0.75
##   - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) 
## 
## Accuracy can also be increased by increasing both &#39;nBoots&#39; and &#39;caseN&#39;.

plot(boot2)</code></pre>
<p><img src="baseline-supplement_files/figure-html/BCTstability-2.png" width="2100" /></p>
<pre class="r"><code>plot(boot2, &quot;strength&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/BCTstability-3.png" width="2100" /></p>
<pre class="r"><code>plot(boot2, &quot;betweenness&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/BCTstability-4.png" width="2100" /></p>
<pre class="r"><code>plot(boot2, &quot;closeness&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/BCTstability-5.png" width="2100" /></p>
</div>
<div id="network-comparison-test-boys-vs.girls" class="section level4">
<h4>Network comparison test: boys vs. girls</h4>
<pre class="r"><code>
nct_results &lt;- NetworkComparisonTest::NCT(nwGirls, nwBoys, it=1000, binary.data=TRUE, paired=FALSE, test.edges=TRUE, edges=&#39;all&#39;, progressbar=TRUE)

nct_results$nwinv.pval  # p value of network structure diff test: 0.424
nct_results$glstrinv.pval  # p value of global connectivity diff test: 0.071
nct_results$einv.pvals     #p values testing diffs for all individual edges: lowest p-value 0.017, most = 1
sum(nct_results$einv.pvals$&quot;p-value&quot; &lt; 0.05)  # how many edges are different0
</code></pre>
</div>
</div>
<div id="ggm-bcts-motivation" class="section level3">
<h3>GGM BCTs &amp; motivation</h3>
<pre class="r"><code>library(corrgram)

nItems &lt;- 19

bctdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Autonomous&#39; = PA_autonomous_T1,
  &#39;Controlled&#39; = PA_controlled_T1,
  &#39;goal setting&#39; = PA_agrbct_01_T1,
  &#39;implementation plan&#39; = PA_agrbct_02_T1,
  &#39;plan by other&#39; = PA_agrbct_03_T1,
  &#39;reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;subgoals&#39; = PA_agrbct_05_T1,
  &#39;new PA options&#39; = PA_agrbct_06_T1,
  &#39;barrier identification&#39; = PA_agrbct_07_T1,
  &#39;coping planning&#39; = PA_agrbct_08_T1,
  &#39;PA identity&#39; = PA_agrbct_09_T1,
  &#39;PA life values&#39; = PA_agrbct_10_T1,
  &#39;positive consequences&#39; = PA_frqbct_01_T1,
  &#39;log on paper&#39; = PA_frqbct_02_T1,
  &#39;smartphone&#39; = PA_frqbct_03_T1,
#  &#39;mnemonic cues&#39; = PA_frqbct_04_T1,
  &#39;goal contrast&#39; = PA_frqbct_05_T1,
  &#39;relevance of PA&#39; = PA_frqbct_06_T1,
  &#39;changes at home&#39; = PA_frqbct_07_T1,
  &#39;social support&#39; = PA_frqbct_08_T1,
  &#39;failure contemplated&#39; = PA_frqbct_09_T1) %&gt;%
  rowwise() %&gt;% 
  mutate( 
  #&#39;has plan&#39; = mean(c(`implementation plan`, `plan by other`), na.rm = TRUE),
  &#39;monitored PA&#39; = mean(c(`log on paper`, `smartphone`), na.rm = TRUE)) %&gt;%
  select(-`log on paper`, -`smartphone`) %&gt;% 
  data.frame %&gt;% 
  mutate_all(as.numeric)
## Warning in evalq(as.numeric(id), &lt;environment&gt;): NAs introduced by coercion
## Warning in evalq(as.numeric(group), &lt;environment&gt;): NAs introduced by
## coercion

# Network for all participants

S.total &lt;- bctdf %&gt;% select(`Autonomous`:ncol(bctdf))
nwBCT &lt;- bootnet::estimateNetwork(S.total, default=&quot;EBICglasso&quot;)
## Estimating Network. Using package::function:
##   - qgraph::EBICglasso for EBIC model selection
##     - using glasso::glasso
##   - qgraph::cor_auto for correlation computation
##     - using lavaan::lavCor
## Variables detected as ordinal: goal.setting; implementation.plan; plan.by.other; reminder.of.plan; subgoals; new.PA.options; barrier.identification; coping.planning; PA.identity; PA.life.values; positive.consequences; goal.contrast; relevance.of.PA; changes.at.home; social.support

# Plot correlations (minmax crowds the diagonal as it plots the minimum and maximum values for each variable).
labs &lt;- colnames(S.total)
corrgram::corrgram(S.total, 
         cor.method = &quot;spearman&quot;, 
         # diag.panel=panel.minmax, 
         # lower.panel=panel.shade, 
         # lower.panel=panel.ellipse,
         # lower.panel=panel.cor,
         upper.panel=panel.conf,
         lower.panel=panel.pie,
         outer.labels=list(
           bottom=list(labels=labs,cex=.75, srt=60),
           left=list(labels=labs,cex=.75, srt=30))
         )</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-31-1.png" width="2100" /></p>
<pre class="r"><code>
labs &lt;- colnames(S.total)
corrgram::corrgram(S.total, 
         cor.method = &quot;spearman&quot;,
         upper.panel=panel.ellipse,
         lower.panel=panel.pie,
         outer.labels=list(
           bottom=list(labels=labs,cex=.75, srt=60),
           left=list(labels=labs,cex=.75, srt=30))
         )</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-31-2.png" width="2100" /></p>
<pre class="r"><code>
# Create means for filling nodes
piefill &lt;- S.total %&gt;%
  summarise_all(funs(median(., na.rm = TRUE) / 6)) 

# Plot network
plot(nwBCT, layout = &quot;spring&quot;, label.scale = FALSE, title = &quot;GGM, BCTs &amp; motivation&quot;, label.cex = 0.75,
     pie = piefill, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-31-3.png" width="2100" /></p>
<pre class="r"><code>
# Combine items further:
bctdf2 &lt;- bctdf %&gt;% rowwise %&gt;% 
  mutate(&#39;goals and plans&#39; = mean(c(`goal.setting`, `implementation.plan`), na.rm = TRUE)) %&gt;% 
  mutate(&#39;barriers identified\nand planned for&#39; = mean(c(`barrier.identification`, `coping.planning`), na.rm = TRUE)) %&gt;% 
  select(-`goal.setting`, -`implementation.plan`, -`barrier.identification`, -`coping.planning`) %&gt;% 
  data.frame

S.total2 &lt;- bctdf2 %&gt;% select(`Autonomous`:ncol(bctdf2))
nwBCT2 &lt;- bootnet::estimateNetwork(S.total2, default=&quot;EBICglasso&quot;)
## Estimating Network. Using package::function:
##   - qgraph::EBICglasso for EBIC model selection
##     - using glasso::glasso
##   - qgraph::cor_auto for correlation computation
##     - using lavaan::lavCor
## Variables detected as ordinal: plan.by.other; reminder.of.plan; subgoals; new.PA.options; PA.identity; PA.life.values; positive.consequences; goal.contrast; relevance.of.PA; changes.at.home; social.support

# Create means for filling nodes
piefill2 &lt;- S.total2 %&gt;%
  mutate(Autonomous = Autonomous * 6/5, # Transform these from scale 1-5 to 1-6
         Controlled = Controlled * 6/5) %&gt;% 
  summarise_all(funs(median(., na.rm = TRUE) / 6)) 

# Plot network
plot(nwBCT2, layout = &quot;spring&quot;, label.scale = FALSE, title = &quot;GGM, BCTs &amp; motivation&quot;, label.cex = 0.75,
     pie = piefill2, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-31-4.png" width="2100" /></p>
<div id="stability-and-robustness" class="section level4">
<h4>Stability and robustness</h4>
<p>Robustness test</p>
<pre class="r"><code>
qgraph::centralityPlot(nwBCT)
## Note: z-scores are shown on x-axis rather than raw centrality indices.</code></pre>
<p><img src="baseline-supplement_files/figure-html/bct-robustness-1.png" width="2100" /></p>
<pre class="r"><code>qgraph::centralityPlot(nwBCT2)
## Note: z-scores are shown on x-axis rather than raw centrality indices.</code></pre>
<p><img src="baseline-supplement_files/figure-html/bct-robustness-2.png" width="2100" /></p>
<pre class="r"><code>
BCTboot1 &lt;- bootnet::bootnet(nwBCT, nBoots = 2500)
## Estimating sample network...
## Estimating Network. Using package::function:
##   - qgraph::EBICglasso for EBIC model selection
##     - using glasso::glasso
##   - qgraph::cor_auto for correlation computation
##     - using lavaan::lavCor
## Variables detected as ordinal: goal.setting; implementation.plan; plan.by.other; reminder.of.plan; subgoals; new.PA.options; barrier.identification; coping.planning; PA.identity; PA.life.values; positive.consequences; goal.contrast; relevance.of.PA; changes.at.home; social.support
## Bootstrapping...
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |                                                                 |   1%
  |                                                                       
  |=                                                                |   1%
  |                                                                       
  |=                                                                |   2%
  |                                                                       
  |==                                                               |   2%
  |                                                                       
  |==                                                               |   3%
  |                                                                       
  |==                                                               |   4%
  |                                                                       
  |===                                                              |   4%
  |                                                                       
  |===                                                              |   5%
  |                                                                       
  |====                                                             |   5%
  |                                                                       
  |====                                                             |   6%
  |                                                                       
  |====                                                             |   7%
  |                                                                       
  |=====                                                            |   7%
  |                                                                       
  |=====                                                            |   8%
  |                                                                       
  |======                                                           |   8%
  |                                                                       
  |======                                                           |   9%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=======                                                          |  10%
  |                                                                       
  |=======                                                          |  11%
  |                                                                       
  |=======                                                          |  12%
  |                                                                       
  |========                                                         |  12%
  |                                                                       
  |========                                                         |  13%
  |                                                                       
  |=========                                                        |  13%
  |                                                                       
  |=========                                                        |  14%
  |                                                                       
  |=========                                                        |  15%
  |                                                                       
  |==========                                                       |  15%
  |                                                                       
  |==========                                                       |  16%
  |                                                                       
  |===========                                                      |  16%
  |                                                                       
  |===========                                                      |  17%
  |                                                                       
  |===========                                                      |  18%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |============                                                     |  19%
  |                                                                       
  |=============                                                    |  19%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |=============                                                    |  21%
  |                                                                       
  |==============                                                   |  21%
  |                                                                       
  |==============                                                   |  22%
  |                                                                       
  |===============                                                  |  22%
  |                                                                       
  |===============                                                  |  23%
  |                                                                       
  |===============                                                  |  24%
  |                                                                       
  |================                                                 |  24%
  |                                                                       
  |================                                                 |  25%
  |                                                                       
  |=================                                                |  25%
  |                                                                       
  |=================                                                |  26%
  |                                                                       
  |=================                                                |  27%
  |                                                                       
  |==================                                               |  27%
  |                                                                       
  |==================                                               |  28%
  |                                                                       
  |===================                                              |  28%
  |                                                                       
  |===================                                              |  29%
  |                                                                       
  |===================                                              |  30%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |====================                                             |  31%
  |                                                                       
  |====================                                             |  32%
  |                                                                       
  |=====================                                            |  32%
  |                                                                       
  |=====================                                            |  33%
  |                                                                       
  |======================                                           |  33%
  |                                                                       
  |======================                                           |  34%
  |                                                                       
  |======================                                           |  35%
  |                                                                       
  |=======================                                          |  35%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |========================                                         |  36%
  |                                                                       
  |========================                                         |  37%
  |                                                                       
  |========================                                         |  38%
  |                                                                       
  |=========================                                        |  38%
  |                                                                       
  |=========================                                        |  39%
  |                                                                       
  |==========================                                       |  39%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |==========================                                       |  41%
  |                                                                       
  |===========================                                      |  41%
  |                                                                       
  |===========================                                      |  42%
  |                                                                       
  |============================                                     |  42%
  |                                                                       
  |============================                                     |  43%
  |                                                                       
  |============================                                     |  44%
  |                                                                       
  |=============================                                    |  44%
  |                                                                       
  |=============================                                    |  45%
  |                                                                       
  |==============================                                   |  45%
  |                                                                       
  |==============================                                   |  46%
  |                                                                       
  |==============================                                   |  47%
  |                                                                       
  |===============================                                  |  47%
  |                                                                       
  |===============================                                  |  48%
  |                                                                       
  |================================                                 |  48%
  |                                                                       
  |================================                                 |  49%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=================================                                |  50%
  |                                                                       
  |=================================                                |  51%
  |                                                                       
  |=================================                                |  52%
  |                                                                       
  |==================================                               |  52%
  |                                                                       
  |==================================                               |  53%
  |                                                                       
  |===================================                              |  53%
  |                                                                       
  |===================================                              |  54%
  |                                                                       
  |===================================                              |  55%
  |                                                                       
  |====================================                             |  55%
  |                                                                       
  |====================================                             |  56%
  |                                                                       
  |=====================================                            |  56%
  |                                                                       
  |=====================================                            |  57%
  |                                                                       
  |=====================================                            |  58%
  |                                                                       
  |======================================                           |  58%
  |                                                                       
  |======================================                           |  59%
  |                                                                       
  |=======================================                          |  59%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |=======================================                          |  61%
  |                                                                       
  |========================================                         |  61%
  |                                                                       
  |========================================                         |  62%
  |                                                                       
  |=========================================                        |  62%
  |                                                                       
  |=========================================                        |  63%
  |                                                                       
  |=========================================                        |  64%
  |                                                                       
  |==========================================                       |  64%
  |                                                                       
  |==========================================                       |  65%
  |                                                                       
  |===========================================                      |  65%
  |                                                                       
  |===========================================                      |  66%
  |                                                                       
  |===========================================                      |  67%
  |                                                                       
  |============================================                     |  67%
  |                                                                       
  |============================================                     |  68%
  |                                                                       
  |=============================================                    |  68%
  |                                                                       
  |=============================================                    |  69%
  |                                                                       
  |=============================================                    |  70%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |==============================================                   |  71%
  |                                                                       
  |==============================================                   |  72%
  |                                                                       
  |===============================================                  |  72%
  |                                                                       
  |===============================================                  |  73%
  |                                                                       
  |================================================                 |  73%
  |                                                                       
  |================================================                 |  74%
  |                                                                       
  |================================================                 |  75%
  |                                                                       
  |=================================================                |  75%
  |                                                                       
  |=================================================                |  76%
  |                                                                       
  |==================================================               |  76%
  |                                                                       
  |==================================================               |  77%
  |                                                                       
  |==================================================               |  78%
  |                                                                       
  |===================================================              |  78%
  |                                                                       
  |===================================================              |  79%
  |                                                                       
  |====================================================             |  79%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |====================================================             |  81%
  |                                                                       
  |=====================================================            |  81%
  |                                                                       
  |=====================================================            |  82%
  |                                                                       
  |======================================================           |  82%
  |                                                                       
  |======================================================           |  83%
  |                                                                       
  |======================================================           |  84%
  |                                                                       
  |=======================================================          |  84%
  |                                                                       
  |=======================================================          |  85%
  |                                                                       
  |========================================================         |  85%
  |                                                                       
  |========================================================         |  86%
  |                                                                       
  |========================================================         |  87%
  |                                                                       
  |=========================================================        |  87%
  |                                                                       
  |=========================================================        |  88%
  |                                                                       
  |==========================================================       |  88%
  |                                                                       
  |==========================================================       |  89%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |===========================================================      |  90%
  |                                                                       
  |===========================================================      |  91%
  |                                                                       
  |===========================================================      |  92%
  |                                                                       
  |============================================================     |  92%
  |                                                                       
  |============================================================     |  93%
  |                                                                       
  |=============================================================    |  93%
  |                                                                       
  |=============================================================    |  94%
  |                                                                       
  |=============================================================    |  95%
  |                                                                       
  |==============================================================   |  95%
  |                                                                       
  |==============================================================   |  96%
  |                                                                       
  |===============================================================  |  96%
  |                                                                       
  |===============================================================  |  97%
  |                                                                       
  |===============================================================  |  98%
  |                                                                       
  |================================================================ |  98%
  |                                                                       
  |================================================================ |  99%
  |                                                                       
  |=================================================================|  99%
  |                                                                       
  |=================================================================| 100%
## Computing statistics...
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |                                                                 |   1%
  |                                                                       
  |=                                                                |   1%
  |                                                                       
  |=                                                                |   2%
  |                                                                       
  |==                                                               |   2%
  |                                                                       
  |==                                                               |   3%
  |                                                                       
  |==                                                               |   4%
  |                                                                       
  |===                                                              |   4%
  |                                                                       
  |===                                                              |   5%
  |                                                                       
  |====                                                             |   5%
  |                                                                       
  |====                                                             |   6%
  |                                                                       
  |====                                                             |   7%
  |                                                                       
  |=====                                                            |   7%
  |                                                                       
  |=====                                                            |   8%
  |                                                                       
  |======                                                           |   8%
  |                                                                       
  |======                                                           |   9%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=======                                                          |  10%
  |                                                                       
  |=======                                                          |  11%
  |                                                                       
  |=======                                                          |  12%
  |                                                                       
  |========                                                         |  12%
  |                                                                       
  |========                                                         |  13%
  |                                                                       
  |=========                                                        |  13%
  |                                                                       
  |=========                                                        |  14%
  |                                                                       
  |=========                                                        |  15%
  |                                                                       
  |==========                                                       |  15%
  |                                                                       
  |==========                                                       |  16%
  |                                                                       
  |===========                                                      |  16%
  |                                                                       
  |===========                                                      |  17%
  |                                                                       
  |===========                                                      |  18%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |============                                                     |  19%
  |                                                                       
  |=============                                                    |  19%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |=============                                                    |  21%
  |                                                                       
  |==============                                                   |  21%
  |                                                                       
  |==============                                                   |  22%
  |                                                                       
  |===============                                                  |  22%
  |                                                                       
  |===============                                                  |  23%
  |                                                                       
  |===============                                                  |  24%
  |                                                                       
  |================                                                 |  24%
  |                                                                       
  |================                                                 |  25%
  |                                                                       
  |=================                                                |  25%
  |                                                                       
  |=================                                                |  26%
  |                                                                       
  |=================                                                |  27%
  |                                                                       
  |==================                                               |  27%
  |                                                                       
  |==================                                               |  28%
  |                                                                       
  |===================                                              |  28%
  |                                                                       
  |===================                                              |  29%
  |                                                                       
  |===================                                              |  30%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |====================                                             |  31%
  |                                                                       
  |====================                                             |  32%
  |                                                                       
  |=====================                                            |  32%
  |                                                                       
  |=====================                                            |  33%
  |                                                                       
  |======================                                           |  33%
  |                                                                       
  |======================                                           |  34%
  |                                                                       
  |======================                                           |  35%
  |                                                                       
  |=======================                                          |  35%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |========================                                         |  36%
  |                                                                       
  |========================                                         |  37%
  |                                                                       
  |========================                                         |  38%
  |                                                                       
  |=========================                                        |  38%
  |                                                                       
  |=========================                                        |  39%
  |                                                                       
  |==========================                                       |  39%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |==========================                                       |  41%
  |                                                                       
  |===========================                                      |  41%
  |                                                                       
  |===========================                                      |  42%
  |                                                                       
  |============================                                     |  42%
  |                                                                       
  |============================                                     |  43%
  |                                                                       
  |============================                                     |  44%
  |                                                                       
  |=============================                                    |  44%
  |                                                                       
  |=============================                                    |  45%
  |                                                                       
  |==============================                                   |  45%
  |                                                                       
  |==============================                                   |  46%
  |                                                                       
  |==============================                                   |  47%
  |                                                                       
  |===============================                                  |  47%
  |                                                                       
  |===============================                                  |  48%
  |                                                                       
  |================================                                 |  48%
  |                                                                       
  |================================                                 |  49%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=================================                                |  50%
  |                                                                       
  |=================================                                |  51%
  |                                                                       
  |=================================                                |  52%
  |                                                                       
  |==================================                               |  52%
  |                                                                       
  |==================================                               |  53%
  |                                                                       
  |===================================                              |  53%
  |                                                                       
  |===================================                              |  54%
  |                                                                       
  |===================================                              |  55%
  |                                                                       
  |====================================                             |  55%
  |                                                                       
  |====================================                             |  56%
  |                                                                       
  |=====================================                            |  56%
  |                                                                       
  |=====================================                            |  57%
  |                                                                       
  |=====================================                            |  58%
  |                                                                       
  |======================================                           |  58%
  |                                                                       
  |======================================                           |  59%
  |                                                                       
  |=======================================                          |  59%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |=======================================                          |  61%
  |                                                                       
  |========================================                         |  61%
  |                                                                       
  |========================================                         |  62%
  |                                                                       
  |=========================================                        |  62%
  |                                                                       
  |=========================================                        |  63%
  |                                                                       
  |=========================================                        |  64%
  |                                                                       
  |==========================================                       |  64%
  |                                                                       
  |==========================================                       |  65%
  |                                                                       
  |===========================================                      |  65%
  |                                                                       
  |===========================================                      |  66%
  |                                                                       
  |===========================================                      |  67%
  |                                                                       
  |============================================                     |  67%
  |                                                                       
  |============================================                     |  68%
  |                                                                       
  |=============================================                    |  68%
  |                                                                       
  |=============================================                    |  69%
  |                                                                       
  |=============================================                    |  70%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |==============================================                   |  71%
  |                                                                       
  |==============================================                   |  72%
  |                                                                       
  |===============================================                  |  72%
  |                                                                       
  |===============================================                  |  73%
  |                                                                       
  |================================================                 |  73%
  |                                                                       
  |================================================                 |  74%
  |                                                                       
  |================================================                 |  75%
  |                                                                       
  |=================================================                |  75%
  |                                                                       
  |=================================================                |  76%
  |                                                                       
  |==================================================               |  76%
  |                                                                       
  |==================================================               |  77%
  |                                                                       
  |==================================================               |  78%
  |                                                                       
  |===================================================              |  78%
  |                                                                       
  |===================================================              |  79%
  |                                                                       
  |====================================================             |  79%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |====================================================             |  81%
  |                                                                       
  |=====================================================            |  81%
  |                                                                       
  |=====================================================            |  82%
  |                                                                       
  |======================================================           |  82%
  |                                                                       
  |======================================================           |  83%
  |                                                                       
  |======================================================           |  84%
  |                                                                       
  |=======================================================          |  84%
  |                                                                       
  |=======================================================          |  85%
  |                                                                       
  |========================================================         |  85%
  |                                                                       
  |========================================================         |  86%
  |                                                                       
  |========================================================         |  87%
  |                                                                       
  |=========================================================        |  87%
  |                                                                       
  |=========================================================        |  88%
  |                                                                       
  |==========================================================       |  88%
  |                                                                       
  |==========================================================       |  89%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |===========================================================      |  90%
  |                                                                       
  |===========================================================      |  91%
  |                                                                       
  |===========================================================      |  92%
  |                                                                       
  |============================================================     |  92%
  |                                                                       
  |============================================================     |  93%
  |                                                                       
  |=============================================================    |  93%
  |                                                                       
  |=============================================================    |  94%
  |                                                                       
  |=============================================================    |  95%
  |                                                                       
  |==============================================================   |  95%
  |                                                                       
  |==============================================================   |  96%
  |                                                                       
  |===============================================================  |  96%
  |                                                                       
  |===============================================================  |  97%
  |                                                                       
  |===============================================================  |  98%
  |                                                                       
  |================================================================ |  98%
  |                                                                       
  |================================================================ |  99%
  |                                                                       
  |=================================================================|  99%
  |                                                                       
  |=================================================================| 100%
BCTboot2 &lt;- bootnet::bootnet(nwBCT2, nBoots = 2500)
## Estimating sample network...
## Estimating Network. Using package::function:
##   - qgraph::EBICglasso for EBIC model selection
##     - using glasso::glasso
##   - qgraph::cor_auto for correlation computation
##     - using lavaan::lavCor
## Variables detected as ordinal: plan.by.other; reminder.of.plan; subgoals; new.PA.options; PA.identity; PA.life.values; positive.consequences; goal.contrast; relevance.of.PA; changes.at.home; social.support
## Bootstrapping...
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |                                                                 |   1%
  |                                                                       
  |=                                                                |   1%
  |                                                                       
  |=                                                                |   2%
  |                                                                       
  |==                                                               |   2%
  |                                                                       
  |==                                                               |   3%
  |                                                                       
  |==                                                               |   4%
  |                                                                       
  |===                                                              |   4%
  |                                                                       
  |===                                                              |   5%
  |                                                                       
  |====                                                             |   5%
  |                                                                       
  |====                                                             |   6%
  |                                                                       
  |====                                                             |   7%
  |                                                                       
  |=====                                                            |   7%
  |                                                                       
  |=====                                                            |   8%
  |                                                                       
  |======                                                           |   8%
  |                                                                       
  |======                                                           |   9%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=======                                                          |  10%
  |                                                                       
  |=======                                                          |  11%
  |                                                                       
  |=======                                                          |  12%
  |                                                                       
  |========                                                         |  12%
  |                                                                       
  |========                                                         |  13%
  |                                                                       
  |=========                                                        |  13%
  |                                                                       
  |=========                                                        |  14%
  |                                                                       
  |=========                                                        |  15%
  |                                                                       
  |==========                                                       |  15%
  |                                                                       
  |==========                                                       |  16%
  |                                                                       
  |===========                                                      |  16%
  |                                                                       
  |===========                                                      |  17%
  |                                                                       
  |===========                                                      |  18%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |============                                                     |  19%
  |                                                                       
  |=============                                                    |  19%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |=============                                                    |  21%
  |                                                                       
  |==============                                                   |  21%
  |                                                                       
  |==============                                                   |  22%
  |                                                                       
  |===============                                                  |  22%
  |                                                                       
  |===============                                                  |  23%
  |                                                                       
  |===============                                                  |  24%
  |                                                                       
  |================                                                 |  24%
  |                                                                       
  |================                                                 |  25%
  |                                                                       
  |=================                                                |  25%
  |                                                                       
  |=================                                                |  26%
  |                                                                       
  |=================                                                |  27%
  |                                                                       
  |==================                                               |  27%
  |                                                                       
  |==================                                               |  28%
  |                                                                       
  |===================                                              |  28%
  |                                                                       
  |===================                                              |  29%
  |                                                                       
  |===================                                              |  30%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |====================                                             |  31%
  |                                                                       
  |====================                                             |  32%
  |                                                                       
  |=====================                                            |  32%
  |                                                                       
  |=====================                                            |  33%
  |                                                                       
  |======================                                           |  33%
  |                                                                       
  |======================                                           |  34%
  |                                                                       
  |======================                                           |  35%
  |                                                                       
  |=======================                                          |  35%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |========================                                         |  36%
  |                                                                       
  |========================                                         |  37%
  |                                                                       
  |========================                                         |  38%
  |                                                                       
  |=========================                                        |  38%
  |                                                                       
  |=========================                                        |  39%
  |                                                                       
  |==========================                                       |  39%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |==========================                                       |  41%
  |                                                                       
  |===========================                                      |  41%
  |                                                                       
  |===========================                                      |  42%
  |                                                                       
  |============================                                     |  42%
  |                                                                       
  |============================                                     |  43%
  |                                                                       
  |============================                                     |  44%
  |                                                                       
  |=============================                                    |  44%
  |                                                                       
  |=============================                                    |  45%
  |                                                                       
  |==============================                                   |  45%
  |                                                                       
  |==============================                                   |  46%
  |                                                                       
  |==============================                                   |  47%
  |                                                                       
  |===============================                                  |  47%
  |                                                                       
  |===============================                                  |  48%
  |                                                                       
  |================================                                 |  48%
  |                                                                       
  |================================                                 |  49%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=================================                                |  50%
  |                                                                       
  |=================================                                |  51%
  |                                                                       
  |=================================                                |  52%
  |                                                                       
  |==================================                               |  52%
  |                                                                       
  |==================================                               |  53%
  |                                                                       
  |===================================                              |  53%
  |                                                                       
  |===================================                              |  54%
  |                                                                       
  |===================================                              |  55%
  |                                                                       
  |====================================                             |  55%
  |                                                                       
  |====================================                             |  56%
  |                                                                       
  |=====================================                            |  56%
  |                                                                       
  |=====================================                            |  57%
  |                                                                       
  |=====================================                            |  58%
  |                                                                       
  |======================================                           |  58%
  |                                                                       
  |======================================                           |  59%
  |                                                                       
  |=======================================                          |  59%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |=======================================                          |  61%
  |                                                                       
  |========================================                         |  61%
  |                                                                       
  |========================================                         |  62%
  |                                                                       
  |=========================================                        |  62%
  |                                                                       
  |=========================================                        |  63%
  |                                                                       
  |=========================================                        |  64%
  |                                                                       
  |==========================================                       |  64%
  |                                                                       
  |==========================================                       |  65%
  |                                                                       
  |===========================================                      |  65%
  |                                                                       
  |===========================================                      |  66%
  |                                                                       
  |===========================================                      |  67%
  |                                                                       
  |============================================                     |  67%
  |                                                                       
  |============================================                     |  68%
  |                                                                       
  |=============================================                    |  68%
  |                                                                       
  |=============================================                    |  69%
  |                                                                       
  |=============================================                    |  70%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |==============================================                   |  71%
  |                                                                       
  |==============================================                   |  72%
  |                                                                       
  |===============================================                  |  72%
  |                                                                       
  |===============================================                  |  73%
  |                                                                       
  |================================================                 |  73%
  |                                                                       
  |================================================                 |  74%
  |                                                                       
  |================================================                 |  75%
  |                                                                       
  |=================================================                |  75%
  |                                                                       
  |=================================================                |  76%
  |                                                                       
  |==================================================               |  76%
  |                                                                       
  |==================================================               |  77%
  |                                                                       
  |==================================================               |  78%
  |                                                                       
  |===================================================              |  78%
  |                                                                       
  |===================================================              |  79%
  |                                                                       
  |====================================================             |  79%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |====================================================             |  81%
  |                                                                       
  |=====================================================            |  81%
  |                                                                       
  |=====================================================            |  82%
  |                                                                       
  |======================================================           |  82%
  |                                                                       
  |======================================================           |  83%
  |                                                                       
  |======================================================           |  84%
  |                                                                       
  |=======================================================          |  84%
  |                                                                       
  |=======================================================          |  85%
  |                                                                       
  |========================================================         |  85%
  |                                                                       
  |========================================================         |  86%
  |                                                                       
  |========================================================         |  87%
  |                                                                       
  |=========================================================        |  87%
  |                                                                       
  |=========================================================        |  88%
  |                                                                       
  |==========================================================       |  88%
  |                                                                       
  |==========================================================       |  89%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |===========================================================      |  90%
  |                                                                       
  |===========================================================      |  91%
  |                                                                       
  |===========================================================      |  92%
  |                                                                       
  |============================================================     |  92%
  |                                                                       
  |============================================================     |  93%
  |                                                                       
  |=============================================================    |  93%
  |                                                                       
  |=============================================================    |  94%
  |                                                                       
  |=============================================================    |  95%
  |                                                                       
  |==============================================================   |  95%
  |                                                                       
  |==============================================================   |  96%
  |                                                                       
  |===============================================================  |  96%
  |                                                                       
  |===============================================================  |  97%
  |                                                                       
  |===============================================================  |  98%
  |                                                                       
  |================================================================ |  98%
  |                                                                       
  |================================================================ |  99%
  |                                                                       
  |=================================================================|  99%
  |                                                                       
  |=================================================================| 100%
## Computing statistics...
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |                                                                 |   1%
  |                                                                       
  |=                                                                |   1%
  |                                                                       
  |=                                                                |   2%
  |                                                                       
  |==                                                               |   2%
  |                                                                       
  |==                                                               |   3%
  |                                                                       
  |==                                                               |   4%
  |                                                                       
  |===                                                              |   4%
  |                                                                       
  |===                                                              |   5%
  |                                                                       
  |====                                                             |   5%
  |                                                                       
  |====                                                             |   6%
  |                                                                       
  |====                                                             |   7%
  |                                                                       
  |=====                                                            |   7%
  |                                                                       
  |=====                                                            |   8%
  |                                                                       
  |======                                                           |   8%
  |                                                                       
  |======                                                           |   9%
  |                                                                       
  |======                                                           |  10%
  |                                                                       
  |=======                                                          |  10%
  |                                                                       
  |=======                                                          |  11%
  |                                                                       
  |=======                                                          |  12%
  |                                                                       
  |========                                                         |  12%
  |                                                                       
  |========                                                         |  13%
  |                                                                       
  |=========                                                        |  13%
  |                                                                       
  |=========                                                        |  14%
  |                                                                       
  |=========                                                        |  15%
  |                                                                       
  |==========                                                       |  15%
  |                                                                       
  |==========                                                       |  16%
  |                                                                       
  |===========                                                      |  16%
  |                                                                       
  |===========                                                      |  17%
  |                                                                       
  |===========                                                      |  18%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |============                                                     |  19%
  |                                                                       
  |=============                                                    |  19%
  |                                                                       
  |=============                                                    |  20%
  |                                                                       
  |=============                                                    |  21%
  |                                                                       
  |==============                                                   |  21%
  |                                                                       
  |==============                                                   |  22%
  |                                                                       
  |===============                                                  |  22%
  |                                                                       
  |===============                                                  |  23%
  |                                                                       
  |===============                                                  |  24%
  |                                                                       
  |================                                                 |  24%
  |                                                                       
  |================                                                 |  25%
  |                                                                       
  |=================                                                |  25%
  |                                                                       
  |=================                                                |  26%
  |                                                                       
  |=================                                                |  27%
  |                                                                       
  |==================                                               |  27%
  |                                                                       
  |==================                                               |  28%
  |                                                                       
  |===================                                              |  28%
  |                                                                       
  |===================                                              |  29%
  |                                                                       
  |===================                                              |  30%
  |                                                                       
  |====================                                             |  30%
  |                                                                       
  |====================                                             |  31%
  |                                                                       
  |====================                                             |  32%
  |                                                                       
  |=====================                                            |  32%
  |                                                                       
  |=====================                                            |  33%
  |                                                                       
  |======================                                           |  33%
  |                                                                       
  |======================                                           |  34%
  |                                                                       
  |======================                                           |  35%
  |                                                                       
  |=======================                                          |  35%
  |                                                                       
  |=======================                                          |  36%
  |                                                                       
  |========================                                         |  36%
  |                                                                       
  |========================                                         |  37%
  |                                                                       
  |========================                                         |  38%
  |                                                                       
  |=========================                                        |  38%
  |                                                                       
  |=========================                                        |  39%
  |                                                                       
  |==========================                                       |  39%
  |                                                                       
  |==========================                                       |  40%
  |                                                                       
  |==========================                                       |  41%
  |                                                                       
  |===========================                                      |  41%
  |                                                                       
  |===========================                                      |  42%
  |                                                                       
  |============================                                     |  42%
  |                                                                       
  |============================                                     |  43%
  |                                                                       
  |============================                                     |  44%
  |                                                                       
  |=============================                                    |  44%
  |                                                                       
  |=============================                                    |  45%
  |                                                                       
  |==============================                                   |  45%
  |                                                                       
  |==============================                                   |  46%
  |                                                                       
  |==============================                                   |  47%
  |                                                                       
  |===============================                                  |  47%
  |                                                                       
  |===============================                                  |  48%
  |                                                                       
  |================================                                 |  48%
  |                                                                       
  |================================                                 |  49%
  |                                                                       
  |================================                                 |  50%
  |                                                                       
  |=================================                                |  50%
  |                                                                       
  |=================================                                |  51%
  |                                                                       
  |=================================                                |  52%
  |                                                                       
  |==================================                               |  52%
  |                                                                       
  |==================================                               |  53%
  |                                                                       
  |===================================                              |  53%
  |                                                                       
  |===================================                              |  54%
  |                                                                       
  |===================================                              |  55%
  |                                                                       
  |====================================                             |  55%
  |                                                                       
  |====================================                             |  56%
  |                                                                       
  |=====================================                            |  56%
  |                                                                       
  |=====================================                            |  57%
  |                                                                       
  |=====================================                            |  58%
  |                                                                       
  |======================================                           |  58%
  |                                                                       
  |======================================                           |  59%
  |                                                                       
  |=======================================                          |  59%
  |                                                                       
  |=======================================                          |  60%
  |                                                                       
  |=======================================                          |  61%
  |                                                                       
  |========================================                         |  61%
  |                                                                       
  |========================================                         |  62%
  |                                                                       
  |=========================================                        |  62%
  |                                                                       
  |=========================================                        |  63%
  |                                                                       
  |=========================================                        |  64%
  |                                                                       
  |==========================================                       |  64%
  |                                                                       
  |==========================================                       |  65%
  |                                                                       
  |===========================================                      |  65%
  |                                                                       
  |===========================================                      |  66%
  |                                                                       
  |===========================================                      |  67%
  |                                                                       
  |============================================                     |  67%
  |                                                                       
  |============================================                     |  68%
  |                                                                       
  |=============================================                    |  68%
  |                                                                       
  |=============================================                    |  69%
  |                                                                       
  |=============================================                    |  70%
  |                                                                       
  |==============================================                   |  70%
  |                                                                       
  |==============================================                   |  71%
  |                                                                       
  |==============================================                   |  72%
  |                                                                       
  |===============================================                  |  72%
  |                                                                       
  |===============================================                  |  73%
  |                                                                       
  |================================================                 |  73%
  |                                                                       
  |================================================                 |  74%
  |                                                                       
  |================================================                 |  75%
  |                                                                       
  |=================================================                |  75%
  |                                                                       
  |=================================================                |  76%
  |                                                                       
  |==================================================               |  76%
  |                                                                       
  |==================================================               |  77%
  |                                                                       
  |==================================================               |  78%
  |                                                                       
  |===================================================              |  78%
  |                                                                       
  |===================================================              |  79%
  |                                                                       
  |====================================================             |  79%
  |                                                                       
  |====================================================             |  80%
  |                                                                       
  |====================================================             |  81%
  |                                                                       
  |=====================================================            |  81%
  |                                                                       
  |=====================================================            |  82%
  |                                                                       
  |======================================================           |  82%
  |                                                                       
  |======================================================           |  83%
  |                                                                       
  |======================================================           |  84%
  |                                                                       
  |=======================================================          |  84%
  |                                                                       
  |=======================================================          |  85%
  |                                                                       
  |========================================================         |  85%
  |                                                                       
  |========================================================         |  86%
  |                                                                       
  |========================================================         |  87%
  |                                                                       
  |=========================================================        |  87%
  |                                                                       
  |=========================================================        |  88%
  |                                                                       
  |==========================================================       |  88%
  |                                                                       
  |==========================================================       |  89%
  |                                                                       
  |==========================================================       |  90%
  |                                                                       
  |===========================================================      |  90%
  |                                                                       
  |===========================================================      |  91%
  |                                                                       
  |===========================================================      |  92%
  |                                                                       
  |============================================================     |  92%
  |                                                                       
  |============================================================     |  93%
  |                                                                       
  |=============================================================    |  93%
  |                                                                       
  |=============================================================    |  94%
  |                                                                       
  |=============================================================    |  95%
  |                                                                       
  |==============================================================   |  95%
  |                                                                       
  |==============================================================   |  96%
  |                                                                       
  |===============================================================  |  96%
  |                                                                       
  |===============================================================  |  97%
  |                                                                       
  |===============================================================  |  98%
  |                                                                       
  |================================================================ |  98%
  |                                                                       
  |================================================================ |  99%
  |                                                                       
  |=================================================================|  99%
  |                                                                       
  |=================================================================| 100%

plot(BCTboot1, labels = TRUE, order = &quot;sample&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/bct-robustness-3.png" width="2100" /></p>
<pre class="r"><code>plot(BCTboot2, labels = TRUE, order = &quot;sample&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/bct-robustness-4.png" width="2100" /></p>
<pre class="r"><code>
autEdges &lt;- summary(BCTboot1, statistics = &quot;edge&quot;, rank = TRUE) %&gt;% 
  dplyr::arrange(mean) %&gt;% 
  dplyr::filter(stringr::str_detect(node1, &#39;Autonomous&#39;)) %&gt;% # str_detect(id, &#39;Autonomous|Controlled&#39;) for both
  dplyr::filter(!(node2 == &#39;Controlled&#39;)) %&gt;% 
  data.frame() %&gt;% 
  select(CIlower, mean, CIupper, node2)

contEdges &lt;- summary(BCTboot1, statistics = &quot;edge&quot;, rank = TRUE) %&gt;% 
  dplyr::arrange(mean) %&gt;% 
  dplyr::filter(stringr::str_detect(node1, &#39;Controlled&#39;)) %&gt;% # str_detect(id, &#39;Autonomous|Controlled&#39;) for both
  data.frame() %&gt;% 
  select(CIlower, mean, CIupper, node2)

diamondPlot(autEdges, 
            ciCols = c(&quot;CIlower&quot;, &quot;mean&quot;, &quot;CIupper&quot;), 
            color = viridis(2, end = 0.8)[1], 
            alpha = 0.3, 
            yLabels = autEdges$node2, 
            fixedSize = 0.3, 
            xlab = NULL) +
  userfriendlyscience::diamondPlot(contEdges, 
              ciCols = c(&quot;CIlower&quot;, &quot;mean&quot;, &quot;CIupper&quot;), 
              color = viridis(2, end = 0.8)[2], 
              alpha = 0.3, 
              yLabels = autEdges$node2, 
              fixedSize = 0.3, 
              xlab = NULL, 
              returnLayerOnly = TRUE) +
  geom_rect(aes(xmin=Inf, xmax=Inf, ymin=Inf, ymax=Inf, fill = &quot;Controlled&quot;), 
            colour=NA, alpha=0.05) + # Create invisible rectangle for legend
  geom_rect(aes(xmin=Inf, xmax=Inf, ymin=Inf, ymax=Inf, fill = &quot;Autonomous&quot;), 
            colour=NA, alpha=0.05) + # Create invisible rectangle for legend
  scale_fill_manual(&#39;Connected node&#39;,
                      values = viridis(2, end = 0.8)[1:2],  
                      guide = guide_legend(override.aes = list(alpha = 1))) +
  ggtitle(&quot;Relative strengths of edges containing autonomous \nor controlled motivation (all items)&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/bct-robustness-5.png" width="2100" /></p>
<pre class="r"><code>  
# Combined items

autEdges &lt;- summary(BCTboot2, statistics = &quot;edge&quot;, rank = TRUE) %&gt;% 
  dplyr::arrange(mean) %&gt;% 
  dplyr::filter(stringr::str_detect(node1, &#39;Autonomous&#39;)) %&gt;% # str_detect(id, &#39;Autonomous|Controlled&#39;) for both
  dplyr::filter(!(node2 == &#39;Controlled&#39;)) %&gt;% 
  data.frame() %&gt;% 
  select(CIlower, mean, CIupper, node2)

contEdges &lt;- summary(BCTboot2, statistics = &quot;edge&quot;, rank = TRUE) %&gt;% 
  dplyr::arrange(mean) %&gt;% 
  dplyr::filter(stringr::str_detect(node1, &#39;Controlled&#39;)) %&gt;% # str_detect(id, &#39;Autonomous|Controlled&#39;) for both
  data.frame() %&gt;% 
  select(CIlower, mean, CIupper, node2)

diamondPlot(autEdges, 
            ciCols = c(&quot;CIlower&quot;, &quot;mean&quot;, &quot;CIupper&quot;), 
            color = viridis(2, end = 0.8)[1], 
            alpha = 0.3, 
            yLabels = autEdges$node2, 
            fixedSize = 0.3, 
            xlab = NULL) +
  userfriendlyscience::diamondPlot(contEdges, 
              ciCols = c(&quot;CIlower&quot;, &quot;mean&quot;, &quot;CIupper&quot;), 
              color = viridis(2, end = 0.8)[2], 
              alpha = 0.3, 
              yLabels = autEdges$node2, 
              fixedSize = 0.3, 
              xlab = NULL, 
              returnLayerOnly = TRUE) +
  geom_rect(aes(xmin=Inf, xmax=Inf, ymin=Inf, ymax=Inf, fill = &quot;Controlled&quot;), 
            colour=NA, alpha=0.05) + # Create invisible rectangle for legend
  geom_rect(aes(xmin=Inf, xmax=Inf, ymin=Inf, ymax=Inf, fill = &quot;Autonomous&quot;), 
            colour=NA, alpha=0.05) + # Create invisible rectangle for legend
  scale_fill_manual(&#39;Connected node&#39;,
                      values = viridis(2, end = 0.8)[1:2],  
                      guide = guide_legend(override.aes = list(alpha = 1))) +
  ggtitle(&quot;Relative strengths of edges containing autonomous \nor controlled motivation (combined items)&quot;)</code></pre>
<p><img src="baseline-supplement_files/figure-html/bct-robustness-6.png" width="2100" /></p>
<pre class="r"><code>
# summary(BCTboot1, statistics = &quot;edge&quot;, rank = TRUE) %&gt;% 
#   dplyr::arrange(mean) %&gt;% 
#   dplyr::filter(stringr::str_detect(id, &#39;Controlled&#39;)) %&gt;%
#   data.frame() %&gt;% 
#   select(CIlower, mean, CIupper, id) %&gt;% 
#   userfriendlyscience::diamondPlot(ciCols = c(&quot;CIlower&quot;, &quot;mean&quot;, &quot;CIupper&quot;), ylabels = id)</code></pre>
</div>
<div id="bct-sdt-regression-analyses" class="section level4">
<h4>BCT-SDT Regression analyses</h4>
<p>Here’s the classical linear model.</p>
<pre class="r"><code>library(broom)

bctdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &#39;Autonomous&#39; = PA_autonomous_T1,
  &#39;Controlled&#39; = PA_controlled_T1,
  &#39;Intrinsic&#39; = PA_intrinsic_T1,
  &#39;Identified&#39; = PA_identified_T1,
  &#39;Integrated&#39; = PA_integrated_T1,
  &#39;Introjected&#39; = PA_introjected_T1,
  &#39;Extrinsic&#39; = PA_extrinsic_T1,
  &#39;goal setting&#39; = PA_agrbct_01_T1,
  &#39;implementation plan&#39; = PA_agrbct_02_T1,
  &#39;plan by other&#39; = PA_agrbct_03_T1,
  &#39;reminder of plan&#39; = PA_agrbct_04_T1,
  &#39;subgoals&#39; = PA_agrbct_05_T1,
  &#39;new PA options&#39; = PA_agrbct_06_T1,
  &#39;barrier identification&#39; = PA_agrbct_07_T1,
  &#39;coping planning&#39; = PA_agrbct_08_T1,
  &#39;PA identity&#39; = PA_agrbct_09_T1,
  &#39;PA life values&#39; = PA_agrbct_10_T1,
  &#39;positive consequences&#39; = PA_frqbct_01_T1,
  &#39;log on paper&#39; = PA_frqbct_02_T1,
  &#39;smartphone&#39; = PA_frqbct_03_T1,
#  &#39;mnemonic cues&#39; = PA_frqbct_04_T1,
  &#39;goal contrast&#39; = PA_frqbct_05_T1,
  &#39;relevance of PA&#39; = PA_frqbct_06_T1,
  &#39;changes at home&#39; = PA_frqbct_07_T1,
  &#39;social support&#39; = PA_frqbct_08_T1,
  &#39;failure contemplated&#39; = PA_frqbct_09_T1) %&gt;%
  rowwise() %&gt;% 
  mutate( 
  #&#39;has plan&#39; = mean(c(`implementation plan`, `plan by other`), na.rm = TRUE),
  &#39;monitored PA&#39; = mean(c(`log on paper`, `smartphone`), na.rm = TRUE)) %&gt;%
  select(-`log on paper`, -`smartphone`) %&gt;% 
  data.frame # %&gt;% 
  # mutate_all(as.numeric)

outcomevars &lt;- c(&#39;Autonomous&#39;, 
  &#39;Controlled&#39;, 
  &#39;Intrinsic&#39;,
  &#39;Identified&#39;, 
  &#39;Integrated&#39;, 
  &#39;Introjected&#39;,
  &#39;Extrinsic&#39;)

for (i in outcomevars) {
m &lt;- lm(paste0(i, &quot; ~ 
  goal.setting +
  implementation.plan +
  plan.by.other +
  reminder.of.plan +
  subgoals +
  new.PA.options +
  barrier.identification +
  coping.planning +
  PA.identity +
  PA.life.values +
  positive.consequences&quot;), 
  data = bctdf)

cat(&quot;\n\nEstimates for&quot;, i, &quot;regulation&quot;, sep = &quot; &quot;)
summary(m) %&gt;% broom::tidy() %&gt;% dplyr::arrange(desc(estimate)) %&gt;% apa_table() 
}
## 
## 
## Estimates for Autonomous regulation&lt;caption&gt;(\#tab:unnamed-chunk-32)&lt;/caption&gt;
## 
## &lt;caption&gt;**&lt;/caption&gt;
## 
## 
## 
## term                     estimate   std.error   statistic   p.value 
## -----------------------  ---------  ----------  ----------  --------
## (Intercept)              1.59       0.07        22.97       0.00    
## positive.consequences    0.12       0.02        6.52        0.00    
## PA.life.values           0.11       0.02        5.05        0.00    
## goal.setting             0.10       0.02        5.23        0.00    
## plan.by.other            0.09       0.02        5.45        0.00    
## new.PA.options           0.08       0.02        4.57        0.00    
## implementation.plan      0.05       0.02        2.48        0.01    
## PA.identity              0.02       0.02        1.03        0.30    
## subgoals                 0.01       0.02        0.27        0.78    
## coping.planning          -0.01      0.02        -0.24       0.81    
## barrier.identification   -0.01      0.02        -0.65       0.51    
## reminder.of.plan         -0.03      0.02        -1.41       0.16    
## 
## 
## Estimates for Controlled regulation&lt;caption&gt;(\#tab:unnamed-chunk-32)&lt;/caption&gt;
## 
## &lt;caption&gt;**&lt;/caption&gt;
## 
## 
## 
## term                     estimate   std.error   statistic   p.value 
## -----------------------  ---------  ----------  ----------  --------
## (Intercept)              1.36       0.07        19.32       0.00    
## PA.identity              0.07       0.02        3.08        0.00    
## barrier.identification   0.06       0.02        2.75        0.01    
## positive.consequences    0.05       0.02        2.69        0.01    
## reminder.of.plan         0.03       0.02        1.54        0.12    
## implementation.plan      0.03       0.02        1.15        0.25    
## subgoals                 0.01       0.02        0.26        0.80    
## coping.planning          0.00       0.02        0.20        0.84    
## plan.by.other            0.00       0.02        0.12        0.91    
## goal.setting             -0.01      0.02        -0.43       0.67    
## new.PA.options           -0.02      0.02        -1.00       0.32    
## PA.life.values           -0.07      0.02        -3.14       0.00    
## 
## 
## Estimates for Intrinsic regulation&lt;caption&gt;(\#tab:unnamed-chunk-32)&lt;/caption&gt;
## 
## &lt;caption&gt;**&lt;/caption&gt;
## 
## 
## 
## term                     estimate   std.error   statistic   p.value 
## -----------------------  ---------  ----------  ----------  --------
## (Intercept)              1.81       0.08        22.81       0.00    
## positive.consequences    0.12       0.02        5.83        0.00    
## goal.setting             0.12       0.02        5.15        0.00    
## PA.life.values           0.12       0.02        4.63        0.00    
## new.PA.options           0.09       0.02        4.49        0.00    
## plan.by.other            0.08       0.02        4.62        0.00    
## implementation.plan      0.06       0.02        2.43        0.02    
## PA.identity              0.02       0.02        0.62        0.53    
## subgoals                 -0.01      0.02        -0.32       0.75    
## barrier.identification   -0.01      0.03        -0.56       0.57    
## coping.planning          -0.02      0.03        -0.71       0.48    
## reminder.of.plan         -0.05      0.02        -2.17       0.03    
## 
## 
## Estimates for Identified regulation&lt;caption&gt;(\#tab:unnamed-chunk-32)&lt;/caption&gt;
## 
## &lt;caption&gt;**&lt;/caption&gt;
## 
## 
## 
## term                     estimate   std.error   statistic   p.value 
## -----------------------  ---------  ----------  ----------  --------
## (Intercept)              1.68       0.08        21.48       0.00    
## positive.consequences    0.13       0.02        6.52        0.00    
## PA.life.values           0.12       0.02        4.87        0.00    
## goal.setting             0.10       0.02        4.30        0.00    
## new.PA.options           0.07       0.02        3.75        0.00    
## plan.by.other            0.05       0.02        2.68        0.01    
## implementation.plan      0.04       0.02        1.84        0.07    
## coping.planning          0.02       0.03        0.61        0.54    
## PA.identity              0.01       0.02        0.58        0.56    
## subgoals                 0.01       0.02        0.34        0.74    
## reminder.of.plan         -0.02      0.02        -0.79       0.43    
## barrier.identification   -0.04      0.02        -1.65       0.10    
## 
## 
## Estimates for Integrated regulation&lt;caption&gt;(\#tab:unnamed-chunk-32)&lt;/caption&gt;
## 
## &lt;caption&gt;**&lt;/caption&gt;
## 
## 
## 
## term                     estimate   std.error   statistic   p.value 
## -----------------------  ---------  ----------  ----------  --------
## (Intercept)              1.30       0.08        16.13       0.00    
## plan.by.other            0.13       0.02        6.97        0.00    
## positive.consequences    0.10       0.02        4.60        0.00    
## goal.setting             0.10       0.02        4.22        0.00    
## PA.life.values           0.08       0.03        3.28        0.00    
## new.PA.options           0.07       0.02        3.62        0.00    
## implementation.plan      0.06       0.03        2.34        0.02    
## PA.identity              0.04       0.02        1.60        0.11    
## subgoals                 0.01       0.03        0.59        0.56    
## barrier.identification   0.01       0.03        0.31        0.76    
## reminder.of.plan         -0.01      0.02        -0.49       0.62    
## coping.planning          -0.01      0.03        -0.43       0.67    
## 
## 
## Estimates for Introjected regulation&lt;caption&gt;(\#tab:unnamed-chunk-32)&lt;/caption&gt;
## 
## &lt;caption&gt;**&lt;/caption&gt;
## 
## 
## 
## term                     estimate   std.error   statistic   p.value 
## -----------------------  ---------  ----------  ----------  --------
## (Intercept)              1.12       0.10        10.73       0.00    
## PA.identity              0.12       0.03        3.66        0.00    
## positive.consequences    0.10       0.03        3.56        0.00    
## barrier.identification   0.07       0.03        2.19        0.03    
## goal.setting             0.06       0.03        1.87        0.06    
## reminder.of.plan         0.04       0.03        1.23        0.22    
## implementation.plan      0.02       0.03        0.62        0.54    
## coping.planning          0.01       0.04        0.36        0.72    
## new.PA.options           -0.01      0.03        -0.42       0.68    
## subgoals                 -0.02      0.03        -0.47       0.64    
## plan.by.other            -0.03      0.02        -1.29       0.20    
## PA.life.values           -0.04      0.03        -1.32       0.19    
## 
## 
## Estimates for Extrinsic regulation&lt;caption&gt;(\#tab:unnamed-chunk-32)&lt;/caption&gt;
## 
## &lt;caption&gt;**&lt;/caption&gt;
## 
## 
## 
## term                     estimate   std.error   statistic   p.value 
## -----------------------  ---------  ----------  ----------  --------
## (Intercept)              1.53       0.07        20.85       0.00    
## barrier.identification   0.05       0.02        2.29        0.02    
## implementation.plan      0.03       0.02        1.35        0.18    
## PA.identity              0.03       0.02        1.30        0.19    
## reminder.of.plan         0.03       0.02        1.33        0.19    
## plan.by.other            0.02       0.02        1.42        0.16    
## positive.consequences    0.02       0.02        0.96        0.34    
## subgoals                 0.02       0.02        0.77        0.44    
## coping.planning          0.00       0.03        0.06        0.95    
## new.PA.options           -0.02      0.02        -1.20       0.23    
## goal.setting             -0.05      0.02        -2.44       0.01    
## PA.life.values           -0.09      0.02        -3.88       0.00</code></pre>
</div>
</div>
</div>
<div id="centrality-stability" class="section level2">
<h2>Centrality stability</h2>
<pre class="r"><code>boot2 &lt;- bootnet::bootnet(Network1, nBoots = 2500, type = &quot;case&quot;)
## Error in is(data, &quot;bootnetResult&quot;): object &#39;Network1&#39; not found
bootnet::corStability(boot2)
## === Correlation Stability Analysis === 
## 
## Sampling levels tested:
##    nPerson Drop%   n
## 1      291  75.0 236
## 2      382  67.2 261
## 3      472  59.5 252
## 4      563  51.7 235
## 5      654  43.9 231
## 6      744  36.1 253
## 7      835  28.3 250
## 8      926  20.5 240
## 9     1016  12.8 279
## 10    1107   5.0 263
## 
## Maximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:
## 
## betweenness: 0.361
##   - For more accuracy, run bootnet(..., caseMin = 0.283, caseMax = 0.439) 
## 
## closeness: 0.672
##   - For more accuracy, run bootnet(..., caseMin = 0.595, caseMax = 0.75) 
## 
## strength: 0.75
##   - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) 
## 
## Accuracy can also be increased by increasing both &#39;nBoots&#39; and &#39;caseN&#39;.

plot(boot2)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-33-1.png" width="2100" /></p>
<pre class="r"><code>
differenceTest(boot1, &quot;auton&quot;, &quot;intent&quot;,  measure = c(&quot;strength&quot;, &quot;closeness&quot;, &quot;betweenness&quot;))
## Error in bootobject$type %in% c(&quot;nonparametric&quot;, &quot;parametric&quot;): object &#39;boot1&#39; not found

plot(boot1, &quot;edge&quot;, plot = &quot;difference&quot;, onlyNonZero = TRUE, order = &quot;sample&quot;)
## Error in plot(boot1, &quot;edge&quot;, plot = &quot;difference&quot;, onlyNonZero = TRUE, : object &#39;boot1&#39; not found

plot(boot1, &quot;strength&quot;)
## Error in plot(boot1, &quot;strength&quot;): object &#39;boot1&#39; not found
plot(boot1, &quot;betweenness&quot;)
## Error in plot(boot1, &quot;betweenness&quot;): object &#39;boot1&#39; not found
plot(boot1, &quot;closeness&quot;)
## Error in plot(boot1, &quot;closeness&quot;): object &#39;boot1&#39; not found</code></pre>
</div>
<div id="pa-determinants-unregularised-correlations-visualised" class="section level2">
<h2>PA determinants: unregularised correlations visualised</h2>
<pre class="r"><code># Network without motivation variables
data &lt;- df %&gt;% select(&#39;PA&#39; = paAccelerometer_T1, &#39;SB&#39; = sitLieAccelerometer_T1,
&#39;fat%&#39; = fatpct_T1,&#39;action planning&#39; = PA_actionplan_T1, &#39;coping planning&#39; = PA_copingplan_T1, &#39;frequency-related BCTs&#39; = PA_frqbct_T1, &#39;agreement-related BCTs&#39; = PA_agrbct_T1, &#39;amotivation&#39; = PA_amotivation_T1, &#39;autonomous motivation&#39; = PA_autonomous_T1, &#39;controlled motivation&#39; = PA_controlled_T1, &#39;descriptive norm&#39; = PA_dnorm_T1, &#39;injunctive norm&#39; = PA_inorm_T1, &#39;intention&#39; = PA_intention_T1, &#39;outcome expectations&#39; = PA_oexp_T1, &#39;self-efficacy / PBC&#39; = PA_sePbc_T1, &#39;perceived opportunities&#39; = PA_opportunities_T1) %&gt;% 
  data.frame
## Error in overscope_eval_next(overscope, expr): object &#39;PA_oexp_T1&#39; not found

names &lt;- df %&gt;% select(&#39;PA&#39; = paAccelerometer_T1, &#39;SB&#39; = sitLieAccelerometer_T1,
&#39;fat%&#39; = fatpct_T1,&#39;action planning&#39; = PA_actionplan_T1, &#39;coping planning&#39; = PA_copingplan_T1, &#39;frequency-related BCTs&#39; = PA_frqbct_T1, &#39;agreement-related BCTs&#39; = PA_agrbct_T1, &#39;amotivation&#39; = PA_amotivation_T1, &#39;autonomous motivation&#39; = PA_autonomous_T1, &#39;controlled motivation&#39; = PA_controlled_T1, &#39;descriptive norm&#39; = PA_dnorm_T1, &#39;injunctive norm&#39; = PA_inorm_T1, &#39;intention&#39; = PA_intention_T1, &#39;outcome expectations&#39; = PA_oexp_T1, &#39;self-efficacy / PBC&#39; = PA_sePbc_T1, &#39;perceived opportunities&#39; = PA_opportunities_T1) %&gt;% names
## Error in overscope_eval_next(overscope, expr): object &#39;PA_oexp_T1&#39; not found

# Spinglass algorithm detects communities. Tutorial here: http://psych-networks.com/r-tutorial-identify-communities-items-networks/

cormatrix &lt;- cor_auto(data) 
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;symbol&#39;
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;language&#39;
## Error in data[, sapply(data, function(x) mean(is.na(x))) != 1]: object of type &#39;closure&#39; is not subsettable

graph1 &lt;- qgraph(cormatrix, layout=&quot;spring&quot;, sampleSize = nrow(data),
              vsize=7, cut=0, maximum=.45, border.width=1.5)
## Error in qgraph(cormatrix, layout = &quot;spring&quot;, sampleSize = nrow(data), : object &#39;cormatrix&#39; not found

g &lt;- as.igraph(graph1, attributes = TRUE)

matrix_spinglass &lt;- matrix(NA, nrow=1,ncol=100)
 
for (i in 1:100) {
set.seed(i)
spinglass &lt;- spinglass.community(g)
matrix_spinglass[1,i] &lt;- max(spinglass$membership) 
}

set.seed(1)

sgc &lt;- spinglass.community(g)

communities &lt;- data.frame(sgc$membership, &#39;node number&#39; = 1:ncol(data))
## Error in 1:ncol(data): argument of length 0

group.spinglass &lt;- list(communities$node.number[communities$sgc.membership == 1], 
                       communities$node.number[communities$sgc.membership == 2])
## Error in communities$node.number: object of type &#39;closure&#39; is not subsettable

piefill &lt;- data %&gt;%
  summarise_all(funs(mean(., na.rm = TRUE))) %&gt;% 
  mutate_at(vars(PA, SB),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  mutate_at(vars(action.planning, coping.planning),
            funs(. / 4)) %&gt;% 
  mutate_at(vars(6:ncol(data)),
            funs(. / 7)) %&gt;% 
  mutate_at(vars(fat.),
            funs(. / 100))  
## Error in UseMethod(&quot;tbl_vars&quot;): no applicable method for &#39;tbl_vars&#39; applied to an object of class &quot;function&quot;

qgraph(graph1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, 
     color=c(&quot;olivedrab2&quot;, &quot;orange&quot;, &quot;lightblue&quot;),
     label.cex = 0.75,
     label.scale = TRUE,
     pie = piefill, 
     color = &quot;skyblue&quot;,
     nodeNames = names,
     pieBorder = 1,
     legend.cex = 0.4)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-34-1.png" width="2100" /></p>
<pre class="r"><code>

# plot(nwAll, groups = itemGroups, nodeNames = itemNames, legend.cex = 0.25)



lmi %&gt;% select(Kys0016.1, Kys0013.1) %&gt;% group_by(Kys0016.1) %&gt;% summarise(n = n())
## # A tibble: 6 x 2
##   Kys0016.1     n
##   &lt;dbl+lbl&gt; &lt;int&gt;
## 1      0       34
## 2      1.00   163
## 3      2.00   274
## 4      3.00   211
## 5      4.00   402
## 6     NA       81

lmi %&gt;% count(Kys0016.1, Kys0013.1) %&gt;% group_by(Kys0016.1)
## # A tibble: 11 x 3
## # Groups: Kys0016.1 [6]
##    Kys0016.1 Kys0013.1     n
##    &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;int&gt;
##  1      0         1.00    16
##  2      0         2.00    18
##  3      1.00      1.00   137
##  4      1.00      2.00    26
##  5      2.00      1.00   164
##  6      2.00      2.00   110
##  7      3.00      1.00    83
##  8      3.00      2.00   128
##  9      4.00      1.00    71
## 10      4.00      2.00   331
## 11     NA        NA       81</code></pre>
<!-- Out of a hundred iterations, spinglass algorithm found `  table(matrix_spinglass)[[1]]` instances of ` table(matrix_spinglass)[1] %>% names` communities, `  table(matrix_spinglass)[[2]]` instances of `  table(matrix_spinglass)[2] %>% names` communities, and `  table(matrix_spinglass)[[3]]` instances of `  table(matrix_spinglass)[3] %>% names` communities. Thus, a random seed which found four communities was chosen.   -->
</div>
<div id="symptom-network-all" class="section level2">
<h2>Symptom network: all</h2>
<pre class="r"><code>
sympdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1,
  &quot;Fat pct&quot; = fatpct_T1,
  &quot;PA&quot; = paAccelerometer_T1,
  &quot;SB&quot; = sitLieAccelerometer_T1
) %&gt;% 
  mutate(
    &#39;Neck and shoulder pain&#39; = ifelse(`Neck and shoulder pain` == 1, 0, 1),
    &#39;Lower back pain&#39; = ifelse(`Lower back pain` == 1, 0, 1),
    &#39;Stomach ache&#39; = ifelse(`Stomach ache` == 1, 0, 1),
    &#39;Tension or nervousness&#39; = ifelse(`Tension or nervousness` == 1, 0, 1),
    &#39;Irritability or anger bursts&#39; = ifelse(`Irritability or anger bursts` == 1, 0, 1),
    &#39;Difficulty with sleep&#39; = ifelse(`Difficulty with sleep` == 1, 0, 1),
    &#39;Headache&#39; = ifelse(`Headache` == 1, 0, 1),
    &#39;Tiredness or faintness&#39; = ifelse(`Tiredness or faintness` == 1, 0, 1),
    &#39;Fat pct&#39; = `Fat pct` / 100) %&gt;% 
  data.frame

S.all &lt;- sympdf %&gt;% select(6:ncol(sympdf)) %&gt;% na.omit(.) 

nwAll &lt;- bootnet::estimateNetwork(S.all, default=&quot;mgm&quot;)
## Estimating Network. Using package::function:
##   - mgm::mgm for network computation
##     - Using glmnet::glmnet
## &#39;type&#39; argument not assigned. Setting type to &#39;c&#39; for all binary variables and &#39;g&#39; for all other variables.
## &#39;lev&#39; argument not assigned. Setting lev to 1 for all Gaussian/Poisson variables and number of unique values for all categorical variables
## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.

## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.

## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.
## Warning in (function (data, type, lev, tuning = 0.5, missing =
## c(&quot;listwise&quot;, : Bootnet does not support unsigned edges and treats these as
## positive edges.

allmeans &lt;- sympdf %&gt;%  
  summarise_at(vars(6:16),
  funs(mean(., na.rm = TRUE))) %&gt;%  
  mutate_at(vars(PA, SB),
            funs(. / (24*60)))  # proportion of day used doing the behaviour


plot(nwAll, label.scale = FALSE, title = &quot;All&quot;, label.cex = 0.75, 
     pie = allmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-35-1.png" width="2100" /></p>
</div>
<div id="symptom-network-boys-and-girls" class="section level2">
<h2>Symptom network: boys and girls</h2>
<pre class="r"><code>
sympdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1,
  &quot;Fat pct&quot; = fatpct_T1,
  &quot;PA&quot; = paAccelerometer_T1,
  &quot;SB&quot; = sitLieAccelerometer_T1
) %&gt;% 
  mutate(
    &#39;Neck and shoulder pain&#39; = ifelse(`Neck and shoulder pain` == 1, 0, 1),
    &#39;Lower back pain&#39; = ifelse(`Lower back pain` == 1, 0, 1),
    &#39;Stomach ache&#39; = ifelse(`Stomach ache` == 1, 0, 1),
    &#39;Tension or nervousness&#39; = ifelse(`Tension or nervousness` == 1, 0, 1),
    &#39;Irritability or anger bursts&#39; = ifelse(`Irritability or anger bursts` == 1, 0, 1),
    &#39;Difficulty with sleep&#39; = ifelse(`Difficulty with sleep` == 1, 0, 1),
    &#39;Headache&#39; = ifelse(`Headache` == 1, 0, 1),
    &#39;Tiredness or faintness&#39; = ifelse(`Tiredness or faintness` == 1, 0, 1),
    &#39;Fat pct&#39; = `Fat pct` / 100) %&gt;% 
  data.frame

S.boys &lt;- sympdf %&gt;% filter(girl == 0) %&gt;% select(6:ncol(sympdf)) %&gt;% na.omit(.) 
S.girls &lt;- sympdf %&gt;% filter(girl == 1) %&gt;% select(6:ncol(sympdf)) %&gt;% na.omit(.)
nwBoys &lt;- bootnet::estimateNetwork(S.boys, default=&quot;mgm&quot;)
## Estimating Network. Using package::function:
##   - mgm::mgm for network computation
##     - Using glmnet::glmnet
## &#39;type&#39; argument not assigned. Setting type to &#39;c&#39; for all binary variables and &#39;g&#39; for all other variables.
## &#39;lev&#39; argument not assigned. Setting lev to 1 for all Gaussian/Poisson variables and number of unique values for all categorical variables
## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.

## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.

## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.
## Warning in (function (data, type, lev, tuning = 0.5, missing =
## c(&quot;listwise&quot;, : Bootnet does not support unsigned edges and treats these as
## positive edges.
nwGirls &lt;- bootnet::estimateNetwork(S.girls, default=&quot;mgm&quot;)
## Estimating Network. Using package::function:
##   - mgm::mgm for network computation
##     - Using glmnet::glmnet
## &#39;type&#39; argument not assigned. Setting type to &#39;c&#39; for all binary variables and &#39;g&#39; for all other variables.
## &#39;lev&#39; argument not assigned. Setting lev to 1 for all Gaussian/Poisson variables and number of unique values for all categorical variables
## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.
## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.

## Warning in rep(1, n) * beta_vector: Recycling array of length 1 in vector-array arithmetic is deprecated.
##   Use c() or as.vector() instead.
## Warning in (function (data, type, lev, tuning = 0.5, missing =
## c(&quot;listwise&quot;, : Bootnet does not support unsigned edges and treats these as
## positive edges.

girlmeans &lt;- sympdf %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:15),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 1) %&gt;% 
  mutate_at(vars(PA, SB),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  select(-1)

boymeans &lt;- sympdf %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:15),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 0) %&gt;% 
  mutate_at(vars(PA, SB),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  select(-1)


layout(t(1:2))
plot(nwGirls, label.scale = FALSE, title = &quot;Girls&quot;, label.cex = 0.75,
     pie = girlmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)

plot(nwBoys, label.scale = FALSE, title = &quot;Boys&quot;, label.cex = 0.75, 
     pie = boymeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-36-1.png" width="2100" /></p>
</div>
<div id="symptom-network-educational-tracks" class="section level2">
<h2>symptom network: educational tracks</h2>
<pre class="r"><code>library(bootnet)
library(qgraph)
library(tidyverse)

sympdf &lt;- df %&gt;% dplyr::select(id,
  intervention,
  track,
  school,
  girl,
  &quot;Neck and shoulder pain&quot; = symptom_neckShoulderPain_T1,
  &quot;Lower back pain&quot; = symptom_lowerBackPain_T1,
  &quot;Stomach ache&quot; = symptom_stomachAche_T1,
  &quot;Tension or nervousness&quot; = symptom_tensionNervousness_T1,
  &quot;Irritability or anger bursts&quot; = symptom_irritabilityAngerbursts_T1,
  &quot;Difficulty with sleep&quot; = symptom_sleepDifficulty_T1,
  &quot;Headache&quot; = symptom_headAche_T1,
  &quot;Tiredness or faintness&quot; = symptom_tirednessFaintness_T1,
  &quot;Fat pct&quot; = fatpct_T1,
  &quot;PA&quot; = paAccelerometer_T1,
  &quot;SB&quot; = sitLieAccelerometer_T1
) %&gt;% 
  mutate(
    &#39;Neck and shoulder pain&#39; = ifelse(`Neck and shoulder pain` == 1, 0, 1),
    &#39;Lower back pain&#39; = ifelse(`Lower back pain` == 1, 0, 1),
    &#39;Stomach ache&#39; = ifelse(`Stomach ache` == 1, 0, 1),
    &#39;Tension or nervousness&#39; = ifelse(`Tension or nervousness` == 1, 0, 1),
    &#39;Irritability or anger bursts&#39; = ifelse(`Irritability or anger bursts` == 1, 0, 1),
    &#39;Difficulty with sleep&#39; = ifelse(`Difficulty with sleep` == 1, 0, 1),
    &#39;Headache&#39; = ifelse(`Headache` == 1, 0, 1),
    &#39;Tiredness or faintness&#39; = ifelse(`Tiredness or faintness` == 1, 0, 1),
    &#39;Fat pct&#39; = `Fat pct` / 100) %&gt;% 
  data.frame

# S.other &lt;- sympdf %&gt;% filter(track == &quot;Other&quot;) %&gt;% select(6:ncol(sympdf)) %&gt;% na.omit(.)
# S.it &lt;- sympdf %&gt;% filter(track == &quot;Business IT&quot;) %&gt;% select(6:ncol(sympdf))
# S.admin &lt;- sympdf %&gt;% filter(track == &quot;Business Admin&quot;) %&gt;% select(6:ncol(sympdf))
# S.hrc &lt;- sympdf %&gt;% filter(track == &quot;HRC&quot;) %&gt;% select(6:ncol(sympdf))
# S.nursing &lt;- sympdf %&gt;% filter(track == &quot;Nursing&quot;) %&gt;% select(6:ncol(sympdf))

# S.other &lt;- sympdf %&gt;% filter(track == 1) %&gt;% select(6:ncol(sympdf))
S.it &lt;- sympdf %&gt;% filter(track == 2) %&gt;% select(6:ncol(sympdf))
S.admin &lt;- sympdf %&gt;% filter(track == 3) %&gt;% select(6:ncol(sympdf))
S.hrc &lt;- sympdf %&gt;% filter(track == 4) %&gt;% select(6:ncol(sympdf))
S.nursing &lt;- sympdf %&gt;% filter(track == 5) %&gt;% select(6:ncol(sympdf))

# nwOther &lt;- bootnet::estimateNetwork(S.other, default=&quot;mgm&quot;)
nwIt &lt;- bootnet::estimateNetwork(S.it, default=&quot;mgm&quot;)
## Estimating Network. Using package::function:
##   - mgm::mgm for network computation
##     - Using glmnet::glmnet
## &#39;type&#39; argument not assigned. Setting type to &#39;c&#39; for all binary variables and &#39;g&#39; for all other variables.
## &#39;lev&#39; argument not assigned. Setting lev to 1 for all Gaussian/Poisson variables and number of unique values for all categorical variables
## Warning in max(weights): no non-missing arguments to max; returning -Inf
## Error in mgm(structure(logical(0), .Dim = c(0L, 11L), .Dimnames = list(: Only integer and numeric values permitted.
nwAdmin &lt;- bootnet::estimateNetwork(S.admin, default=&quot;mgm&quot;)
## Estimating Network. Using package::function:
##   - mgm::mgm for network computation
##     - Using glmnet::glmnet
## &#39;type&#39; argument not assigned. Setting type to &#39;c&#39; for all binary variables and &#39;g&#39; for all other variables.
## &#39;lev&#39; argument not assigned. Setting lev to 1 for all Gaussian/Poisson variables and number of unique values for all categorical variables
## Warning in max(weights): no non-missing arguments to max; returning -Inf
## Error in mgm(structure(logical(0), .Dim = c(0L, 11L), .Dimnames = list(: Only integer and numeric values permitted.
nwHrc &lt;- bootnet::estimateNetwork(S.hrc, default=&quot;mgm&quot;)
## Estimating Network. Using package::function:
##   - mgm::mgm for network computation
##     - Using glmnet::glmnet
## &#39;type&#39; argument not assigned. Setting type to &#39;c&#39; for all binary variables and &#39;g&#39; for all other variables.
## &#39;lev&#39; argument not assigned. Setting lev to 1 for all Gaussian/Poisson variables and number of unique values for all categorical variables
## Warning in max(weights): no non-missing arguments to max; returning -Inf
## Error in mgm(structure(logical(0), .Dim = c(0L, 11L), .Dimnames = list(: Only integer and numeric values permitted.
nwNursing &lt;- bootnet::estimateNetwork(S.nursing, default=&quot;mgm&quot;)
## Estimating Network. Using package::function:
##   - mgm::mgm for network computation
##     - Using glmnet::glmnet
## &#39;type&#39; argument not assigned. Setting type to &#39;c&#39; for all binary variables and &#39;g&#39; for all other variables.
## &#39;lev&#39; argument not assigned. Setting lev to 1 for all Gaussian/Poisson variables and number of unique values for all categorical variables
## Warning in max(weights): no non-missing arguments to max; returning -Inf
## Error in mgm(structure(logical(0), .Dim = c(0L, 11L), .Dimnames = list(: Only integer and numeric values permitted.

# othermeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
#   summarise_at(vars(5:15),
#   funs(mean(., na.rm = TRUE))) %&gt;% 
#   filter(track == &quot;Other&quot;) %&gt;% 
#   mutate_at(vars(PA, SB),
#             funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
#   select(-1)

# itmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
#   summarise_at(vars(5:15),
#   funs(mean(., na.rm = TRUE))) %&gt;% 
#   filter(track == &quot;Business IT&quot;) %&gt;% 
#   mutate_at(vars(PA, SB),
#             funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
#   select(-1)

itmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
  summarise_at(vars(5:15),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(track == 2) %&gt;% 
  mutate_at(vars(PA, SB),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  select(-1)

# adminmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
#   summarise_at(vars(5:15),
#   funs(mean(., na.rm = TRUE))) %&gt;% 
#   filter(track == &quot;Business Admin&quot;) %&gt;% 
#   mutate_at(vars(PA, SB),
#             funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
#   select(-1)

adminmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
  summarise_at(vars(5:15),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(track == 3) %&gt;% 
  mutate_at(vars(PA, SB),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  select(-1)

# hrcmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
#   summarise_at(vars(5:15),
#   funs(mean(., na.rm = TRUE))) %&gt;% 
#   filter(track == &quot;HRC&quot;) %&gt;% 
#   mutate_at(vars(PA, SB),
#             funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
#   select(-1)

hrcmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
  summarise_at(vars(5:15),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(track == 4) %&gt;% 
  mutate_at(vars(PA, SB),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  select(-1)

# nursingmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
#   summarise_at(vars(5:15),
#   funs(mean(., na.rm = TRUE))) %&gt;% 
#   filter(track == &quot;Nursing&quot;) %&gt;% 
#   mutate_at(vars(PA, SB),
#             funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
#   select(-1)

nursingmeans &lt;- sympdf %&gt;% group_by(track) %&gt;% 
  summarise_at(vars(5:15),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(track == 5) %&gt;% 
  mutate_at(vars(PA, SB),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  select(-1)

averagelayout &lt;- averageLayout(nwIt, nwAdmin, nwHrc, nwNursing)
## Error in averageWmat(...): object &#39;nwIt&#39; not found
# plot(nwOther, label.scale = FALSE, title = &quot;Girls&quot;, label.cex = 0.75,
#      pie = othermeans, 
#      color = &quot;skyblue&quot;,
#      pieBorder = 1)

layout(t(1:4))
plot(nwIt, label.scale = FALSE, title = &quot;Business IT&quot;, layout = averagelayout, label.cex = 0.75, 
     pie = itmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in plot(nwIt, label.scale = FALSE, title = &quot;Business IT&quot;, layout = averagelayout, : object &#39;nwIt&#39; not found

plot(nwAdmin, label.scale = FALSE, title = &quot;Business admin&quot;, layout = averagelayout, label.cex = 0.75, 
     pie = adminmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in plot(nwAdmin, label.scale = FALSE, title = &quot;Business admin&quot;, : object &#39;nwAdmin&#39; not found

plot(nwHrc, label.scale = FALSE, title = &quot;Hotel, restaurant and catering&quot;, layout = averagelayout, label.cex = 0.75, 
     pie = hrcmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in plot(nwHrc, label.scale = FALSE, title = &quot;Hotel, restaurant and catering&quot;, : object &#39;nwHrc&#39; not found

plot(nwNursing, label.scale = FALSE, title = &quot;Nursing&quot;, layout = averagelayout, label.cex = 0.75, 
     pie = nursingmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in plot(nwNursing, label.scale = FALSE, title = &quot;Nursing&quot;, layout = averagelayout, : object &#39;nwNursing&#39; not found</code></pre>
<pre class="r"><code>
colfill &lt;- c(1,2,3,4,5)

# Create data frame
densplot &lt;- d
levels(densplot$intervention) &lt;- list(&quot;Intervention&quot; = &quot;1&quot;, &quot;Control&quot; = &quot;0&quot;)
levels(densplot$girl) &lt;- list(&quot;Girl&quot; = &quot;1&quot;, &quot;Boy&quot; = &quot;0&quot;)

# This gives side-by-side plots
layout(t(1:2), 1)

# Intervention vs. control
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(fatpct_T1, intervention) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.fatpct_T1_1 &lt;- sm.density.compare2(as.numeric(dens$fatpct_T1), as.factor(dens$intervention), xlab=&quot;Percentage&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0.23
legend(&quot;topright&quot;, levels(dens$intervention), fill=c(1, 2))

# Girls vs. boys
# Choose only the variables needed and drop NA
dens &lt;- densplot %&gt;% select(fatpct_T1, girl) %&gt;% 
  filter(complete.cases(.))

# Set random number generator for reproducibility of bootstrap test of equal densities
set.seed(10)

# Make plot
sm.fatpct_T1_2 &lt;- sm.density.compare2(as.numeric(dens$fatpct_T1), as.factor(dens$girl), xlab=&quot;Percentage&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-38-1.png" width="2100" /></p>
<pre class="r"><code>
sm.fatpct_T1_2 &lt;- sm.density.compare2(as.numeric(dens$fatpct_T1), as.factor(dens$girl), xlab=&quot;Percentage&quot;, col=colfill, lty=c(1,2), bandcol=&#39;LightGray&#39;, model=&quot;equal&quot;, lwd=(c(2,2)))
## 
## Test of equal densities:  p-value =  0
legend(&quot;topright&quot;, levels(dens$girl), fill=c(1, 2))</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-38-2.png" width="2100" /></p>
</div>
</div>
<div id="physical-activity-network" class="section level1">
<h1>Physical activity network</h1>
<pre class="r"><code>
data &lt;- df %&gt;% select(PA = paAccelerometer_T1, actCop = actcop_T1, BCT = frqbct_T1, amot = amotivation_T1, auton = autonomous_T1, cont = controlled_T1, dnorm = dnorm_T1, fatpct = fatpct_T1, inorm = inorm_T1, intent = intention_T1, oexp = oexp_T1, opp = opportunities_T1, sePbc = sePbc_T1) %&gt;% data.frame() 
## Error in overscope_eval_next(overscope, expr): object &#39;actcop_T1&#39; not found

# Spinglass algorithm detects communities. Tutorial here: http://psych-networks.com/r-tutorial-identify-communities-items-networks/

qgraph(cor_auto(data), layout=&quot;spring&quot;)
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;symbol&#39;
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;language&#39;
## Error in data[, sapply(data, function(x) mean(is.na(x))) != 1]: object of type &#39;closure&#39; is not subsettable

cormatrix &lt;- cor_auto(data1)
## Error in as.data.frame(data): object &#39;data1&#39; not found

graph1 &lt;- qgraph(cormatrix, graph=&quot;glasso&quot;, layout=&quot;spring&quot;, sampleSize = nrow(data),
              vsize=7, cut=0, maximum=.45, border.width=1.5)
## Error in qgraph(cormatrix, graph = &quot;glasso&quot;, layout = &quot;spring&quot;, sampleSize = nrow(data), : object &#39;cormatrix&#39; not found

g = as.igraph(graph1, attributes=TRUE)

sgc &lt;- spinglass.community(g)

sgc$membership
##  [1] 1 4 3 3 3 3 3 2 2 2 2 2 4 4 4 4 4 4 4

group.spinglass&lt;- list(c(1, 2, 3, 5, 10), 
                       c(4, 6, 8), 
                       c(7, 9), 
                       c(11, 12, 13))

set.seed(2)

network1 &lt;- bootnet::estimateNetwork(data1, default=&quot;EBICglasso&quot;)
## Error in is.data.frame(data): object &#39;data1&#39; not found

#bladibla &lt;- averageLayout(network1$graph, network2$graph)

# layout(t(1:2))
# graph1 &lt;- plot(network1, layout=bladibla, cut=0)
# graph2 &lt;- plot(network2, layout=bladibla, cut=0)
# graph1 &lt;- plot(network1, cut=0)
# graph2 &lt;- plot(network2, cut=0)

plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, color=c(&quot;olivedrab2&quot;, &quot;orange&quot;, &quot;mediumpurple1&quot;, &quot;lightblue&quot;))
## Error in plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, : object &#39;network1&#39; not found</code></pre>
<div id="pa-network-without-sdt-motivations" class="section level3">
<h3>PA network without SDT motivations</h3>
<pre class="r"><code># Network without motivation variables
data &lt;- df %&gt;% select(PA = paAccelerometer_T1, actCop = PA_actcop_T1, BCT = PA_frqbct_T1, amot = PA_amotivation_T1, auton = PA_autonomous_T1, cont = PA_controlled_T1, dnorm = PA_dnorm_T1, fatpct = fatpct_T1, inorm = PA_inorm_T1, intent = PA_intention_T1, oexp = PA_oexp_T1, opp = PA_opportunities_T1, sePbc = PA_sePbc_T1) %&gt;% data.frame() %&gt;% 
  select(-auton, -cont, -amot)
## Error in overscope_eval_next(overscope, expr): object &#39;PA_actcop_T1&#39; not found

# Spinglass algorithm detects communities. Tutorial here: http://psych-networks.com/r-tutorial-identify-communities-items-networks/

cormatrix &lt;- cor_auto(data)
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;symbol&#39;
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;language&#39;
## Error in data[, sapply(data, function(x) mean(is.na(x))) != 1]: object of type &#39;closure&#39; is not subsettable

graph1&lt;-qgraph(cormatrix, graph=&quot;glasso&quot;, layout=&quot;spring&quot;, sampleSize = nrow(data),
              vsize=7, cut=0, maximum=.45, border.width=1.5)
## Error in qgraph(cormatrix, graph = &quot;glasso&quot;, layout = &quot;spring&quot;, sampleSize = nrow(data), : object &#39;cormatrix&#39; not found

g = as.igraph(graph1, attributes=TRUE)

sgc &lt;- spinglass.community(g)

sgc$membership
##  [1] 1 2 1 1 1 1 1 3 3 3 3 3 2 2 2 2 2 2 2

# Without SDT motivations
group.spinglass&lt;- list(c(1, 2, 3, 7), 
                       c(4, 6), 
                       c(5), 
                       c(8, 9, 10))

set.seed(2)

network1 &lt;- bootnet::estimateNetwork(data, default=&quot;EBICglasso&quot;)
## Error in bootnet::estimateNetwork(data, default = &quot;EBICglasso&quot;): &#39;data&#39; argument must be a data frame

plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, color=c(&quot;olivedrab2&quot;, &quot;orange&quot;, &quot;mediumpurple1&quot;, &quot;lightblue&quot;))
## Error in plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, : object &#39;network1&#39; not found</code></pre>
</div>
<div id="pa-network-without-bcts-and-sdt" class="section level3">
<h3>PA network without BCTs and SDT</h3>
<pre class="r"><code># Network without motivation variables
data &lt;- df %&gt;% select(PA = paAccelerometer_T1, &#39;action and coping planning&#39; = PA_actcop_T1, &#39;Frequency-related BCTs&#39; = PA_frqbct_T1, &#39;amotivation&#39; = PA_amotivation_T1, &#39;autonomous motivation&#39; = PA_autonomous_T1, &#39;controlled motivation&#39; = PA_controlled_T1, &#39;descriptive norm&#39; = PA_dnorm_T1, &#39;injunctive norm&#39; = PA_inorm_T1, &quot;fat pct&quot; = fatpct_T1, &#39;intention&#39; = PA_intention_T1, &#39;outcome expectations&#39; = PA_oexp_T1, &#39;Self-efficacy / PBC&#39; = PA_sePbc_T1, &#39;perceived opportunities&#39; = PA_opportunities_T1) %&gt;% 
            select(-`autonomous motivation`, -`controlled motivation`, -`amotivation`, -`Frequency-related BCTs`) %&gt;% 
  data.frame
## Error in overscope_eval_next(overscope, expr): object &#39;PA_actcop_T1&#39; not found

# Spinglass algorithm detects communities. Tutorial here: http://psych-networks.com/r-tutorial-identify-communities-items-networks/

cormatrix &lt;- cor_auto(data)
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;symbol&#39;
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;language&#39;
## Error in data[, sapply(data, function(x) mean(is.na(x))) != 1]: object of type &#39;closure&#39; is not subsettable

graph1 &lt;- qgraph(cormatrix, graph=&quot;glasso&quot;, layout=&quot;spring&quot;, sampleSize = nrow(data),
              vsize=7, cut=0, maximum=.45, border.width=1.5)
## Error in qgraph(cormatrix, graph = &quot;glasso&quot;, layout = &quot;spring&quot;, sampleSize = nrow(data), : object &#39;cormatrix&#39; not found

g = as.igraph(graph1, attributes=TRUE)

set.seed(4)

sgc &lt;- spinglass.community(g)

sgc$membership
##  [1] 2 4 2 2 1 1 1 3 3 3 3 3 4 4 4 4 4 4 4

# Without SDT motivations

group.spinglass&lt;- list(c(1, 2, 6), 
                       c(3, 4), 
                       c(5),
                       c(7, 8, 9))

network1 &lt;- bootnet::estimateNetwork(data, default=&quot;EBICglasso&quot;)
## Error in bootnet::estimateNetwork(data, default = &quot;EBICglasso&quot;): &#39;data&#39; argument must be a data frame

piefill &lt;- data %&gt;%
  summarise_all(funs(mean(., na.rm = TRUE))) %&gt;% 
  mutate_at(vars(PA),
            funs(. / (24*60))) %&gt;% # proportion of day used doing the behaviour
  mutate_at(vars(action.and.coping.planning),
            funs(. / 4)) %&gt;% 
  mutate_at(vars(3, 4, 6, 7, 8, 9),
            funs(. / 7)) %&gt;% 
  mutate_at(vars(5),
            funs(. / 100))  
## Error in UseMethod(&quot;tbl_vars&quot;): no applicable method for &#39;tbl_vars&#39; applied to an object of class &quot;function&quot;

plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, color=c(&quot;olivedrab2&quot;, &quot;orange&quot;, &quot;mediumpurple1&quot;, &quot;lightblue&quot;),
     label.cex = 0.75,
     label.scale = FALSE,
     pie = piefill, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, : object &#39;network1&#39; not found


plot(nwBoys, label.scale = FALSE, title = &quot;Boys&quot;, label.cex = 0.75, 
     pie = boymeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-41-1.png" width="2100" /></p>
</div>
<div id="pa-network-without-bcts-and-sdt-intention-pa-fat" class="section level3">
<h3>PA network without BCTs and SDT, intention, PA, fat%</h3>
<pre class="r"><code># Network without motivation variables
data &lt;- df %&gt;% select(PA = paAccelerometer_T1, &#39;action and coping planning&#39; = PA_actcop_T1, &#39;Frequency-related BCTs&#39; = PA_frqbct_T1, &#39;amotivation&#39; = PA_amotivation_T1, &#39;autonomous motivation&#39; = PA_autonomous_T1, &#39;controlled motivation&#39; = PA_controlled_T1, &#39;descriptive norm&#39; = PA_dnorm_T1, &#39;injunctive norm&#39; = PA_inorm_T1, &quot;fat pct&quot; = fatpct_T1, &#39;intention&#39; = PA_intention_T1, &#39;outcome expectations&#39; = PA_oexp_T1, &#39;Self-efficacy / PBC&#39; = PA_sePbc_T1, &#39;perceived opportunities&#39; = PA_opportunities_T1) %&gt;% 
            select(-`autonomous motivation`, -`controlled motivation`, -`amotivation`, -`Frequency-related BCTs`, -PA, -`intention`, -`fat pct`) %&gt;% 
  data.frame
## Error in overscope_eval_next(overscope, expr): object &#39;PA_actcop_T1&#39; not found

# Spinglass algorithm detects communities. Tutorial here: http://psych-networks.com/r-tutorial-identify-communities-items-networks/

cormatrix &lt;- cor_auto(data)
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;symbol&#39;
## Warning in is.na(x): is.na() applied to non-(list or vector) of type
## &#39;language&#39;
## Error in data[, sapply(data, function(x) mean(is.na(x))) != 1]: object of type &#39;closure&#39; is not subsettable

graph1 &lt;- qgraph(cormatrix, graph=&quot;glasso&quot;, layout=&quot;spring&quot;, sampleSize = nrow(data),
              vsize=7, cut=0, maximum=.45, border.width=1.5)
## Error in qgraph(cormatrix, graph = &quot;glasso&quot;, layout = &quot;spring&quot;, sampleSize = nrow(data), : object &#39;cormatrix&#39; not found

g = as.igraph(graph1, attributes=TRUE)

set.seed(1)

sgc &lt;- spinglass.community(g)

sgc$membership
##  [1] 1 3 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 3

group.spinglass&lt;- list(c(1, 4:6), 
                       c(2, 3))

# Estimate and plot graph


network1 &lt;- bootnet::estimateNetwork(data, default=&quot;EBICglasso&quot;)
## Error in bootnet::estimateNetwork(data, default = &quot;EBICglasso&quot;): &#39;data&#39; argument must be a data frame

piefill &lt;- data %&gt;%
  summarise_all(funs(mean(., na.rm = TRUE))) %&gt;%
  mutate_at(vars(action.and.coping.planning),
            funs(. / 4)) %&gt;% 
  mutate_at(vars(2:6),
            funs(. / 7))
## Error in UseMethod(&quot;tbl_vars&quot;): no applicable method for &#39;tbl_vars&#39; applied to an object of class &quot;function&quot;

plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, color=c(&quot;olivedrab2&quot;, &quot;orange&quot;, &quot;mediumpurple1&quot;, &quot;lightblue&quot;),
     label.cex = 0.75,
     label.scale = FALSE,
     pie = piefill, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)
## Error in plot(network1, layout = &quot;spring&quot;, labels = TRUE, groups = group.spinglass, : object &#39;network1&#39; not found</code></pre>
</div>
<div id="robustness-test" class="section level2">
<h2>Robustness test</h2>
<pre class="r"><code>
Network1 &lt;- bootnet::estimateNetwork(data1, default = &quot;EBICglasso&quot;)
## Error in is.data.frame(data): object &#39;data1&#39; not found
plot(Network1, layout = &quot;spring&quot;, labels = TRUE)
## Error in plot(Network1, layout = &quot;spring&quot;, labels = TRUE): object &#39;Network1&#39; not found

qgraph::centralityPlot(Network1)
## Note: z-scores are shown on x-axis rather than raw centrality indices.
## Error in getWmat(list(...)): object &#39;Network1&#39; not found

boot1 &lt;- bootnet::bootnet(Network1, nBoots = 2500, nCores = 2)
## Error in is(data, &quot;bootnetResult&quot;): object &#39;Network1&#39; not found

plot(boot1, labels = TRUE, order = &quot;sample&quot;)
## Error in plot(boot1, labels = TRUE, order = &quot;sample&quot;): object &#39;boot1&#39; not found

Network2 &lt;- bootnet::estimateNetwork(data1, default = &quot;pcor&quot;)
## Error in is.data.frame(data): object &#39;data1&#39; not found
plot(Network2, layout = &quot;spring&quot;, labels = TRUE)
## Error in plot(Network2, layout = &quot;spring&quot;, labels = TRUE): object &#39;Network2&#39; not found

boot2 &lt;- bootnet::bootnet(Network2, nBoots = 2500, nCores = 2)
## Error in is(data, &quot;bootnetResult&quot;): object &#39;Network2&#39; not found

qgraph::centralityPlot(Network)
## Note: z-scores are shown on x-axis rather than raw centrality indices.
## Error in getWmat(list(...)): object &#39;Network&#39; not found
qgraph::centralityPlot(Network2)
## Note: z-scores are shown on x-axis rather than raw centrality indices.
## Error in getWmat(list(...)): object &#39;Network2&#39; not found</code></pre>
</div>
<div id="centrality-stability-1" class="section level2">
<h2>Centrality stability</h2>
<pre class="r"><code>boot2 &lt;- bootnet::bootnet(Network1, nBoots = 2500, type = &quot;case&quot;, nCores = 2)
## Error in is(data, &quot;bootnetResult&quot;): object &#39;Network1&#39; not found
bootnet::corStability(boot2)
## === Correlation Stability Analysis === 
## 
## Sampling levels tested:
##    nPerson Drop%   n
## 1      291  75.0 236
## 2      382  67.2 261
## 3      472  59.5 252
## 4      563  51.7 235
## 5      654  43.9 231
## 6      744  36.1 253
## 7      835  28.3 250
## 8      926  20.5 240
## 9     1016  12.8 279
## 10    1107   5.0 263
## 
## Maximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:
## 
## betweenness: 0.361
##   - For more accuracy, run bootnet(..., caseMin = 0.283, caseMax = 0.439) 
## 
## closeness: 0.672
##   - For more accuracy, run bootnet(..., caseMin = 0.595, caseMax = 0.75) 
## 
## strength: 0.75
##   - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) 
## 
## Accuracy can also be increased by increasing both &#39;nBoots&#39; and &#39;caseN&#39;.

plot(boot2)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-44-1.png" width="2100" /></p>
<pre class="r"><code>
differenceTest(boot1, &quot;auton&quot;, &quot;intent&quot;,  measure = c(&quot;strength&quot;, &quot;closeness&quot;, &quot;betweenness&quot;))
## Error in bootobject$type %in% c(&quot;nonparametric&quot;, &quot;parametric&quot;): object &#39;boot1&#39; not found

plot(boot1, &quot;edge&quot;, plot = &quot;difference&quot;, onlyNonZero = TRUE, order = &quot;sample&quot;)
## Error in plot(boot1, &quot;edge&quot;, plot = &quot;difference&quot;, onlyNonZero = TRUE, : object &#39;boot1&#39; not found

plot(boot1, &quot;strength&quot;)
## Error in plot(boot1, &quot;strength&quot;): object &#39;boot1&#39; not found
plot(boot1, &quot;betweenness&quot;)
## Error in plot(boot1, &quot;betweenness&quot;): object &#39;boot1&#39; not found
plot(boot1, &quot;closeness&quot;)
## Error in plot(boot1, &quot;closeness&quot;): object &#39;boot1&#39; not found</code></pre>
</div>
<div id="network-comparison-test-girls-and-boys" class="section level2">
<h2>Network comparison test: girls and boys</h2>
<pre class="r"><code>
# here goes your data; call it &quot;data&quot;
data &lt;- df %&gt;% select(paT1, girl, actcop_T1, frqbct_T1, amotivation_T1, autonomous_T1, controlled_T1, dnorm_T1, fatpct_T1, inorm_T1, intention_T1, oexp_T1, opportunities_T1, sePbc_T1) 
## Error in overscope_eval_next(overscope, expr): object &#39;paT1&#39; not found

### Split data into girls and boys
data1 &lt;- data %&gt;% filter(girl == 1) %&gt;% select(-girl) %&gt;% as.data.frame
## Error in UseMethod(&quot;filter_&quot;): no applicable method for &#39;filter_&#39; applied to an object of class &quot;function&quot;

data2 &lt;- data %&gt;% filter(girl == 0) %&gt;% select(-girl) %&gt;% as.data.frame
## Error in UseMethod(&quot;filter_&quot;): no applicable method for &#39;filter_&#39; applied to an object of class &quot;function&quot;

# ---------------------------------------------------------------------------------------
# ---------- 3. NCT ------------------------------------------------------------------
# ---------------------------------------------------------------------------------------


### estimate networks and compare visually; use averageLayout function, then plot via layout(t(1:2))
network1 &lt;- bootnet::estimateNetwork(data1, default=&quot;EBICglasso&quot;)
## Error in is.data.frame(data): object &#39;data1&#39; not found
network2 &lt;- bootnet::estimateNetwork(data2, default=&quot;EBICglasso&quot;)
## Error in is.data.frame(data): object &#39;data2&#39; not found

bladibla &lt;- averageLayout(network1$graph, network2$graph)
## Error in averageWmat(...): object &#39;network1&#39; not found

layout(t(1:2))
graph1 &lt;- plot(network1, layout=bladibla, cut=0)
## Error in plot(network1, layout = bladibla, cut = 0): object &#39;network1&#39; not found
graph2 &lt;- plot(network2, layout=bladibla, cut=0)
## Error in plot(network2, layout = bladibla, cut = 0): object &#39;network2&#39; not found

### run NCT 

nct_results &lt;- NetworkComparisonTest::NCT(data1, data2, it=1000, binary.data=FALSE, paired=TRUE, test.edges=TRUE, edges=&#39;all&#39;, progressbar=TRUE)
## Error in is(data1, &quot;bootnetResult&quot;): object &#39;data1&#39; not found

nct_results$nwinv.pval  # p value of network structure diff test
## Error in eval(expr, envir, enclos): object &#39;nct_results&#39; not found
nct_results$glstrinv.pval  # p value of global connectivity diff test
## Error in eval(expr, envir, enclos): object &#39;nct_results&#39; not found
nct_results$einv.pvals     #p values testing diffs for all individual edges
## Error in eval(expr, envir, enclos): object &#39;nct_results&#39; not found
sum(nct_results$einv.pvals$&quot;p-value&quot; &lt; 0.05)  # how many edges are different
## Error in eval(expr, envir, enclos): object &#39;nct_results&#39; not found</code></pre>
</div>
<div id="robustness-test-1" class="section level2">
<h2>Robustness test</h2>
<pre class="r"><code>data &lt;- data %&gt;% select(BCT = agrbct_T1,
    AUT = autonomous_T1,
    Intn = intention_T1,
    PBC = pbc_T1,
    OExp = oexp_T1,
    DNorm = norm_T1)
## Error in UseMethod(&quot;select_&quot;): no applicable method for &#39;select_&#39; applied to an object of class &quot;function&quot;

Network &lt;- bootnet::estimateNetwork(data, default = &quot;EBICglasso&quot;)
## Error in bootnet::estimateNetwork(data, default = &quot;EBICglasso&quot;): &#39;data&#39; argument must be a data frame

boot1 &lt;- bootnet::bootnet(Network, nBoots = 2500, nCores = 2)
## Error in is(data, &quot;bootnetResult&quot;): object &#39;Network&#39; not found

plot(boot1, labels = TRUE, order = &quot;sample&quot;)
## Error in plot(boot1, labels = TRUE, order = &quot;sample&quot;): object &#39;boot1&#39; not found

plot(Network, layout = &quot;spring&quot;, labels = TRUE)
## Error in plot(Network, layout = &quot;spring&quot;, labels = TRUE): object &#39;Network&#39; not found

Network2 &lt;- bootnet::estimateNetwork(data, default = &quot;pcor&quot;)
## Error in bootnet::estimateNetwork(data, default = &quot;pcor&quot;): &#39;data&#39; argument must be a data frame
plot(Network2, layout = &quot;spring&quot;, labels = TRUE)
## Error in plot(Network2, layout = &quot;spring&quot;, labels = TRUE): object &#39;Network2&#39; not found

boot1 &lt;- bootnet::bootnet(Network2, nBoots = 2500, nCores = 2)
## Error in is(data, &quot;bootnetResult&quot;): object &#39;Network2&#39; not found

qgraph::centralityPlot(Network)
## Note: z-scores are shown on x-axis rather than raw centrality indices.
## Error in getWmat(list(...)): object &#39;Network&#39; not found
qgraph::centralityPlot(Network2)
## Note: z-scores are shown on x-axis rather than raw centrality indices.
## Error in getWmat(list(...)): object &#39;Network2&#39; not found</code></pre>
</div>
</div>
<div id="centrality-stability-2" class="section level1">
<h1>Centrality stability</h1>
<pre class="r"><code>boot2 &lt;- bootnet::bootnet(Network, nBoots = 2500, type = &quot;case&quot;, nCores = 2)
## Error in is(data, &quot;bootnetResult&quot;): object &#39;Network&#39; not found
bootnet::corStability(boot2)
## === Correlation Stability Analysis === 
## 
## Sampling levels tested:
##    nPerson Drop%   n
## 1      291  75.0 236
## 2      382  67.2 261
## 3      472  59.5 252
## 4      563  51.7 235
## 5      654  43.9 231
## 6      744  36.1 253
## 7      835  28.3 250
## 8      926  20.5 240
## 9     1016  12.8 279
## 10    1107   5.0 263
## 
## Maximum drop proportions to retain correlation of 0.7 in at least 95% of the samples:
## 
## betweenness: 0.361
##   - For more accuracy, run bootnet(..., caseMin = 0.283, caseMax = 0.439) 
## 
## closeness: 0.672
##   - For more accuracy, run bootnet(..., caseMin = 0.595, caseMax = 0.75) 
## 
## strength: 0.75
##   - For more accuracy, run bootnet(..., caseMin = 0.672, caseMax = 1) 
## 
## Accuracy can also be increased by increasing both &#39;nBoots&#39; and &#39;caseN&#39;.

plot(boot2)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-47-1.png" width="2100" /></p>
<pre class="r"><code>
differenceTest(boot1, &quot;AUT&quot;, &quot;Intn&quot;,  measure = c(&quot;strength&quot;, &quot;closeness&quot;, &quot;betweenness&quot;))
## Error in bootobject$type %in% c(&quot;nonparametric&quot;, &quot;parametric&quot;): object &#39;boot1&#39; not found

plot(boot1, &quot;edge&quot;, plot = &quot;difference&quot;, onlyNonZero = TRUE, order = &quot;sample&quot;)
## Error in plot(boot1, &quot;edge&quot;, plot = &quot;difference&quot;, onlyNonZero = TRUE, : object &#39;boot1&#39; not found

plot(boot1, &quot;strength&quot;)
## Error in plot(boot1, &quot;strength&quot;): object &#39;boot1&#39; not found
plot(boot1, &quot;betweenness&quot;)
## Error in plot(boot1, &quot;betweenness&quot;): object &#39;boot1&#39; not found
plot(boot1, &quot;closeness&quot;)
## Error in plot(boot1, &quot;closeness&quot;): object &#39;boot1&#39; not found</code></pre>
</div>
<div id="pa-motivation-examined" class="section level1">
<h1>PA motivation examined</h1>
<pre class="r"><code>nItems &lt;- 18
regulations.df &lt;- lmi %&gt;% select(id = ID,
  intervention = ryhmä,
  group = ryhmäkoodi_korjattu,
  school = Aineisto.1,
  girl = Kys0013.1,
  PA_amotivation_02_T1 = Kys0086.1,
  PA_amotivation_01_T1 = Kys0082.1,
  PA_amotivation_03_T1 = Kys0096.1,
  PA_amotivation_04_T1 = Kys0097.1,
  PA_extrinsic_01_T1 = Kys0080.1,
  PA_extrinsic_02_T1 = Kys0081.1,
  PA_extrinsic_03_T1 = Kys0083.1,
  PA_introjected_01_T1 = Kys0084.1,
  PA_introjected_02_T1 = Kys0085.1,
  PA_identified_01_T1 = Kys0087.1,
  PA_identified_02_T1 = Kys0088.1,
  PA_identified_03_T1 = Kys0090.1,
  PA_integrated_01_T1 = Kys0089.1,
  PA_integrated_02_T1 = Kys0092.1,
  PA_integrated_03_T1 = Kys0094.1,
  PA_intrinsic_01_T1 = Kys0091.1,
  PA_intrinsic_02_T1 = Kys0093.1,
  PA_intrinsic_03_T1 = Kys0095.1
)
## Error in overscope_eval_next(overscope, expr): object &#39;ryhmä&#39; not found

regulations.df &lt;- regulations.df %&gt;% dplyr::mutate(group = ifelse(group == &quot;&quot;, NA, group))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found

# Fix intervention and gender variables
regulations.df &lt;- regulations.df %&gt;% dplyr::mutate(intervention = ifelse(intervention == 1, 1, 0),
                         intervention = factor(intervention),
            girl = ifelse(girl == 2, 1, 0),
            girl = factor(girl, levels = c(&quot;1&quot;, &quot;0&quot;)),
            school = factor(school, levels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;)))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found


motiGirls &lt;- regulations.df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  PA_amotivation_02_T1,
  PA_amotivation_01_T1,
  PA_amotivation_03_T1,
  PA_amotivation_04_T1,
  PA_extrinsic_01_T1,
  PA_extrinsic_02_T1,
  PA_extrinsic_03_T1,
  PA_introjected_01_T1,
  PA_introjected_02_T1,
  PA_identified_01_T1,
  PA_identified_02_T1,
  PA_identified_03_T1,
  PA_integrated_01_T1,
  PA_integrated_02_T1,
  PA_integrated_03_T1,
  PA_intrinsic_01_T1,
  PA_intrinsic_02_T1,
  PA_intrinsic_03_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Girls&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 5.5))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found

motiBoys &lt;- regulations.df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  PA_amotivation_02_T1,
  PA_amotivation_01_T1,
  PA_amotivation_03_T1,
  PA_amotivation_04_T1,
  PA_extrinsic_01_T1,
  PA_extrinsic_02_T1,
  PA_extrinsic_03_T1,
  PA_introjected_01_T1,
  PA_introjected_02_T1,
  PA_identified_01_T1,
  PA_identified_02_T1,
  PA_identified_03_T1,
  PA_integrated_01_T1,
  PA_integrated_02_T1,
  PA_integrated_03_T1,
  PA_intrinsic_01_T1,
  PA_intrinsic_02_T1,
  PA_intrinsic_03_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(girl == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;darkolivegreen2&quot;, &quot;darkolivegreen4&quot;)) +
  labs(title = &quot;Boys&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        plot.title = element_text(hjust = 0.5),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 5.5))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found

motiInt &lt;- regulations.df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  PA_amotivation_02_T1,
  PA_amotivation_01_T1,
  PA_amotivation_03_T1,
  PA_amotivation_04_T1,
  PA_extrinsic_01_T1,
  PA_extrinsic_02_T1,
  PA_extrinsic_03_T1,
  PA_introjected_01_T1,
  PA_introjected_02_T1,
  PA_identified_01_T1,
  PA_identified_02_T1,
  PA_identified_03_T1,
  PA_integrated_01_T1,
  PA_integrated_02_T1,
  PA_integrated_03_T1,
  PA_intrinsic_01_T1,
  PA_intrinsic_02_T1,
  PA_intrinsic_03_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;1&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Intervention&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 5.5))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found

motiCont &lt;- regulations.df %&gt;% dplyr::select(id,
  intervention,
  group,
  school,
  girl,
  PA_amotivation_02_T1,
  PA_amotivation_01_T1,
  PA_amotivation_03_T1,
  PA_amotivation_04_T1,
  PA_extrinsic_01_T1,
  PA_extrinsic_02_T1,
  PA_extrinsic_03_T1,
  PA_introjected_01_T1,
  PA_introjected_02_T1,
  PA_identified_01_T1,
  PA_identified_02_T1,
  PA_identified_03_T1,
  PA_integrated_01_T1,
  PA_integrated_02_T1,
  PA_integrated_03_T1,
  PA_intrinsic_01_T1,
  PA_intrinsic_02_T1,
  PA_intrinsic_03_T1) %&gt;%
 tidyr::gather(key = Variable, value = Value, 6:ncol(.)) %&gt;%
  filter(intervention == &quot;0&quot;) %&gt;% 
 ggplot(aes(x = Value, y = Variable, group = Variable)) +
  ggridges::geom_density_ridges2(aes(fill = Variable), stat = &quot;binline&quot;, binwidth = 1, scale = 0.95) +
  scale_x_continuous(breaks = c(1:6), expand = c(0, 0),
                     name = &quot;&quot;) +
  scale_y_discrete(expand = c(0.01, 0), name = &quot;&quot;, labels = NULL) +
  ggridges::scale_fill_cyclical(values = c(&quot;deepskyblue&quot;, &quot;deepskyblue4&quot;)) +
  labs(title = &quot;Control&quot;) +
  guides(y = &quot;none&quot;) +
  ggridges::theme_ridges(grid = FALSE) +
  theme(axis.title.x = element_text(hjust = 0.5),
        axis.title.y = element_text(hjust = 0.5),
        axis.text=element_text(size=10)) +
coord_cartesian(xlim = c(0.5, 5.5))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found

#grid.arrange(motiInt, motiGirls, motiCont, motiBoys, ncol = 2)

# (&quot;Seldom or never&quot;, &quot;About once a month&quot;, &quot;About once a week&quot;, &quot;Almost daily&quot;)

# This draws all histograms next to each other:
grid::grid.newpage()
grid::grid.draw(cbind(ggplotGrob(motiInt), ggplotGrob(motiCont), ggplotGrob(motiGirls), ggplotGrob(motiBoys), size = &quot;last&quot;))
## Error in plot_clone(plot): object &#39;motiInt&#39; not found</code></pre>
<div id="motivational-regulations-network" class="section level2">
<h2>Motivational regulations network</h2>
</div>
<div id="tee-tanne-piefill-tummempi-sama-vari-tai-opacity" class="section level2">
<h2>TEE TÄNNE PIEFILL; tummempi sama väri tai opacity?</h2>
<pre class="r"><code># Was going to do fused graphical lasso, but the items not normal...

# s1 &lt;- regulations.df %&gt;% filter(school == 1) %&gt;% select(6:ncol(regulations.df)) # %&gt;% na.omit(.) 
# s2 &lt;- regulations.df %&gt;% filter(school == 2) %&gt;% select(6:ncol(regulations.df)) # %&gt;% na.omit(.)
# s3 &lt;- regulations.df %&gt;% filter(school == 3) %&gt;% select(6:ncol(regulations.df)) # %&gt;% na.omit(.) 
# s4 &lt;- regulations.df %&gt;% filter(school == 4) %&gt;% select(6:ncol(regulations.df)) # %&gt;% na.omit(.)
# s5 &lt;- regulations.df %&gt;% filter(school == 5) %&gt;% select(6:ncol(regulations.df)) # %&gt;% na.omit(.)
# 
# network2 &lt;- EstimateGroupNetwork(list(&quot;1&quot; = s1,
#                                       &quot;2&quot; = s2,
#                                       &quot;3&quot; = s3,
#                                       &quot;4&quot; = s4,
#                                       &quot;5&quot; = s5),
#                                  n = c(nrow(s1), nrow(s2), nrow(s3), nrow(s4), nrow(s5)))
# 
regulations.df &lt;- regulations.df %&gt;% mutate(
PA_amotivation_02_T1 = ifelse(PA_amotivation_02_T1 == 1, 0, 1),
PA_amotivation_01_T1 = ifelse(PA_amotivation_01_T1 == 1, 0, 1),
PA_amotivation_03_T1 = ifelse(PA_amotivation_03_T1 == 1, 0, 1),
PA_amotivation_04_T1 = ifelse(PA_amotivation_04_T1 == 1, 0, 1),
PA_extrinsic_01_T1 = ifelse(PA_extrinsic_01_T1 == 1, 0, 1),
PA_extrinsic_02_T1 = ifelse(PA_extrinsic_02_T1 == 1, 0, 1),
PA_extrinsic_03_T1 = ifelse(PA_extrinsic_03_T1 == 1, 0, 1),
PA_introjected_01_T1 = ifelse(PA_introjected_01_T1 == 1, 0, 1),
PA_introjected_02_T1 = ifelse(PA_introjected_02_T1 == 1, 0, 1),
PA_identified_01_T1 = ifelse(PA_identified_01_T1 == 1, 0, 1),
PA_identified_02_T1 = ifelse(PA_identified_02_T1 == 1, 0, 1),
PA_identified_03_T1 = ifelse(PA_identified_03_T1 == 1, 0, 1),
PA_integrated_01_T1 = ifelse(PA_integrated_01_T1 == 1, 0, 1),
PA_integrated_02_T1 = ifelse(PA_integrated_02_T1 == 1, 0, 1),
PA_integrated_03_T1 = ifelse(PA_integrated_03_T1 == 1, 0, 1),
PA_intrinsic_01_T1 = ifelse(PA_intrinsic_01_T1 == 1, 0, 1),
PA_intrinsic_02_T1 = ifelse(PA_intrinsic_02_T1 == 1, 0, 1),
PA_intrinsic_03_T1 = ifelse(PA_intrinsic_03_T1 == 1, 0, 1))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found


### GIRLS AND BOYS

S.boys &lt;- regulations.df %&gt;% filter(girl == 0) %&gt;% select(6:ncol(regulations.df)) # %&gt;% na.omit(.) 
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found
S.girls &lt;- regulations.df %&gt;% filter(girl == 1) %&gt;% select(6:ncol(regulations.df)) # %&gt;% na.omit(.)
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found
nwBoys &lt;- bootnet::estimateNetwork(S.boys, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## Error in y %*% rep(1, nc): non-conformable arguments
nwGirls &lt;- bootnet::estimateNetwork(S.girls, default=&quot;IsingFit&quot;)
## Estimating Network. Using package::function:
##   - IsingFit::IsingFit for network computation
##     - Using glmnet::glmnet
## Warning in bootnet::binarize(data, split = split, verbose = verbose):
## Splitting data by median
## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |======                                                           |   9%
  |                                                                       
  |============                                                     |  18%
  |                                                                       
  |==================                                               |  27%
  |                                                                       
  |========================                                         |  36%
  |                                                                       
  |==============================                                   |  45%
  |                                                                       
  |===================================                              |  55%
  |                                                                       
  |=========================================                        |  64%
  |                                                                       
  |===============================================                  |  73%
  |                                                                       
  |=====================================================            |  82%
  |                                                                       
  |===========================================================      |  91%
  |                                                                       
  |=================================================================| 100%

data1 &lt;- regulations.df %&gt;% select(6:ncol(regulations.df))
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found
names(data1) &lt;- c(paste0(rep(&quot;Amoti&quot;, 4), 1:4),
                paste0(rep(&quot;Extri&quot;, 3), 1:3),
                paste0(rep(&quot;Intro&quot;, 2), 1:2),
                paste0(rep(&quot;Ident&quot;, 3), 1:3),
                paste0(rep(&quot;Integ&quot;, 3), 1:3),
                paste0(rep(&quot;Intri&quot;, 3), 1:3))
## Error in names(data1) &lt;- c(paste0(rep(&quot;Amoti&quot;, 4), 1:4), paste0(rep(&quot;Extri&quot;, : object &#39;data1&#39; not found
nwAll &lt;- bootnet::estimateNetwork(data1, default=&quot;IsingFit&quot;)
## Error in is.data.frame(data): object &#39;data1&#39; not found

# Create means for filling nodes
girlmeans &lt;- regulations.df %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:(5+nItems-1)),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 1) %&gt;% 
  select(-1)
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found

boymeans &lt;- regulations.df %&gt;% group_by(girl) %&gt;% 
  summarise_at(vars(5:(5+nItems-1)),
  funs(mean(., na.rm = TRUE))) %&gt;% 
  filter(girl == 0) %&gt;% 
  select(-1)
## Error in eval(lhs, parent, parent): object &#39;regulations.df&#39; not found

# Find average layout for comparability and plot graphs next to each other

Layout &lt;- averageLayout(nwGirls, nwBoys)


layout(t(1:2))
plot(nwGirls, layout = Layout, label.scale = FALSE, title = &quot;Girls&quot;, label.cex = 0.75,
     pie = girlmeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)

plot(nwBoys, layout = Layout, label.scale = FALSE, title = &quot;Boys&quot;, label.cex = 0.75, 
     pie = boymeans, 
     color = &quot;skyblue&quot;,
     pieBorder = 1)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-49-1.png" width="2100" /></p>
<pre class="r"><code>
itemNames &lt;- c(&#39;I can\&#39;t see why I should bother exercising&#39;,
  &#39;I do not see why I should have to exercise&#39;,
  &#39; I do not see the point in exercising&#39;,
  &#39; I think exercising is a waste of time&#39;,
  &#39; I exercise because other people say I should&#39;,
  &#39; I exercise because others will not be pleased with me if I do not&#39;,
  &#39; I feel under pressure from my friends/family to exercise&#39;,
  &#39; I feel guilty when I do not exercise&#39;,
  &#39; I feel like a failure when I have not exercised in a while&#39;,
  &#39; I think it is important to make the effort to exercise regularly&#39;,
  &#39; I value the benefits of exercise&#39;,
  &#39; it is important to me to exercise regularly&#39;,
  &#39; I exercise because it is consistent with my life goals.&#39;,
  &#39; I consider exercise consistent with my values.&#39;,
  &#39; I consider exercise a fundamental part of who I am.&#39;,
  &#39; I get pleasure and satisfaction from participating in exercise&#39;,
  &#39; I exercise because it is fun&#39;,
  &#39; I enjoy my exercise sessions&#39;)

itemGroups &lt;- c(rep(&quot;Amotivation&quot;, 4),
                rep(&quot;Extrinsic&quot;, 3),
                rep(&quot;Introjected&quot;, 2),
                rep(&quot;Identified&quot;, 3),
                rep(&quot;Integrated&quot;, 3),
                rep(&quot;Intrinsic&quot;, 3))


plot(nwAll, groups = itemGroups, nodeNames = itemNames, legend.cex = 0.25)
## Warning in lcolor[is.na(lcolor)] &lt;- ifelse(vertex.colors == &quot;background&quot;, :
## number of items to replace is not a multiple of replacement length
## Error in layout[groups[[g]], 1]: subscript out of bounds</code></pre>
</div>
<div id="community-detection" class="section level2">
<h2>Community detection</h2>
<pre class="r"><code>
# Find communities
graph1 &lt;- plot(nwBCT)</code></pre>
<p><img src="baseline-supplement_files/figure-html/unnamed-chunk-50-1.png" width="2100" /></p>
<pre class="r"><code> 
g = as.igraph(graph1, attributes=TRUE)
 
matrix_spinglass &lt;- matrix(NA, nrow=1,ncol=1000)

set.seed(1)
for (i in 1:100) {
set.seed(i)
spinglass &lt;- spinglass.community(g)
matrix_spinglass[1,i] &lt;- max(spinglass$membership) 
} # 1000 took 8 minutes
 
mean(as.vector(matrix_spinglass)) 
## [1] NA
max(as.vector(matrix_spinglass)) 
## [1] NA
min(as.vector(matrix_spinglass)) 
## [1] NA
median(as.vector(matrix_spinglass)) 
## [1] NA

set.seed(1)
spinglass &lt;- spinglass.community(g)
spinglass$membership
##  [1] 1 3 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 3
spinglassGroups &lt;- list(rep(2, 6), rep(1, 4), rep(3, 9))</code></pre>
<!-- Of all the iterations of the spinglass algorithm, ` sum(table(matrix_spinglass)[1]) / 100`% gave `names(table(matrix_spinglass)[1])` groups, ` sum(table(matrix_spinglass)[2]) / 100`% gave `names(table(matrix_spinglass)[2])` groups, and ` sum(table(matrix_spinglass)[3]) / 100`% gave ` names(table(matrix_spinglass)[1])` groups,  -->
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
